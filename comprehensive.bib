@techreport{Pecka,
abstract = {We overview different approaches to safety in (semi)auto-nomous robotics. Particularly, we focus on how to achieve safe behavior of a robot if it is requested to perform exploration of unknown states. Presented methods are studied from the viewpoint of reinforcement learning, a partially-supervised machine learning method. To collect training data for this algorithm, the robot is required to freely explore the state space-which can lead to possibly dangerous situations. The role of safe exploration is to provide a framework allowing exploration while preserving safety. The examined methods range from simple algorithms to sophisticated methods based on previous experience or state prediction. Our overview also addresses the issues of how to define safety in the real-world applications (apparently absolute safety is unachievable in the continuous and random real world). In the conclusion we also suggest several ways that are worth researching more thoroughly.},
author = {Pecka, Martin and Svoboda, Tomas},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pecka, Svoboda - Unknown - LNCS 8906 - Safe Exploration Techniques for Reinforcement Learning – An Overview.pdf:pdf},
keywords = {Safe exploration,policy search,reinforcement learning},
title = {{LNCS 8906 - Safe Exploration Techniques for Reinforcement Learning – An Overview}},
url = {http://cmp.felk.cvut.cz/∼peckama2}
}
@article{Bencomo2019,
abstract = {More than a decade ago, the research topic models@run.time was coined. Since then, the research area has received increasing attention. Given the prolific results during these years, the current outcomes need to be sorted and classified. Furthermore, many gaps need to be categorized in order to further develop the research topic by experts of the research area but also newcomers. Accordingly, the paper discusses the principles and requirements of models@run.time and the state of the art of the research line. To make the discussion more concrete, a taxonomy is defined and used to compare the main approaches and research outcomes in the area during the last decade and including ancestor research initiatives. We identified and classified 275 papers on models@run.time, which allowed us to identify the underlying research gaps and to elaborate on the corresponding research challenges. Finally, we also facilitate sustainability of the survey over time by offering tool support to add, correct and visualize data.},
author = {Bencomo, Nelly and G{\"{o}}tz, Sebastian and Song, {\textperiodcentered} Hui},
doi = {10.1007/s10270-018-00712-x},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bencomo, G{\"{o}}tz, Song - 2019 - Models@run.time a guided tour of the state of the art and research challenges.pdf:pdf},
journal = {Software & Systems Modeling},
keywords = {Causal connection,Models@run.time,Self-reflection,Systematic literature review},
pages = {3049--3082},
title = {{Models@run.time: a guided tour of the state of the art and research challenges}},
url = {https://doi.org/10.1007/s10270-018-00712-x},
volume = {18},
year = {2019}
}
@article{Kuwajima2020,
abstract = {Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that employ machine learning and deep learning models, such as automated driving vehicles. In order to use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system through engineering processes. However, thus far, no such widely accepted engineering concepts or frameworks have been established for these systems. The key to using a machine learning model in a deductively engineered system is decomposing the data-driven training of machine learning models into requirement, design, and verification, particularly for machine learning models used in safety-critical systems. Simultaneously, open problems and relevant technical fields are not organized in a manner that enables researchers to select a theme and work on it. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems—that is, in terms of requirement, design, and verification of machine learning models and systems—as well as discuss related works and research directions, using automated driving vehicles as an example. Our results show that machine learning models are characterized by a lack of requirements specification, lack of design specification, lack of interpretability, and lack of robustness. We also perform a gap analysis on a conventional system quality standard SQuaRE with the characteristics of machine learning models to study quality models for machine learning systems. We find that a lack of requirements specification and lack of robustness have the greatest impact on conventional quality models.},
archivePrefix = {arXiv},
arxivId = {1904.00001},
author = {Kuwajima, Hiroshi and Yasuoka, Hirotoshi and Nakae, Toshihiro},
doi = {10.1007/s10994-020-05872-w},
eprint = {1904.00001},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuwajima, Yasuoka, Nakae - 2020 - Engineering problems in machine learning systems.pdf:pdf},
issn = {15730565},
journal = {Machine Learning},
keywords = {Automated driving,Machine learning,Quality models,Safety critical systems,Software engineering,Systems engineering},
month = {may},
number = {5},
pages = {1103--1126},
publisher = {Springer},
title = {{Engineering problems in machine learning systems}},
volume = {109},
year = {2020}
}
@article{Vogel2014,
abstract = {The development of self-adaptive software requires the engineering of an adaptation engine that controls the underlying adaptable software by feedback loops. The engine often describes the adaptation by runtime models representing the adaptable software and by activities such as analysis and planning that use these models. To systematically address the interplay between runtime models and adaptation activities, runtime megamodels have been proposed. A runtime megamodel is a specific model capturing runtime models and adaptation activities. In this article, we go one step further and present an executable modeling language for ExecUtable RuntimE MegAmodels (EUREMA) that eases the development of adaptation engines by following a model-driven engineering approach. We provide a domain-specific modeling language and a runtime interpreter for adaptation engines, in particular feedback loops. Megamodels are kept alive at runtime and by interpreting them, they are directly executed to run feedback loops. Additionally, they can be dynamically adjusted to adapt feedback loops. Thus, EUREMA supports development by making feedback loops explicit at a higher level of abstraction and it enables solutions where multiple feedback loops interact or operate on top of each other and self-adaptation co-exists with offline adaptation for evolution.},
author = {Vogel, Thomas and Giese, Holger},
doi = {10.1145/2555612},
journal = {ACM Trans. Auton. Adapt. Syst. 8, 4, Article},
keywords = {D210 [Software Engineering]: Design General Terms:,D22 [Software Engineering]: Design Tools and Techn,D29 [Software Engineering]: Management},
title = {{8 Model-Driven Engineering of Self-Adaptive Software with EUREMA}},
url = {http://dx.doi.org/10.1145/2555612},
volume = {18},
year = {2014}
}
@techreport{Annable2020,
abstract = {Thesis},
author = {Annable, Nicholas and Mechatronics, B Eng},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Annable, Mechatronics - 2020 - A Model-Based Approach to Formal Assurance Cases.pdf:pdf},
keywords = {Safety Assurance,Software Engineering,Thesis},
title = {{A Model-Based Approach to Formal Assurance Cases}},
url = {https://macsphere.mcmaster.ca/handle/11375/25343},
year = {2020}
}
@article{Kienzle2019,
abstract = {The growing use of models for separating concerns in complex systems has lead to a proliferation of model composition operators. These composition operators have traditionally been defined from scratch following various approaches differing in formality, level of detail, chosen paradigm, and styles. Due to the lack of proper foundations for defining model composition (concepts, abstractions, or frameworks), it is difficult to compare or reuse composition operators. In this paper, we stipulate the existence of a unifying framework that reduces all structural composition operators to structural merging, and all composition operators acting on discrete behaviors to event scheduling. We provide convincing evidence of this hypothesis by discussing how structural and behavioral homogeneous model composition operators (i.e., weavers) can be mapped onto this framework. Based on this discussion, we propose a conceptual model of the framework and identify a set of research challenges, which, if addressed, lead to the realization of this framework to support rigorous and efficient engineering of model composition operators for homogeneous and eventually heterogeneous modeling languages.},
author = {Kienzle, J{\"{o}}rg and Mussbacher, Gunter and Combemale, Benoit and Deantoni, Julien},
doi = {10.1007/s10270-018-00707-8},
issn = {16191374},
journal = {Software and Systems Modeling},
keywords = {Event scheduling,Event structures,Model composition,Separation of concerns,Symmetric merge},
month = {oct},
number = {5},
pages = {3005--3023},
publisher = {Springer Verlag},
title = {{A unifying framework for homogeneous model composition}},
volume = {18},
year = {2019}
}
@book{Piedra2020,
abstract = {Knowledge management plays a crucial role in initiatives that promotes the discovery and sharing of cultural and heritage informational resources from diverse and autonomous organizations and initiatives. Information in this domain is heterogeneous, distributed, multi-lingual, comes in unstructured formats and large quantities, is strongly contextualized by time and place is created collaboratively. These challenges can be undertaken using semantic technologies. Semantic Web approach and Linked Data technologies are a catalyst for cross-domain and cross-organizational semantic data interoperability and data integration. In this regard, this work will look at the interaction between knowledge management and linked open data within the context of cultural and heritage data with a particular focus on the concept of music data. This work will discuss, among other things, how Semantic Knowledge Graphs based on linked data can contribute to enhancing knowledge management and increase productivity, in actions related with cultural data enrichment, data exploration, knowledge discovery, cultural data reuse, and data visualization. By representing information using data models and open semantic standards, data integration and reasoning can be applied to the cultural data in a well-defined way.},
author = {Piedra, Nelson and {Mosquera Ar{\'{e}}valo}, Jean Pa{\'{u}}l},
booktitle = {Advances in Intelligent Systems and Computing},
doi = {10.1007/978-3-030-33547-2_12},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Piedra, Mosquera Ar{\'{e}}valo - 2020 - Linked Data and Musical Information to Improvement the Cultural and Heritage Knowledge Management.pdf:pdf;:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Piedra, Mosquera Ar{\'{e}}valo - 2020 - Linked Data and Musical Information to Improvement the Cultural and Heritage Knowledge Management(2).pdf:pdf},
isbn = {9783030335465},
issn = {21945365},
keywords = {Cultural heritage,Knowledge graphs,Linked open data,Music,Ontologies},
number = {Cimps},
pages = {141--155},
title = {{Linked Data and Musical Information to Improvement the Cultural and Heritage Knowledge Management}},
volume = {1071},
year = {2020}
}
@misc{,
title = {{The MODA framework: Model-Driven Engineering for Data-Centric Systems}},
url = {https://modeling-languages.com/a-hitchhikers-guide-to-model-driven-engineering-for-data-centric-systems/},
urldate = {2021-02-10}
}
@techreport{Hernandez-Orallo,
abstract = {AI safety often analyses a risk or safety issue, such as interruptibility, under a particular AI paradigm, such as reinforcement learning. But what is an AI paradigm and how does it affect the understanding and implications of the safety issue? Is AI safety research covering the most representative paradigms and the right combinations of paradigms with safety issues? Will current research directions in AI safety be able to anticipate more capable and powerful systems yet to come? In this paper we analyse these questions, introducing a distinction between two types of paradigms in AI: artefacts and techniques. We then use experimental data of research and media documents from AI Topics, an official publication of the AAAI, to examine how safety research is distributed across artefacts and techniques. We observe that AI safety research is not sufficiently antici-patory, and is heavily weighted towards certain research paradigms. We identify a need for AI safety to be more explicit about the artefacts and techniques for which a particular issue may be applicable, in order to identify gaps and cover a broader range of issues.},
author = {Hern{\'{a}}ndez-Orallo, Jose and Mart{\'{i}}nez-Plumed, Fernando and Avin, Shahar and Whittlestone, Jess and Se{\'{a}}n´o, Se{\'{a}}n Se{\'{a}}n´ and Eigeartaigh, ´},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hern{\'{a}}ndez-Orallo et al. - Unknown - AI Paradigms and AI Safety Mapping Artefacts and Techniques to Safety Issues.pdf:pdf},
title = {{AI Paradigms and AI Safety: Mapping Artefacts and Techniques to Safety Issues}},
url = {https://github.com/nandomp/AIParadigmsSafety.}
}
@inproceedings{Braiek2019,
abstract = {The increasing inclusion of Machine Learning (ML) models in safety-critical systems like autonomous cars have led to the development of multiple model-based ML testing techniques. One common denominator of these testing techniques is their assumption that training programs are adequate and bug-free. These techniques only focus on assessing the performance of the constructed model using manually labeled data or automatically generated data. However, their assumptions about the training program are not always true as training programs can contain inconsistencies and bugs. In this paper, we examine training issues in ML programs and propose a catalog of verification routines that can be used to detect the identified issues, automatically. We implemented the routines in a Tensorflow-based library named TFCheck. Using TFCheck, practitioners can detect the aforementioned issues automatically. To assess the effectiveness of TFCheck, we conducted a case study with real-world, mutants, and synthetic training programs. Results show that TFCheck can successfully detect training issues in ML code implementations.},
archivePrefix = {arXiv},
arxivId = {1909.02562},
author = {Braiek, Houssem Ben and Khomh, Foutse},
booktitle = {Proceedings - 19th IEEE International Conference on Software Quality, Reliability and Security, QRS 2019},
doi = {10.1109/QRS.2019.00059},
eprint = {1909.02562},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/A TensorFlow Library for Detecting Training Issues in.pdf:pdf},
isbn = {9781728139272},
keywords = {Deep Learning,TensorFlow program,Testing,Training issues},
month = {jul},
pages = {426--433},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{TFCheck : A TensorFlow Library for Detecting Training Issues in Neural Network Programs}},
year = {2019}
}
@misc{,
title = {{(No Title)}},
url = {https://repositorio-aberto.up.pt/bitstream/10216/126252/2/386471.pdf},
urldate = {2020-05-24}
}
@techreport{Deepmind,
abstract = {In many real-world reinforcement learning (RL) problems, besides optimizing the main objective function, an agent must concurrently avoid violating a number of constraints. In particular, besides optimizing performance, it is crucial to guarantee the safety of an agent during training as well as deployment (e.g., a robot should avoid taking actions-exploratory or not-which irrevocably harm its hardware). To incorporate safety in RL, we derive algorithms under the framework of constrained Markov decision processes (CMDPs), an extension of the standard Markov decision processes (MDPs) augmented with constraints on expected cumulative costs. Our approach hinges on a novel Lyapunov method. We define and present a method for constructing Lyapunov functions, which provide an effective way to guarantee the global safety of a behavior policy during training via a set of local linear constraints. Leveraging these theoretical underpinnings, we show how to use the Lyapunov approach to systematically transform dynamic programming (DP) and RL algorithms into their safe counterparts. To illustrate their effectiveness, we evaluate these algorithms in several CMDP planning and decision-making tasks on a safety benchmark domain. Our results show that our proposed method significantly outperforms existing baselines in balancing constraint satisfaction and performance.},
author = {Deepmind, Yinlam Chow and Nachum, Ofir and Brain, Google and Ghavamzadeh, Mohammad and Duenez, Edgar and Deepmind, Guzman},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Deepmind et al. - Unknown - A Lyapunov-based Approach to Safe Reinforcement Learning.pdf:pdf},
title = {{A Lyapunov-based Approach to Safe Reinforcement Learning}}
}
@misc{,
title = {{Improving Worker Safety in the Era of Machine Learning (A) - Case - Faculty & Research - Harvard Business School}},
url = {https://www.hbs.edu/faculty/Pages/item.aspx?num=53417},
urldate = {2021-02-24}
}
@article{Kristjanpoller2018,
abstract = {Measurement, prediction, and modeling of currency price volatility constitutes an important area of research at both the national and corporate level. Countries attempt to understand currency volatility to set national economic policies and firms to best manage exchange rate risk and leverage assets. A relatively new technological invention that the corporate treasurer has to turn to as part of the overall financial strategy is cryptocurrency. One estimate values the total market capitalization of cryptocurrencies at $557 billion USD at the beginning of 2018. While the overall size of the market for cryptocurrency is significant, our understanding of the behavior of this instrument is only beginning. In this article, we propose a hybrid Artificial Neural Network-Generalized AutoRegressive Conditional Heteroskedasticity (ANN-GARCH) model with preprocessing to forecast the price volatility of bitcoin, the most traded and largest by market capitalization of the cryptocurrencies.},
author = {Kristjanpoller, Werner and Minutolo, Marcel C.},
doi = {10.1016/j.eswa.2018.05.011},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kristjanpoller, Minutolo - 2018 - A hybrid volatility forecasting framework integrating GARCH, artificial neural network, technical anal.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
title = {{A hybrid volatility forecasting framework integrating GARCH, artificial neural network, technical analysis and principal components analysis}},
year = {2018}
}
@article{Bishop2013,
abstract = {Several decades of research in the field of machine learning have resulted in a multitude of different algorithms for solving a broad range of problems. To tackle a new application, a researcher typically tries to map their problem onto one of these existing methods, often influenced by their familiarity with specific algorithms and by the availability of corresponding software implementations. In this study, we describe an alternative methodology for applying machine learning, in which a bespoke solution is formulated for each new application. The solution is expressed through a compact modelling language, and the corresponding custom machine learning code is then generated automatically. This model-based approach offers several major advantages, including the opportunity to create highly tailored models for specific scenarios, as well as rapid prototyping and comparison of a range of alternative models. Furthermore, newcomers to the field of machine learning do not have to learn about the huge range of traditional methods, but instead can focus their attention on understanding a single modelling environment. In this study, we show how probabilistic graphical models, coupled with efficient inference algorithms, provide a very flexible foundation formodel-based machine learning, and we outline a large-scale commercial application of this framework involving tens of millions of users. We also describe the concept of probabilistic programming as a powerful software environment for modelbased machine learning, and we discuss a specific probabilistic programming language called Infer.NET, which has been widely used in practical applications. {\textcopyright} 2012 The Author(s) Published by the Royal Society. All rights reserved.},
author = {Bishop, Christopher M.},
doi = {10.1098/rsta.2012.0222},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop - 2013 - Model-based machine learning.pdf:pdf},
issn = {1364503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {Bayesian inference,Graphical probabilistic programming,Infer. NET},
month = {feb},
number = {1984},
publisher = {Royal Society},
title = {{Model-based machine learning}},
url = {/pmc/articles/PMC3538442/ /pmc/articles/PMC3538442/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3538442/},
volume = {371},
year = {2013}
}
@inproceedings{Breuker2014,
abstract = {Graphical models and general purpose inference algorithms are powerful tools for moving from imperative towards declarative specification of machine learning problems. Although graphical models define the principle information necessary to adapt inference algorithms to specific probabilistic models, entirely model-driven development is not yet possible. However, generating executable code from graphical models could have several advantages. It could reduce the skills necessary to implement probabilistic models and may speed up development processes. Both advantages address pressing industry needs. They come along with increased supply of data scientist labor, the demand of which cannot be fulfilled at the moment. To explore the opportunities of model-driven big data analytics, I review the main modeling languages used in machine learning as well as inference algorithms and corresponding software implementations. Gaps hampering direct code generation from graphical models are identified and closed by proposing an initial conceptualization of a domain-specific modeling language. {\textcopyright} 2014 IEEE.},
author = {Breuker, Dominic},
booktitle = {Proceedings of the Annual Hawaii International Conference on System Sciences},
doi = {10.1109/HICSS.2014.101},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Towards model-driven engineering for big data analytics–an exploratory analysis of domain- specific languages for machine learning.pdf:pdf},
isbn = {9781479925049},
issn = {15301605},
pages = {758--767},
publisher = {IEEE Computer Society},
title = {{Towards model-driven engineering for big data analytics - An exploratory analysis of domain-specific languages for machine learning}},
year = {2014}
}
@article{Xu,
archivePrefix = {arXiv},
arxivId = {1609.08144},
author = {Xu, Zongben and Sun, Jian},
doi = {10.1093/nsr/nwx099},
eprint = {1609.08144},
title = {{Special Topic: Machine Learning Model-driven deep-learning}},
url = {https://academic.oup.com/nsr/article-abstract/5/1/22/4093908}
}
@article{Abadi,
abstract = {TensorFlow is a powerful, programmable system for machine learning. This paper aims to provide the basics of a conceptual framework for understanding the behavior of TensorFlow models during training and inference: it describes an operational semantics, of the kind common in the literature on programming languages. More broadly, the paper suggests that a programming-language perspective is fruitful in designing and in explaining systems such as TensorFlow.},
author = {Abadi, Mart{\'{i}}n and Isard, Michael and {Google Brain}, Derek G Murray},
doi = {10.1145/3088525.3088527},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi, Isard, Google Brain - Unknown - A Computational Model for TensorFlow An Introduction(2).pdf:pdf},
isbn = {9781450350716},
keywords = {CCS Concepts • Theory of computation → Operational,• Computing methodologies → Neural networks,• Software and its engineering → Data flow archite},
title = {{A Computational Model for TensorFlow An Introduction}},
url = {http://dx.doi.org/10.1145/3088525.3088527}
}
@article{Lessmann2015,
author = {Lessmann, Stefan and Baesens, Bart and Seow, Hsin-Vonn and Thomas, Lyn C},
doi = {10.1016/j.ejor.2015.05.030},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lessmann et al. - 2015 - Benchmarking state-of-the-art classification algorithms for credit scoring An update of research.pdf:pdf},
journal = {European Journal of Operational Research},
keywords = {Credit scoring,Data mining,Forecasting benchmark,OR in banking},
pages = {124--136},
title = {{Benchmarking state-of-the-art classification algorithms for credit scoring: An update of research}},
url = {http://dx.doi.org/10.1016/j.ejor.2015.05.030},
volume = {247},
year = {2015}
}
@techreport{Fisac,
abstract = {Safety analysis is a necessary component in the design and deployment of autonomous systems. Techniques from robust optimal control theory, such as Hamilton-Jacobi reachability analysis, allow a rigorous formalization of safety as guaranteed constraint satisfaction. Unfortunately, the computational complexity of these tools for general dynamical systems scales poorly with state dimension, making existing tools impractical beyond small problems. Modern reinforcement learning methods have shown promising ability to find approximate yet proficient solutions to optimal control problems in complex and high-dimensional systems, however their formulation is restricted to problems with an additive payoff (reward) over time, unsuitable for reasoning about safety. In recent work, we proved that the problem of maximizing the minimum payoff over time, central to safety analysis, can be time-discounted to induce a contraction mapping. Here, we introduce a novel, time-discounted Safety Bellman Equation that renders reinforcement learning techniques amenable to quantitative safety analysis, enabling them to approximate the safe set and optimal safety policy. This opens a new avenue of research connecting control-theoretic safety analysis and the reinforcement learning domain. We demonstrate our formulation on a variety of simulated robotics tasks and reinforcement learning schemes, validating our results against analytic and numerical solutions when these can be obtained, and showing scalability to previously intractable problems of up to 18 state dimensions by exploiting state-of-the-art deep reinforcement learning algorithms.},
author = {Fisac, Jaime F and Lugovoy, Neil F and Rubies-Royo, Vicen{\c{c}} and Ghosh, Shromona and Tomlin, Claire J},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisac et al. - Unknown - Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning.pdf:pdf},
title = {{Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning}}
}
@article{Koseler,
abstract = {Accompanying the Big Data (BD) paradigm is a resurgence in machine learning (ML). Using ML techniques to work with BD is a complex task, requiring specialized knowledge of the problem space, domain specific concepts, and appropriate ML approaches. However, specialists who possess that knowledge and programming ability are difficult to find and expensive to train. Model-Driven Engineering (MDE) allows developers to implement quality software through modeling using high-level domain specific concepts. In this research, we attempt to fill the gap between MDE and the industrial need for development of ML software by demonstrating the plausibility of applying MDE to BD. Specifically, we apply MDE to the setting of the thriving industry of professional baseball analytics. Our case study involves developing an MDE solution for the binary classification problem of predicting if a baseball pitch will be a fastball. We employ and refine an existing, but untested, ML Domain-Specific Modeling Language (DSML); devise model instances representing prediction features; create a code generation scheme; and evaluate our solution. We show our MDE solution is comparable to the one developed through traditional programming, distribute all our artifacts for public use and extension, and discuss the impact of our work and lessons we learned.},
author = {Koseler, Kaan and Mcgraw, Kelsea and Stephan, Matthew},
doi = {10.5220/0007245800130024},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Koseler, Mcgraw, Stephan - Unknown - Realization of a Machine Learning Domain Specific Modeling Language A Baseball Analytics Case Study.pdf:pdf},
isbn = {9789897583582},
keywords = {Baseball Analytics,Binary Classification,Domain Specific Modeling Language,Machine Learning,Model Driven Engineering,Supervised Learning},
title = {{Realization of a Machine Learning Domain Specific Modeling Language: A Baseball Analytics Case Study}},
url = {https://sc.lib.miamioh.edu/handle/2374.MIA/6234}
}
@article{DelaVega2020,
abstract = {Input data of a data mining algorithm must conform to a very specific tabular format. Data scientists arrange data into that format by creating long and complex scripts, where different low-level operations are performed, and which can be a time-consuming and error-prone process. To alleviate this situation, we present Lavoisier, a declarative language for data selection and formatting in a data mining context. Using Lavoisier, script size for data preparation can be reduced by ∼40% on average, and by up to 80% in some cases. Additionally, accidental complexity present in state-of-the-art technologies is considerably mitigated.},
author = {de la Vega, Alfonso and Garc{\'{i}}a-Saiz, Diego and Zorrilla, Marta and S{\'{a}}nchez, Pablo},
doi = {10.1016/j.cola.2020.100987},
issn = {25901184},
journal = {Journal of Computer Languages},
keywords = {Data formatting,Data mining,Data selection,Domain-specific languages},
month = {oct},
pages = {100987},
publisher = {Elsevier Ltd},
title = {{Lavoisier: A DSL for increasing the level of abstraction of data selection and formatting in data mining}},
volume = {60},
year = {2020}
}
@article{,
doi = {10.1007/978-3-319-33361-8},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2016 - Functional Safety for Road Vehicles.pdf:pdf},
isbn = {9783319333601},
title = {{Functional Safety for Road Vehicles}},
year = {2016}
}
@article{Mohseni2020,
abstract = {Autonomous vehicles rely on machine learning to solve challenging tasks in perception and motion planning. However, automotive software safety standards have not fully evolved to address the challenges of machine learning safety such as interpretability, verification, and performance limitations. In this paper, we review and organize practical machine learning safety techniques that can complement engineering safety for machine learning based software in autonomous vehicles. Our organization maps safety strategies to state-of-the-art machine learning techniques in order to enhance dependability and safety of machine learning algorithms. We also discuss security limitations and user experience aspects of machine learning components in autonomous vehicles.},
author = {Mohseni, Sina and Pitale, Mandar and Singh, Vasu and Wang, Zhangyang},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohseni et al. - 2020 - Practical Solutions for Machine Learning Safety in Autonomous Vehicles.pdf:pdf},
keywords = {Autonomous,Machine Learning,Safety},
mendeley-tags = {Autonomous,Machine Learning,Safety},
title = {{Practical Solutions for Machine Learning Safety in Autonomous Vehicles}},
year = {2020}
}
@techreport{Ries,
author = {Ries, Benoˆıt Benoˆıt and Guelfi, Nicolas and Jahi´c, Benjamin Jahi´c},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ries, Guelfi, Jahi´c - Unknown - An MDE Method for Improving Deep Learning Dataset Requirements Engineering using Alloy and UML.pdf:pdf},
keywords = {Alloy,EMF,Model-Driven Engineering,Requirements Engineering,Sirius,Software Engineering},
title = {{An MDE Method for Improving Deep Learning Dataset Requirements Engineering using Alloy and UML}},
url = {https://orcid.org/0000-0002-8680-2797}
}
@misc{Kelly2019,
abstract = {Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.},
author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
booktitle = {BMC Medicine},
doi = {10.1186/s12916-019-1426-2},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelly et al. - 2019 - Key challenges for delivering clinical impact with artificial intelligence(2).pdf:pdf},
issn = {17417015},
keywords = {Algorithms,Artificial intelligence,Evaluation,Machine learning,Regulation,Translation},
month = {oct},
number = {1},
pages = {195},
pmid = {31665002},
publisher = {BioMed Central Ltd.},
title = {{Key challenges for delivering clinical impact with artificial intelligence}},
url = {https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1426-2},
volume = {17},
year = {2019}
}
@techreport{Manuel2020,
author = {Manuel, Pedro and Costa, Afonso},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Manuel, Costa - 2020 - FACULDADE DE ENGENHARIA DA UNIVERSIDADE DO PORTO Customized Hardware for Long-Short Term Memory Networks in Embed.pdf:pdf},
title = {{FACULDADE DE ENGENHARIA DA UNIVERSIDADE DO PORTO Customized Hardware for Long-Short Term Memory Networks in Embedded Systems}},
year = {2020}
}
@article{Ganin2015,
abstract = {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of "deep" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard back-propagation. Overall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.},
archivePrefix = {arXiv},
arxivId = {1409.7495},
author = {Ganin, Yaroslav and Lempitsky, Victor},
eprint = {1409.7495},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ganin, Lempitsky - 2015 - Unsupervised domain adaptation by backpropagation.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
month = {sep},
pages = {1180--1189},
publisher = {International Machine Learning Society (IMLS)},
title = {{Unsupervised domain adaptation by backpropagation}},
url = {https://arxiv.org/abs/1409.7495v2},
volume = {2},
year = {2015}
}
@techreport{Varshney2017a,
abstract = {Machine learning algorithms increasingly influence our decisions and interact with us in all parts of our daily lives. Therefore, just as we consider the safety of power plants, highways, and a variety of other engineered socio-technical systems, we must also take into account the safety of systems involving machine learning. Heretofore, the definition of safety has not been formalized in a machine learning context. In this paper, we do so by defining machine learning safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. We then use this definition to examine safety in all sorts of applications in cyber-physical systems, decision sciences, and data products. We find that the foundational principle of modern statistical machine learning, empirical risk minimization, is not always a sufficient objective. Finally, we discuss how four different categories of strategies for achieving safety in engineering, including inherently safe design, safety reserves, safe fail, and procedural safeguards can be mapped to a machine learning context. We then discuss example techniques that can be adopted in each category, such as considering interpretability and causality of predictive models, 2 objective functions beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software and open data.},
archivePrefix = {arXiv},
arxivId = {1610.01256v2},
author = {Varshney, Kush R and Alemzadeh, Homa},
eprint = {1610.01256v2},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Varshney, Alemzadeh - 2017 - On the Safety of Machine Learning Cyber-Physical Systems, Decision Sciences, and Data Products.pdf:pdf},
title = {{On the Safety of Machine Learning: Cyber-Physical Systems, Decision Sciences, and Data Products}},
year = {2017}
}
@techreport{Qayyum,
abstract = {Recent years have witnessed widespread adoption of machine learning (ML)/deep learning (DL) techniques due to their superior performance for a variety of healthcare applications ranging from the prediction of cardiac arrest from one-dimensional heart signals to computer-aided diagnosis (CADx) using multi-dimensional medical images. Notwithstanding the impressive performance of ML/DL, there are still lingering doubts regarding the robustness of ML/DL in healthcare settings (which is traditionally considered quite challenging due to the myriad security and privacy issues involved), especially in light of recent results that have shown that ML/DL are vulnerable to adversarial attacks. In this paper, we present an overview of various application areas in healthcare that leverage such techniques from security and privacy point of view and present associated challenges. In addition, we present potential methods to ensure secure and privacy-preserving ML for healthcare applications. Finally, we provide insight into the current research challenges and promising directions for future research.},
archivePrefix = {arXiv},
arxivId = {2001.08103v1},
author = {Qayyum, Adnan and Qadir, Junaid and Bilal, Muhammad and Al-Fuqaha, Ala},
eprint = {2001.08103v1},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qayyum et al. - Unknown - Secure and Robust Machine Learning for Healthcare A Survey.pdf:pdf},
title = {{Secure and Robust Machine Learning for Healthcare: A Survey}},
url = {https://tinyurl.com/FDA-AI-diabetic-eye}
}
@misc{,
title = {{Artificial intelligence in the software engineering workflow – O'Reilly}},
url = {https://www.oreilly.com/radar/artificial-intelligence-in-the-software-engineering-workflow/},
urldate = {2021-03-16}
}
@article{Humbatova,
abstract = {The growing application of deep neural networks in safety-critical domains makes the analysis of faults that occur in such systems of enormous importance. In this paper we introduce a large taxonomy of faults in deep learning (DL) systems. We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts. Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our tax-onomy with a variety of additional faults that did not emerge from the other two sources. Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50% of the survey participants. CCS CONCEPTS • Software and its engineering → Software verification and validation.},
author = {Humbatova, Nargiz and Jahangirova, Gunel and Bavota, Gabriele and Riccio, Vincenzo and Stocco, Andrea and Tonella, Paolo},
doi = {10.1145/3377811.3380395},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Humbatova et al. - Unknown - Taxonomy of Real Faults in Deep Learning Systems.pdf:pdf},
isbn = {9781450371216},
keywords = {deep learning,real faults,software testing,taxonomy},
pages = {12},
publisher = {ACM},
title = {{Taxonomy of Real Faults in Deep Learning Systems}},
url = {https://doi.org/10.1145/3377811.3380395}
}
@techreport{Hernandez-Oralloa,
abstract = {The current analysis in the AI safety literature usually combines a risk or safety issue (e.g., interruptibility) with a particular paradigm for an AI agent (e.g., reinforcement learning). However, there is currently no survey of safety-relevant characteristics of AI systems that may reveal neglected areas of research or suggest to developers what design choices they could make to avoid or minimise certain safety concerns. In this paper, we take a first step towards delivering such a survey , from two angles. The first features AI system characteristics that are already known to be relevant to safety concerns, including internal system characteristics, characteristics relating to the effect of the external environment on the system , and characteristics relating to the effect of the system on the target environment. The second presents a brief survey of a broad range of AI system characteristics that could prove relevant to safety research, including types of interaction, computation, integration, anticipation, supervision, modification , motivation and achievement. This survey enables further work in exploring system characteristics and design choices that affect safety concerns.},
author = {Hern{\'{a}}ndez-Orallo, Jos{\'{e}} and Mart{\'{i}}nez-Plumed, Fernando and Avin, Shahar and Se{\'{a}}n´o, Se{\'{a}}n Se{\'{a}}n´ and Eigeartaigh, ´},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hern{\'{a}}ndez-Orallo et al. - Unknown - Surveying Safety-relevant AI Characteristics.pdf:pdf},
title = {{Surveying Safety-relevant AI Characteristics}}
}
@techreport{Varshney2016,
abstract = {Machine learning algorithms are increasingly influencing our decisions and interacting with us in all parts of our daily lives. Therefore, just like for power plants, highways, and myriad other engineered sociotechnical systems, we must consider the safety of systems involving machine learning. In this paper, we first discuss the definition of safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. Then we examine dimensions, such as the choice of cost function and the appropriateness of minimizing the empirical average training cost, along which certain real-world applications may not be completely amenable to the foundational principle of modern statistical machine learning: empirical risk minimization. In particular, we note an emerging dichotomy of applications: ones in which safety is important and risk minimization is not the complete story (we name these Type A applications), and ones in which safety is not so critical and risk minimization is sufficient (we name these Type B applications). Finally, we discuss how four different strategies for achieving safety in engineering (inherently safe design, safety reserves, safe fail, and procedural safeguards) can be mapped to the machine learning context through inter-pretability and causality of predictive models, objectives beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software.},
archivePrefix = {arXiv},
arxivId = {1601.04126v1},
author = {Varshney, Kush R},
eprint = {1601.04126v1},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Varshney - 2016 - Engineering Safety in Machine Learning.pdf:pdf},
keywords = {()},
title = {{Engineering Safety in Machine Learning}},
year = {2016}
}
@inproceedings{Varshney2017,
abstract = {Machine learning algorithms are increasingly influencing our decisions and interacting with us in all parts of our daily lives. Therefore, just like for power plants, highways, and myriad other engineered sociotechnical systems, we must consider the safety of systems involving machine learning. In this paper, we first discuss the definition of safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. Then we examine dimensions, such as the choice of cost function and the appropriateness of minimizing the empirical average training cost, along which certain real-world applications may not be completely amenable to the foundational principle of modern statistical machine learning: empirical risk minimization. In particular, we note an emerging dichotomy of applications: ones in which safety is important and risk minimization is not the complete story (we name these Type A applications), and ones in which safety is not so critical and risk minimization is sufficient (we name these Type B applications). Finally, we discuss how four different strategies for achieving safety in engineering (inherently safe design, safety reserves, safe fail, and procedural safeguards) can be mapped to the machine learning context through inter-pretability and causality of predictive models, objectives beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software.},
archivePrefix = {arXiv},
arxivId = {1601.04126},
author = {Varshney, Kush R.},
booktitle = {2016 Information Theory and Applications Workshop, ITA 2016},
doi = {10.1109/ITA.2016.7888195},
eprint = {1601.04126},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Engineering safety in machine learning.pdf:pdf},
isbn = {9781509025299},
month = {mar},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Engineering safety in machine learning}},
year = {2017}
}
@article{Zolotas2019,
abstract = {Flexible or bottom-up model-driven engineering (MDE) is an emerging approach to domain and systems modelling. Domain experts, who have detailed domain knowledge, typically lack the technical expertise to transfer this knowledge using traditional MDE tools. Flexible MDE approaches tackle this challenge by promoting the use of simple drawing tools to increase the involvement of domain experts in the language definition process. In such approaches, no metamodel is created upfront, but instead the process starts with the definition of example models that will be used to infer the metamodel. Pre-defined metamodels created by MDE experts may miss important concepts of the domain and thus restrict their expressiveness. However, the lack of a metamodel, that encodes the semantics of conforming models has some drawbacks, among others that of having models with elements that are unintentionally left untyped. In this paper, we propose the use of classification algorithms to help with the inference of such untyped elements. We evaluate the proposed approach in a number of random generated example models from various domains. The correct type prediction varies from 23 to 100% depending on the domain, the proportion of elements that were left untyped and the prediction algorithm used. Keywords Model-driven engineering {\textperiodcentered} Flexible model-driven engineering {\textperiodcentered} Bottom-up metamodelling {\textperiodcentered} Type inference {\textperiodcentered} Classification and regression trees {\textperiodcentered} Random forests},
author = {Zolotas, Athanasios and Matragkas, Nicholas and Devlin, {\textperiodcentered} Sam and Kolovos, Dimitrios S and Richard, {\textperiodcentered} and Paige, F},
doi = {10.1007/s10270-018-0658-5},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zolotas et al. - 2019 - Type inference in flexible model-driven engineering using classification algorithms.pdf:pdf},
journal = {Software & Systems Modeling},
keywords = {Bottom-up metamodelling,Classification and regression trees,Flexible model-driven engineering,Model-driven engineering,Random forests,Type inference},
pages = {345--366},
title = {{Type inference in flexible model-driven engineering using classification algorithms}},
url = {https://doi.org/10.1007/s10270-018-0658-5},
volume = {18},
year = {2019}
}
@misc{,
title = {{IEEE Xplore Full-Text PDF:}},
url = {https://ieeexplore-ieee-org.libaccess.lib.mcmaster.ca/stamp/stamp.jsp?tp=&arnumber=8904820},
urldate = {2021-03-16}
}
@article{Burton,
abstract = {This paper describes the challenges involved in arguing the safety of highly automated driving functions which make use of machine learning techniques. An assurance case structure is used to highlight the systems engineering and validation considerations when applying machine learning methods for highly automated driving. Particular focus is placed on addressing functional insufficiencies in the perception functions based on convolutional neural networks and possible types of evidence that can be used to mitigate against such risks.},
author = {Burton, Simon and Gauerhof, Lydia and Heinzemann, Christian},
doi = {10.1007/978-3-319-66284-8},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Burton, Gauerhof, Heinzemann - Unknown - Making the Case for Safety of Machine Learning in Highly Automated Driving.pdf:pdf},
title = {{Making the Case for Safety of Machine Learning in Highly Automated Driving}},
url = {https://www.youtube.com/watch?v=u6aEYuemt0M}
}
@techreport{Cheriton,
abstract = {The amount of data generated in the modern society is increasing rapidly. New problems and novel approaches of data capture, storage, analysis and visualization are responsible for the emergence of the Big Data research field. Machine Learning algorithms can be used in Big Data to make better and more accurate inferences. However, because of the challenges Big Data imposes, these algorithms need to be adapted and optimized to specific applications. One important decision made by software engineers is the choice of the language that is used in the implementation of these algorithms. Therefore, this literature survey identifies and describes domain-specific languages and frameworks used for Machine Learning in Big Data. By doing this, software engineers can then make more informed choices and beginners have an overview of the main languages used in this domain.},
author = {Cheriton, David R and Alencar, Paulo and Cowan, Donald},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheriton, Alencar, Cowan - Unknown - A Survey on Domain-Specific Languages for Machine Learning in Big Data Ivens Portugal.pdf:pdf},
keywords = {BD,Big Data,DSL,ML,Machine Learning,domain-specific languages,literature survey},
title = {{A Survey on Domain-Specific Languages for Machine Learning in Big Data Ivens Portugal}}
}
@article{Henriksson2018,
abstract = {Machine learning (ML) applications generate a continuous stream of success stories from various domains. ML enables many novel applications, also in safety-critical contexts. However, the functional safety standards such as ISO 26262 did not evolve to cover ML. We conduct an exploratory study on which parts of ISO 26262 represent the most critical gaps between safety engineering and ML development. While this paper only reports the first steps toward a larger research endeavor, we report three adaptations that are critically needed to allow ISO 26262 compliant engineering, and related suggestions on how to evolve the standard. CCS CONCEPTS • Computing methodologies → Machine learning; • Software and its engineering → Software safety; KEYWORDS automotive software, machine learning, safety, interview study ACM Reference Format: Jens Henriksson, Markus Borg, and Cristofer Englund. 2018. Automotive safety and machine learning: Initial results from a study on how to adapt the ISO 26262 safety standard.},
archivePrefix = {arXiv},
arxivId = {1604.07316},
author = {Henriksson, Jens and Borg, Markus and Englund, Cristofer},
doi = {10.1145/3194085.3194090},
eprint = {1604.07316},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Henriksson, Borg, Englund - 2018 - Automotive safety and machine learning Initial results from a study on how to adapt the ISO 26262 saf.pdf:pdf},
isbn = {9781450357395},
publisher = {ACM},
title = {{Automotive safety and machine learning: Initial results from a study on how to adapt the ISO 26262 safety standard}},
url = {https://doi.org/10.1145/3194085.3194090},
year = {2018}
}
@inproceedings{Nguyen2019,
abstract = {Manual classification methods of metamodel repositories require highly trained personnel and the results are usually influenced by the subjectivity of human perception. Therefore, automated metamodel classification is very desirable and stringent. In this work, Machine Learning techniques have been employed for metamodel automated classification. In particular, a tool implementing a feed-forward neural network is introduced to classify metamodels. An experimental evaluation over a dataset of 555 metamodels demonstrates that the technique permits to learn from manually classified data and effectively categorize incoming unlabeled data with a considerably high prediction rate: the best performance comprehends 95.40% as success rate, 0.945 as precision, 0.938 as recall, and 0.942 as F1 score.},
author = {Nguyen, Phuong T. and {Di Rocco}, Juri and {Di Ruscio}, Davide and Pierantonio, Alfonso and Iovino, Ludovico},
booktitle = {Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems, MODELS 2019},
doi = {10.1109/MODELS.2019.00011},
isbn = {9781728125350},
keywords = {Machine learning,metamodel classification,metamodel repositories},
month = {sep},
pages = {272--282},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Automated Classification of Metamodel Repositories: A Machine Learning Approach}},
year = {2019}
}
@techreport{Hendrycks,
abstract = {In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.},
archivePrefix = {arXiv},
arxivId = {1903.12261v1},
author = {Hendrycks, Dan and Dietterich, Thomas},
eprint = {1903.12261v1},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hendrycks, Dietterich - Unknown - BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS.pdf:pdf},
title = {{BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS}},
url = {https://github.com/hendrycks/robustness.}
}
@article{Hartmann2019a,
abstract = {Machine learning algorithms are designed to resolve unknown behaviors by extracting commonalities over massive datasets. Unfortunately, learning such global behaviors can be inaccurate and slow for systems composed of heterogeneous elements, which behave very differently, for instance as it is the case for cyber-physical systems and Internet of Things applications. Instead, to make smart decisions, such systems have to continuously refine the behavior on a per-element basis and compose these small learning units together. However, combining and composing learned behaviors from different elements is challenging and requires domain knowledge. Therefore, there is a need to structure and combine the learned behaviors and domain knowledge together in a flexible way. In this paper we propose to weave machine learning into domain modeling. More specifically, we suggest to decompose machine learning into reusable, chainable, and independently computable small learning units, which we refer to as microlearning units. These microlearning units are modeled together with and at the same level as the domain data. We show, based on a smart grid case study, that our approach can be significantly more accurate than learning a global behavior, while the performance is fast enough to be used for live learning.},
author = {Hartmann, Thomas and Moawad, Assaad and Fouquet, Francois and {Le Traon}, Yves},
doi = {10.1007/s10270-017-0600-2},
issn = {1619-1366},
journal = {Software & Systems Modeling},
keywords = {Cyber-physical systems,Domain modeling,Live learning,Metamodeling,Model-driven engineering,Smart grids},
month = {apr},
number = {2},
pages = {1285--1304},
publisher = {Springer Verlag},
title = {{The next evolution of MDE: a seamless integration of machine learning into domain modeling}},
url = {http://link.springer.com/10.1007/s10270-017-0600-2},
volume = {18},
year = {2019}
}
@article{Arlot2010,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplic-ity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
archivePrefix = {arXiv},
arxivId = {0907.4728},
author = {Arlot, Sylvain and Celisse, Alain},
doi = {10.1214/09-SS054},
eprint = {0907.4728},
issn = {19357516},
journal = {Statistics Surveys},
keywords = {Cross-validation,Leave-one-out,Model selection},
pages = {40--79},
title = {{A survey of cross-validation procedures for model selection}},
volume = {4},
year = {2010}
}
@article{Zhang,
abstract = {Deep learning applications become increasingly popular in important domains such as self-driving systems and facial identity systems. Defective deep learning applications may lead to catastrophic consequences. Although recent research eeorts were made on testing and debugging deep learning applications, the characteristics of deep learning defects have never been studied. To oll this gap, we studied deep learning applications built on top of TensorFlow and collected program bugs related to TensorFlow from StackOver-ow QA pages and Github projects. We extracted information from QA pages, commit messages, pull request messages, and issue discussions to examine the root causes and symptoms of these bugs. We also studied the strategies deployed by TensorFlow users for bug detection and localization. These endings help researchers and TensorFlow users to gain a better understanding of coding defects in TensorFlow programs and point out a new direction for future research. CCS CONCEPTS • Software and its engineering → Software defect analysis; KEYWORDS},
author = {Zhang, Yuhao and Chen, Yifan and Cheung, Shing-Chi and Xiong, Yingfei and Zhang, Lu},
doi = {10.1145/3213846.3213866},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - Unknown - An Empirical Study on TensorFlow Program Bugs.pdf:pdf},
isbn = {9781450356992},
pages = {12},
publisher = {ACM},
title = {{An Empirical Study on TensorFlow Program Bugs}},
url = {https://doi.org/10.1145/3213846.3213866}
}
@misc{Salay2017,
abstract = {—Machine learning (ML) plays an ever-increasing role in advanced automotive functionality for driver assistance and autonomous operation; however, its adequacy from the perspective of safety certification remains controversial. In this paper, we analyze the impacts that the use of ML as an implementation approach has on ISO 26262 safety lifecycle and ask what could be done to address them. We then provide a set of recommendations on how to adapt the standard to accommodate ML.},
archivePrefix = {arXiv},
arxivId = {1709.02435},
author = {Salay, Rick and Queiroz, Rodrigo and Czarnecki, Krzysztof},
booktitle = {arXiv},
eprint = {1709.02435},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salay, Queiroz, Czarnecki - 2017 - An Analysis of ISO 26262 Using Machine Learning Safely in Automotive Software.pdf:pdf},
issn = {23318422},
month = {sep},
publisher = {arXiv},
title = {{An Analysis of ISO 26262: Using Machine Learning Safely in Automotive Software}},
year = {2017}
}
@misc{,
title = {{Theano - Computational Graph - Tutorialspoint}},
url = {https://www.tutorialspoint.com/theano/theano_computational_graph.htm},
urldate = {2021-03-17}
}
@article{Bencomo2019a,
abstract = {More than a decade ago, the research topic models@run.time was coined. Since then, the research area has received increasing attention. Given the prolific results during these years, the current outcomes need to be sorted and classified. Furthermore, many gaps need to be categorized in order to further develop the research topic by experts of the research area but also newcomers. Accordingly, the paper discusses the principles and requirements of models@run.time and the state of the art of the research line. To make the discussion more concrete, a taxonomy is defined and used to compare the main approaches and research outcomes in the area during the last decade and including ancestor research initiatives. We identified and classified 275 papers on models@run.time, which allowed us to identify the underlying research gaps and to elaborate on the corresponding research challenges. Finally, we also facilitate sustainability of the survey over time by offering tool support to add, correct and visualize data.},
author = {Bencomo, Nelly and G{\"{o}}tz, Sebastian and Song, Hui},
doi = {10.1007/s10270-018-00712-x},
issn = {16191374},
journal = {Software and Systems Modeling},
keywords = {Causal connection,Models@run.time,Self-reflection,Systematic literature review},
month = {oct},
number = {5},
pages = {3049--3082},
publisher = {Springer Verlag},
title = {{Models@run.time: a guided tour of the state of the art and research challenges}},
url = {https://link.springer.com/article/10.1007/s10270-018-00712-x},
volume = {18},
year = {2019}
}
@article{Amodei2016a,
abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
archivePrefix = {arXiv},
arxivId = {1606.06565},
author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'{e}}, Dan},
eprint = {1606.06565},
month = {jun},
title = {{Concrete Problems in AI Safety}},
url = {http://arxiv.org/abs/1606.06565},
year = {2016}
}
@techreport{Al-Rfou,
archivePrefix = {arXiv},
arxivId = {1605.02688v1},
author = {Al-Rfou, Rami and Alain, Guillaume and Almahairi, Amjad and Angermueller, Christof and Bahdanau, Dzmitry and Ballas, Nicolas and Bastien, Fr{\'{e}}d{\'{e}}ric and Bayer, Justin and Belikov, Anatoly and Belopolsky, Alexander and Bengio, Yoshua and Bergeron, Arnaud and Bergstra, James and Bisson, Valentin and Snyder, Josh Bleecher and Bouchard, Nicolas and Boulanger-Lewandowski, Nicolas and Bouthillier, Xavier and {De Br{\'{e}}bisson}, Alexandre and Breuleux, Olivier and Carrier, Pierre-Luc and Cho, Kyunghyun and Chorowski, Jan and Christiano, Paul and Cooijmans, Tim and C{\^{o}}t{\'{e}}, Marc-Alexandre and C{\^{o}}t{\'{e}}, Myriam and Courville, Aaron and Dauphin, Yann N and Delalleau, Olivier and Demouth, Julien and Desjardins, Guillaume and Dieleman, Sander and Dinh, Laurent and Ducoffe, M{\'{e}}lanie and Dumoulin, Vincent and Kahou, Samira Ebrahimi and Erhan, Dumitru and Fan, Ziye and Firat, Orhan and Germain, Mathieu and Glorot, Xavier and Goodfellow, Ian and Graham, Matt and Gulcehre, Caglar and Hamel, Philippe and Harlouchet, Iban and Heng, Jean-Philippe and Hidasi, Bal{\'{a}}zs and Honari, Sina and Jain, Arjun and Jean, S{\'{e}}bastien and Jia, Kai and Korobov, Mikhail and Kulkarni, Vivek and Lamb, Alex and Lamblin, Pascal and Larsen, Eric and Laurent, C{\'{e}}sar and Lee, Sean and Lefrancois, Simon and Lemieux, Simon and L{\'{e}}onard, Nicholas and Lin, Zhouhan and Livezey, Jesse A and Lorenz, Cory and Lowin, Jeremiah and Ma, Qianli and Manzagol, Pierre-Antoine and Mastropietro, Olivier and Mcgibbon, Robert T and Memisevic, Roland and {Van Merri{\"{e}}nboer}, Bart and Michalski, Vincent and Mirza, Mehdi and Orlandi, Alberto and Pal, Christopher and Pascanu, Razvan and Pezeshki, Mohammad and Raffel, Colin and Renshaw, Daniel and Rocklin, Matthew and Romero, Adriana and Roth, Markus and Sadowski, Peter and Salvatier, John and Savard, Fran{\c{c}}ois and Schl{\"{u}}ter, Jan and Schulman, John and Schwartz, Gabriel and Serban, Iulian Vlad and Serdyuk, Dmitriy and Shabanian, Samira and Simon, Etienne and Spieckermann, Sigurd and Subramanyam, S Ramana and Sygnowski, Jakub and Tanguay, J{\'{e}}r{\'{e}}mie and {Van Tulder}, Gijs and Turian, Joseph and Urban, Sebastian and Vincent, Pascal and Visin, Francesco and {De Vries}, Harm and Warde-Farley, David and Webb, Dustin J and Willson, Matthew and Xu, Kelvin and Xue, Lijun and Yao, Li and Zhang, Saizheng and Zhang, Ying},
eprint = {1605.02688v1},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Rfou et al. - Unknown - Theano A Python framework for fast computation of mathematical expressions (The Theano Development Team).pdf:pdf},
title = {{Theano: A Python framework for fast computation of mathematical expressions (The Theano Development Team) *}},
url = {https://groups.google.com/group/theano-dev/}
}
@article{Shlezinger2020,
abstract = {Signal processing, communications, and control have traditionally relied on classical statistical modeling techniques. Such model-based methods utilize mathematical formulations that represent the underlying physics, prior information and additional domain knowledge. Simple classical models are useful but sensitive to inaccuracies and may lead to poor performance when real systems display complex or dynamic behavior. On the other hand, purely data-driven approaches that are model-agnostic are becoming increasingly popular as datasets become abundant and the power of modern deep learning pipelines increases. Deep neural networks (DNNs) use generic architectures which learn to operate from data, and demonstrate excellent performance, especially for supervised problems. However, DNNs typically require massive amounts of data and immense computational resources, limiting their applicability for some signal processing scenarios. We are interested in hybrid techniques that combine principled mathematical models with data-driven systems to benefit from the advantages of both approaches. Such model-based deep learning methods exploit both partial domain knowledge, via mathematical structures designed for specific problems, as well as learning from limited data. In this article we survey the leading approaches for studying and designing model-based deep learning systems. We divide hybrid model-based/data-driven systems into categories based on their inference mechanism. We provide a comprehensive review of the leading approaches for combining model-based algorithms with deep learning in a systematic manner, along with concrete guidelines and detailed signal processing oriented examples from recent literature. Our aim is to facilitate the design and study of future systems on the intersection of signal processing and machine learning that incorporate the advantages of both domains.},
archivePrefix = {arXiv},
arxivId = {2012.08405},
author = {Shlezinger, Nir and Whang, Jay and Eldar, Yonina C. and Dimakis, Alexandros G.},
eprint = {2012.08405},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shlezinger et al. - 2020 - Model-Based Deep Learning.pdf:pdf},
journal = {arXiv},
month = {dec},
publisher = {arXiv},
title = {{Model-Based Deep Learning}},
url = {http://arxiv.org/abs/2012.08405},
year = {2020}
}
@misc{,
title = {{Emerging Safety Issues in Artificial Intelligence | PSNet}},
url = {https://psnet.ahrq.gov/perspective/emerging-safety-issues-artificial-intelligence#ref15},
urldate = {2021-03-17}
}
@inproceedings{Hartmann2017,
abstract = {Machine learning algorithms are designed to resolve unknown behaviours by extracting commonalities over massive datasets. Unfortunately, learning such global behaviours can be inaccurate and slow for systems composed of heterogeneous elements, which behave very differently, for instance as it is the case for cyber-physical systems and Internet of Things applications. Instead, to make smart decisions, such systems have to continuously refine the behaviour on a per-element basis and compose these small learning units together. However, combining and composing learned behaviours from different elements is challenging and requires domain knowledge. Therefore, there is a need to structure and combine the learned behaviours and domain knowledge together in a flexible way. In this paper we propose to weave machine learning into domain modeling. More specifically, we suggest to decompose machine learning into reusable, chainable, and independently computable small learning units, which we refer to as micro learning units. These micro learning units are modeled together with and at the same level as the domain data. We show, based on a smart grid case study, that our approach can be significantly more accurate than learning a global behaviour while the performance is fast enough to be used for live learning.},
author = {Hartmann, Thomas and Moawad, Assaad and Fouquet, Francois and {Le Traon}, Yves},
booktitle = {Proceedings - ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems, MODELS 2017},
doi = {10.1109/MODELS.2017.32},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hartmann2019_Article_TheNextEvolutionOfMDEASeamless.pdf:pdf},
isbn = {9781538634929},
keywords = {Cyber-physical systems,Domain modeling,Live learning,Meta modeling,Model-driven engineering,Smart grids},
month = {nov},
pages = {180},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The Next Evolution of MDE: A Seamless Integration of Machine Learning into Domain Modeling}},
year = {2017}
}
@techreport{Fulton2018,
abstract = {Formal verification provides a high degree of confidence in safe system operation, but only if reality matches the verified model. Although a good model will be accurate most of the time, even the best models are incomplete. This is especially true in Cyber-Physical Systems because high-fidelity physical models of systems are expensive to develop and often intractable to verify. Conversely, reinforcement learning-based controllers are lauded for their flexibility in unmodeled environments , but do not provide guarantees of safe operation. This paper presents an approach for provably safe learning that provides the best of both worlds: the exploration and optimization capabilities of learning along with the safety guarantees of formal verification. Our main insight is that formal verification combined with verified runtime monitoring can ensure the safety of a learning agent. Verification results are preserved whenever learning agents limit exploration within the confounds of verified control choices as long as observed reality comports with the model used for off-line verification. When a model violation is detected, the agent abandons efficiency and instead attempts to learn a control strategy that guides the agent to a modeled portion of the state space. We prove that our approach toward incorporating knowledge about safe control into learning systems preserves safety guarantees, and demonstrate that we retain the empirical performance benefits provided by reinforcement learning. We also explore various points in the design space for these justified speculative controllers in a simple model of adaptive cruise control model for autonomous cars.},
author = {Fulton, Nathan and Platzer, Andr{\'{e}}},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fulton, Platzer - 2018 - Safe Reinforcement Learning via Formal Methods Toward Safe Control Through Proof and Learning.pdf:pdf},
keywords = {Robotics Track},
title = {{Safe Reinforcement Learning via Formal Methods: Toward Safe Control Through Proof and Learning}},
url = {www.aaai.org},
year = {2018}
}
@techreport{Serban2020,
abstract = {Deep reinforcement learning has recently shown many impressive successes. However, one major obstacle towards applying such methods to real-world problems is their lack of data-efficiency. To this end, we propose the Bottleneck Simulator: a model-based reinforcement learning method which combines a learned, factorized transition model of the environment with rollout simulations to learn an effective policy from few examples. The learned transition model employs an abstract, discrete (bottleneck) state, which increases sample efficiency by reducing the number of model parameters and by exploiting structural properties of the environment. We provide a mathematical analysis of the Bottleneck Simulator in terms of fixed points of the learned policy, which reveals how performance is affected by four distinct sources of error: an error related to the abstract space structure, an error related to the transition model estimation variance, an error related to the transition model estimation bias, and an error related to the transition model class bias. Finally, we evaluate the Bottleneck Simulator on two natural language processing tasks: a text adventure game and a real-world, complex dialogue response selection task. On both tasks, the Bottleneck Simulator yields excellent performance beating competing approaches.},
author = {Serban, Iulian Vlad and Sankar, Chinnadhurai and Pieper, Michael and Montreal, Polytechnique Montreal and Pineau, Canada Joelle and Bengio, Yoshua},
booktitle = {Journal of Artificial Intelligence Research},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Serban et al. - 2020 - The Bottleneck Simulator A Model-Based Deep Reinforcement Learning Approach.pdf:pdf},
pages = {571--612},
title = {{The Bottleneck Simulator: A Model-Based Deep Reinforcement Learning Approach}},
volume = {69},
year = {2020}
}
@article{Macrae2019,
author = {Macrae, Carl},
doi = {10.1136/bmjqs-2019-009484},
issn = {20445415},
journal = {BMJ Quality and Safety},
keywords = {governance,information technology,risk management},
month = {jun},
number = {6},
pages = {495--498},
pmid = {30979783},
publisher = {BMJ Publishing Group},
title = {{Governing the safety of artificial intelligence in healthcare}},
url = {https://qualitysafety.bmj.com/lookup/doi/10.1136/bmjqs-2019-009484},
volume = {28},
year = {2019}
}
@article{Kuwajima2020a,
abstract = {Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that employ machine learning and deep learning models, such as automated driving vehicles. In order to use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system through engineering processes. However, thus far, no such widely accepted engineering concepts or frameworks have been established for these systems. The key to using a machine learning model in a deductively engineered system is decomposing the data-driven training of machine learning models into requirement, design, and verification, particularly for machine learning models used in safety-critical systems. Simultaneously, open problems and relevant technical fields are not organized in a manner that enables researchers to select a theme and work on it. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems—that is, in terms of requirement, design, and verification of machine learning models and systems—as well as discuss related works and research directions, using automated driving vehicles as an example. Our results show that machine learning models are characterized by a lack of requirements specification, lack of design specification, lack of interpretability, and lack of robustness. We also perform a gap analysis on a conventional system quality standard SQuaRE with the characteristics of machine learning models to study quality models for machine learning systems. We find that a lack of requirements specification and lack of robustness have the greatest impact on conventional quality models.},
archivePrefix = {arXiv},
arxivId = {1904.00001},
author = {Kuwajima, Hiroshi and Yasuoka, Hirotoshi and Nakae, Toshihiro},
doi = {10.1007/s10994-020-05872-w},
eprint = {1904.00001},
issn = {15730565},
journal = {Machine Learning},
keywords = {Automated driving,Machine learning,Quality models,Safety critical systems,Software engineering,Systems engineering},
month = {may},
number = {5},
pages = {1103--1126},
publisher = {Springer},
title = {{Engineering problems in machine learning systems}},
url = {https://doi.org/10.1007/s10994-020-05872-w},
volume = {109},
year = {2020}
}
@article{Combemale2020,
author = {Combemale, Benoit and Kienzle, J{\"{o}}rg and Mussbacher, Gunter and Ali, Hyacinth and Amyot, Daniel and Bagherzadeh, Mojtaba and Batot, Edouard and Bencomo, Nelly and Benni, Benjamin and Bruel, Jean-Michel and Cabot, Jordi and Cheng, Betty H C and Collet, Philippe and Engels, Gregor and Heinrich, Robert and J{\'{e}}z{\'{e}}quel, Jean-Marc and Koziolek, Anne and Reussner, Ralf and Sahraoui, Houari and Saini, Rijul and Sallou, June and Stinckwich, Serge and Syriani, Eugene and Wimmer, Manuel},
doi = {10.1109/MS.2020.2995125ï},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Combemale et al. - 2020 - A Hitchhiker's Guide to Model-Driven Engineering for Data-Centric Systems.pdf:pdf},
pages = {1--9},
title = {{A Hitchhiker's Guide to Model-Driven Engineering for Data-Centric Systems }},
url = {https://hal.inria.fr/hal-02612087},
year = {2020}
}
@techreport{,
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Proposed Regulatory Framework for Modifications to Artificial IntelligenceMachine Learning (AIML)-Based Software as.pdf:pdf},
title = {{Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD)-Discussion Paper and Request for Feedback}},
url = {https://www.fda.gov/downloads/medicaldevices/deviceregulationandguidance/guidancedocuments/ucm514737.pdf.}
}
@article{Arcos-Garcia2018,
abstract = {This paper presents a Deep Learning approach for traffic sign recognition systems. Several classification experiments are conducted over publicly available traffic sign datasets from Germany and Belgium using a Deep Neural Network which comprises Convolutional layers and Spatial Transformer Networks. Such trials are built to measure the impact of diverse factors with the end goal of designing a Convolutional Neural Network that can improve the state-of-the-art of traffic sign classification task. First, different adaptive and non-adaptive stochastic gradient descent optimisation algorithms such as SGD, SGD-Nesterov, RMSprop and Adam are evaluated. Subsequently, multiple combinations of Spatial Transformer Networks placed at distinct positions within the main neural network are analysed. The recognition rate of the proposed Convolutional Neural Network reports an accuracy of 99.71% in the German Traffic Sign Recognition Benchmark, outperforming previous state-of-the-art methods and also being more efficient in terms of memory requirements.},
author = {Arcos-Garc{\'{i}}a, {\'{A}}lvaro and {\'{A}}lvarez-Garc{\'{i}}a, Juan A. and Soria-Morillo, Luis M.},
doi = {10.1016/j.neunet.2018.01.005},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Arcos-Garc{\'{i}}a, {\'{A}}lvarez-Garc{\'{i}}a, Soria-Morillo - 2018 - Deep neural network for traffic sign recognition systems An analysis of spatial tra.pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Convolutional neural network,Deep learning,Spatial transformer network,Traffic sign},
title = {{Deep neural network for traffic sign recognition systems: An analysis of spatial transformers and stochastic optimisation methods}},
year = {2018}
}
@misc{Challen2019,
abstract = {In medicine, artificial intelligence (AI) research is becoming increasingly focused on applying machine learning (ML) techniques to complex problems, and so allowing computers to make predictions from large amounts of patient data, by learning their own associations.1 Estimates of the impact of AI on the wider economy globally vary wildly, with a recent report suggesting a 14% effect on global gross domestic product by 2030, half of which coming from productivity improvements.2 These predictions create political appetite for the rapid development of the AI industry,3 and healthcare is a priority area where this technology has yet to be exploited.2 3 The digital health revolution described by Duggal et al 4 is already in full swing with the potential to ‘disrupt' healthcare. Health AI research has demonstrated some impressive results,5–10 but its clinical value has not yet been realised, hindered partly by a lack of a clear understanding of how to quantify benefit or ensure patient safety, and increasing concerns about the ethical and medico-legal impact.11 

This analysis is written with the dual aim of helping clinical safety professionals to critically appraise current medical AI research from a quality and safety perspective, and supporting research and development in AI by highlighting some of the clinical safety questions that must be considered if medical application of these exciting technologies is to be successful.

Clinical decision support systems (DSS) are in widespread use in medicine and have had most impact providing guidance on the safe prescription of medicines,12 guideline adherence, simple risk screening13 or prognostic scoring.14 These systems use predefined rules, which have predictable behaviour and are usually shown to reduce clinical error,12 although sometimes inadvertently introduce safety issues themselves.15 16 Rules-based systems have also been developed to address diagnostic uncertainty17–19 {\ldots}},
author = {Challen, Robert and Denny, Joshua and Pitt, Martin and Gompels, Luke and Edwards, Tom and Tsaneva-Atanasova, Krasimira},
booktitle = {BMJ Quality and Safety},
doi = {10.1136/bmjqs-2018-008370},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Challen et al. - 2019 - Artificial intelligence, bias and clinical safety.pdf:pdf;:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Challen et al. - 2019 - Artificial intelligence, bias and clinical safety(2).pdf:pdf},
issn = {20445415},
keywords = {artificial intelligence,clinical decision support systems,clinical safety,machine learning},
month = {mar},
number = {3},
pages = {231--237},
pmid = {30636200},
publisher = {BMJ Publishing Group},
title = {{Artificial intelligence, bias and clinical safety}},
url = {https://qualitysafety.bmj.com/lookup/doi/10.1136/bmjqs-2018-008370 http://qualitysafety.bmj.com/},
volume = {28},
year = {2019}
}
@inproceedings{Hartmann2019,
abstract = {Although artificial intelligence and machine learning are currently extremely fashionable, applying machine learning on real-life problems remains very challenging. Data scientists need to evaluate various learning algorithms and tune their numerous parameters, based on their assumptions and experience, against concrete problems and training data sets. This is a long, tedious, and resource expensive task. Meta-learning is a recent technique to overcome, i.e. automate this problem. It aims at using machine learning itself to automatically learn the most appropriate algorithms and parameters for a machine learning problem. As it turns out, there are many parallels between meta-modelling - in the sense of model-driven engineering - and meta-learning. Both rely on abstractions, the meta data, to model a predefined class of problems and to define the variabilities of the models conforming to this definition. Both are used to define the output and input relationships and then fitting the right models to represent that behaviour. In this paper, we envision how a meta-model for meta-learning can look like. We discuss possible variabilities, for what types of learning it could be appropriate for, how concrete learning models can be generated from it, and how models can be finally selected. Last but not least, we discuss a possible integration into existing modelling tools.},
author = {Hartmann, Thomas and Moawad, Assaad and Schockaert, Cedric and Fouquet, Francois and {Le Traon}, Yves},
booktitle = {Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems, MODELS 2019},
doi = {10.1109/MODELS.2019.00014},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Meta-Modelling Meta-Learning.pdf:pdf},
isbn = {9781728125350},
keywords = {AutoML,meta-learning,meta-modelling,modelling framework},
month = {sep},
pages = {300--305},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Meta-Modelling Meta-Learning}},
year = {2019}
}
@techreport{Agrawal2019,
abstract = {TensorFlow Eager is a multi-stage, Python-embedded domain-specific language for hardware-accelerated machine learning, suitable for both interactive research and production. TensorFlow, which TensorFlow Eager extends, requires users to represent computations as dataflow graphs; this permits compiler optimizations and simplifies deployment but hinders rapid prototyping and run-time dynamism. TensorFlow Eager eliminates these usability costs without sacrificing the benefits furnished by graphs: It provides an imperative front-end to TensorFlow that executes operations immediately and a JIT tracer that translates Python functions composed of TensorFlow operations into executable dataflow graphs. TensorFlow Eager thus offers a multi-stage programming model that makes it easy to interpolate between imperative and staged execution in a single package.},
archivePrefix = {arXiv},
arxivId = {1903.01855v1},
author = {Agrawal, Akshay and Modi, Akshay Naresh and Passos, Alexandre and Lavoie, Allen and Agarwal, Ashish and Shankar, Asim and Ganichev, Igor and Levenberg, Josh and Hong, Mingsheng and Monga, Rajat and Cai, Shanqing},
eprint = {1903.01855v1},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Agrawal et al. - 2019 - TENSORFLOW EAGER A MULTI-STAGE, PYTHON-EMBEDDED DSL FOR MACHINE LEARNING.pdf:pdf},
title = {{TENSORFLOW EAGER: A MULTI-STAGE, PYTHON-EMBEDDED DSL FOR MACHINE LEARNING}},
year = {2019}
}
@techreport{BeziersLaFosse2018,
abstract = {Energy consumption is a critical point when developing applications. Either for battery-saving purposes, for lowering the cost of data-centers, or simply for the sake of having an eco-friendly program, reducing the energy needed to run a software becomes mandatory. Model-Driven Engineering has shown great results when it comes to program understanding and refactoring. Modeling the source code along with its energy consumption could be a powerful asset to programmers in order to develop greener code. For that purpose, this paper presents an approach for modeling energy consumption inside a source code model. Energy metrics are gathered at runtime, modeled using the standard Structured Metrics Meta-model, and associated to the source code model, enabling model-driven techniques for energy analysis and optimizations.},
author = {{B{\'{e}}ziers La Fosse}, Thibault and Mottu, Jean-Marie and Tisi, Massimo and Suny{\'{e}}, Gerson and {B{\'{e}}ziers la Fosse}, Thibault and Rocheteau, J{\'{e}}r{\^{o}}me},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/B{\'{e}}ziers La Fosse et al. - 2018 - Characterizing a Source Code Model with Energy Measurements Characterizing a Source Code Model with Ene.pdf:pdf},
title = {{Characterizing a Source Code Model with Energy Measurements Characterizing a Source Code Model with Energy Measurements. Workshop on Measurement and Metrics for Green and Sustainable Software Systems ( Characterizing a Source Code Model with Energy Measur}},
url = {https://asm.ow2.io/},
year = {2018}
}
@inproceedings{Abadib,
abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production , we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that Tensor-Flow achieves for several real-world applications.},
author = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang and Brain, Google},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - Unknown - This paper is included in the Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implemen.pdf:pdf},
isbn = {978-1-931971-33-1},
title = {{TensorFlow: A System for Large-Scale Machine Learning TensorFlow: A system for large-scale machine learning}},
url = {https://tensorflow.org.}
}
@article{Wolny2018,
abstract = {Tackling the challenge of managing the full life-cycle of systems requires a well-defined mix of approaches. While in the early phases model-driven approaches are frequently used to design systems, in the later phases data-driven approaches are used to reason on different key performance indicators of systems under operation. This immediately poses the question how operational data can be mapped back to design models to evaluate existing designs and to reason about future redesigns. In this paper, we present a novel approach for harmonizing model-driven and data-driven approaches. In particular, we introduce an architecture for time-series data management to analyse runtime properties of systems which is derived from design models. Having this systematic generation of time-series data management opens the door to analyse data through design models. We show how such data analytics is specified for modelling languages using standard metamodelling techniques and technologies.},
author = {Wolny, Sabine and Mazak, Alexandra and Wimmer, Manuel and Konlechner, Rafael and Kappel, Gerti},
doi = {10.18417/emisa.si.hcm.19},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolny et al. - 2018 - Model-Driven Time-Series Analytics.pdf:pdf},
journal = {International Journal of Conceptual},
keywords = {Data Analytics,Language Engineering,Model-Driven Engineering,Time-Series},
month = {feb},
pages = {252--261},
title = {{Model-Driven Time-Series Analytics}},
url = {http://json.org/example.html},
volume = {13},
year = {2018}
}
@inproceedings{Basciani2016,
abstract = {Over the last years, several model repositories have been proposed in response to the need of the MDE community for advanced systems supporting the reuse of modeling artifacts. Modelers can interact with MDE repositories with different intents ranging from merely repository browsing, to searching specific artifacts satisfying precise requirements. The organization and browsing facilities provided by current repositories is limited since they do not produce structured overviews of the contained artifacts, and the ategorization mechanisms (if any) are based on manual activities. When dealing with large numbers of modeling artifacts, such limitations increase the effort for managing and reusing artifacts stored in model repositories. By focusing on metamodel repositories, in this paper we propose the application of clustering techniques to automatically organize stored metamodels and to provide users with overviews of the application domains covered by the available metamodels. The approach has been implemented in the MDEForge repository.},
author = {Basciani, Francesco and Rocco, Juri Di and Ruscio, Davide Di and Iovino, Ludovico and Pierantonio, Alfonso},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-39696-5_21},
isbn = {9783319396958},
issn = {16113349},
keywords = {MDEForge,Metamodel clustering,Model Driven Engineering,Model repositories},
pages = {342--358},
publisher = {Springer Verlag},
title = {{Automated clustering of metamodel repositories}},
volume = {9694},
year = {2016}
}
@article{KhadjehNassirtoussi2015,
abstract = {In this paper a novel approach is proposed to predict intraday directional-movements of a currency-pair in the foreign exchange market based on the text of breaking financial news-headlines. The motivation behind this work is twofold: First, although market-prediction through text-mining is shown to be a promising area of work in the literature, the text-mining approaches utilized in it at this stage are not much beyond basic ones as it is still an emerging field. This work is an effort to put more emphasis on the text-mining methods and tackle some specific aspects thereof that are weak in previous works, namely: the problem of high dimensionality as well as the problem of ignoring sentiment and semantics in dealing with textual language. This research assumes that addressing these aspects of text-mining have an impact on the quality of the achieved results. The proposed system proves this assumption to be right. The second part of the motivation is to research a specific market, namely, the foreign exchange market, which seems not to have been researched in the previous works based on predictive text-mining. Therefore, results of this work also successfully demonstrate a predictive relationship between this specific market-type and the textual data of news. Besides the above two main components of the motivation, there are other specific aspects that make the setup of the proposed system and the conducted experiment unique, for example, the use of news article-headlines only and not news article-bodies, which enables usage of short pieces of text rather than long ones; or the use of general financial breaking news without any further filtration. In order to accomplish the above, this work produces a multi-layer algorithm that tackles each of the mentioned aspects of the text-mining problem at a designated layer. The first layer is termed the Semantic Abstraction Layer and addresses the problem of co-reference in text mining that is contributing to sparsity. Co-reference occurs when two or more words in a text corpus refer to the same concept. This work produces a custom approach by the name of Heuristic-Hypernyms Feature-Selection which creates a way to recognize words with the same parent-word to be regarded as one entity. As a result, prediction accuracy increases significantly at this layer which is attributed to appropriate noise-reduction from the feature-space. The second layer is termed Sentiment Integration Layer, which integrates sentiment analysis capability into the algorithm by proposing a sentiment weight by the name of SumScore that reflects investors' sentiment. Additionally, this layer reduces the dimensions by eliminating those that are of zero value in terms of sentiment and thereby improves prediction accuracy. The third layer encompasses a dynamic model creation algorithm, termed Synchronous Targeted Feature Reduction (STFR). It is suitable for the challenge at hand whereby the mining of a stream of text is concerned. It updates the models with the most recent information available and, more importantly, it ensures that the dimensions are reduced to the absolute minimum. The algorithm and each of its layers are extensively evaluated using real market data and news content across multiple years and have proven to be solid and superior to any other comparable solution. The proposed techniques implemented in the system, result in significantly high directional-accuracies of up to 83.33%. On top of a well-rounded multifaceted algorithm, this work contributes a much needed research framework for this context with a test-bed of data that must make future research endeavors more convenient. The produced algorithm is scalable and its modular design allows improvement in each of its layers in future research. This paper provides ample details to reproduce the entire system and the conducted experiments. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {{Khadjeh Nassirtoussi}, Arman and Aghabozorgi, Saeed and {Ying Wah}, Teh and Ngo, David Chek Ling},
doi = {10.1016/j.eswa.2014.08.004},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Khadjeh Nassirtoussi et al. - 2015 - Text mining of news-headlines for FOREX market prediction A Multi-layer Dimension Reduction Algorit.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {FOREX prediction,Market prediction,Market sentiment analysis,News mining,News semantic analysis},
title = {{Text mining of news-headlines for FOREX market prediction: A Multi-layer Dimension Reduction Algorithm with semantics and sentiment}},
year = {2015}
}
@article{Moin,
abstract = {In this paper, we present the current position of the research project ML-Quadrat, which aims to extend the methodology, modeling language and tool support of ThingML-an open source modeling tool for IoT/CPS-to address Machine Learning needs for the IoT applications. Currently, ThingML offers a modeling language and tool support for modeling the components of the system, their communication interfaces as well as their behaviors. The latter is done through state machines. However, we argue that in many cases IoT/CPS services involve system components and physical processes, whose behaviors are not well understood in order to be modeled using state machines. Hence, quite often a data-driven approach that enables inference based on the observed data, e.g., using Machine Learning is preferred. To this aim, ML-Quadrat integrates the necessary Machine Learning concepts into ThingML both on the modeling level (syntax and semantics of the modeling language) and on the code generators level. We plan to support two target platforms for code generation regarding Stream Processing and Complex Event Processing, namely Apache SAMOA and Apama.},
author = {Moin, Armin and R{\"{o}}ssler, Stephan and G{\"{u}}nnemann, Stephan},
doi = {10.1016/j},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moin, R{\"{o}}ssler, G{\"{u}}nnemann - Unknown - Augmenting Model-Driven Software Engineering for the Internet of Things with Machine Learning.pdf:pdf},
title = {{Augmenting Model-Driven Software Engineering for the Internet of Things with Machine Learning}},
url = {https://doi.org/10.1016/j.}
}
@article{Hendrycks2019,
abstract = {In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.},
archivePrefix = {arXiv},
arxivId = {1903.12261},
author = {Hendrycks, Dan and Dietterich, Thomas},
eprint = {1903.12261},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hendrycks, Dietterich - 2019 - Benchmarking Neural Network Robustness to Common Corruptions and Perturbations.pdf:pdf},
journal = {arXiv},
month = {mar},
publisher = {arXiv},
title = {{Benchmarking Neural Network Robustness to Common Corruptions and Perturbations}},
url = {http://arxiv.org/abs/1903.12261},
year = {2019}
}
@techreport{EllDocu,
abstract = {We present VERIFAI, a software toolkit for the formal design and analysis of systems that include artificial intelligence (AI) and machine learning (ML) components. VERIFAI particularly addresses challenges with applying formal methods to ML components such as perception systems based on deep neural networks, as well as systems containing them, and to model and analyze system behavior in the presence of environment uncertainty. We describe the initial version of VERIFAI, which centers on simulation-based verification and synthesis, guided by formal models and specifications. We give examples of several use cases, including temporal-logic falsification, model-based systematic fuzz testing , parameter synthesis, counterexample analysis, and data set augmentation.},
author = {{Ell Docu}, W and Dreossi, Tommaso and Fremont, Daniel J and Ghosh, Shromona and Kim, Edward and Ravanbakhsh, Hadi and Vazquez-Chanlatte, Marcell and Seshia, Sanjit A},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ell Docu et al. - Unknown - Con sis te n t Comple te VERIFAI A Toolkit for the Formal Design and Analysis of Artificial Intelligence-Ba.pdf:pdf},
keywords = {Artificial,Autonomous,Cyber-,Falsification {\textperiodcentered},Formal,Intelligence {\textperiodcentered},Learning {\textperiodcentered},Machine,Methods {\textperiodcentered},Physical,Simulation {\textperiodcentered},Sys-tems {\textperiodcentered},Vehicles},
title = {{Con sis te n t * Comple te VERIFAI: A Toolkit for the Formal Design and Analysis of Artificial Intelligence-Based Systems}}
}
@inproceedings{Perez-Soler2020,
abstract = {Conversational interfaces (also called chatbots) are being increasingly adopted in various domains such as e-commerce or customer service, as a direct communication channel between companies and end-users. Their advantage is that they can be embedded within social networks, and provide a natural language (NL) interface that enables their use by non-technical users. While there are many emerging platforms for building chatbots, their construction remains a highly technical, challenging task. In this paper, we propose the use of chatbots to facilitate querying domain-specific models. This way, instead of relying on technical query languages (e.g., OCL), models are queried using NL as this can be more suitable for non-technical users. To avoid manual programming, our solution is based on the automatic synthesis of the model query chatbots from a domain meta-model. These chatbots communicate with an EMF-based modelling backend using the Xatkit framework.},
author = {P{\'{e}}rez-Soler, Sara and Daniel, Gwendal and Cabot, Jordi and Guerra, Esther and de Lara, Juan},
booktitle = {Lecture Notes in Business Information Processing},
doi = {10.1007/978-3-030-49418-6_17},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/P{\'{e}}rez-Soler et al. - 2020 - Towards automating the synthesis of chatbots for conversational model query.pdf:pdf},
isbn = {9783030494179},
issn = {18651356},
keywords = {Automatic chatbot synthesis,Model query,Model-driven engineering},
month = {jun},
pages = {257--265},
publisher = {Springer},
title = {{Towards automating the synthesis of chatbots for conversational model query}},
url = {https://doi.org/10.1007/978-3-030-49418-6_17},
volume = {387 LNBIP},
year = {2020}
}
@inproceedings{Hoser2019,
abstract = {The implementation of intelligent agents in industrial applications is often prevented by the high cost of adopting such a system to a particular problem domain. This paper states the thesis that when learning agents are applied to work environments that require domain-specific experience, the agent benefits if it can be further adapted by a supervising domain expert. Closely interacting with the agent, a domain expert should be able to understand its decisions and update the underlying knowledge base as needed. The result would be an agent with individualized knowledge that comes in part from the domain experts. The model of such an adaptive learning agent must take into account the problem domain, the design of the learning agent and the perception of the domain user. Therefore, already in the modeling phase, more attention must be paid to make the learning element of the agent adaptable by an operator. Domain modeling and meta-modeling methods could help to make inner processes of the agent more accessible. In addition, the knowledge gained should be made reusable for future agents in similar environments. To begin with, the existing methods for modeling agent systems and the underlying concepts will be evaluated, based on the requirements for different industrial scenarios. The methods are then compiled into a framework that allows for the description and modeling of such systems in terms of adaptability to a problem domain. Where necessary, new methods or tools will be introduced to close the gap between inconsistent modeling artifacts. The framework shall then be used to build learning agents for real-life scenarios and observe their application in a case study. The results will be used to assess the quality of the adapted knowledge base and compare it to a manual knowledge modeling process.},
author = {Hoser, Moritz},
booktitle = {Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019},
doi = {10.1109/MODELS-C.2019.00101},
isbn = {9781728151250},
keywords = {Adaptive Learning Agents,Domain modeling,Knowledge Engineering,Multi-modeling},
month = {sep},
pages = {660--665},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Modeling adaptive learning agents for domain knowledge transfer}},
year = {2019}
}
@misc{,
title = {{The MODA framework: Model-Driven Engineering for Data-Centric Systems}},
url = {https://modeling-languages.com/a-hitchhikers-guide-to-model-driven-engineering-for-data-centric-systems/},
urldate = {2021-03-09}
}
@book{,
booktitle = {Safety of the Intended Functionality Book 3 - Automated Vehicle Safety},
doi = {10.4271/9780768002683},
month = {mar},
publisher = {SAE International},
title = {{Safety of the Intended Functionality Book 3 - Automated Vehicle Safety}},
year = {2019}
}
@inproceedings{Burgueno2019,
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations - which we call MDE Intelligence - can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE - for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline. To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
author = {Burgueno, Loli and Burdusel, Alexandru and Gerard, Sebastien and Wimmer, Manuel},
booktitle = {Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019},
doi = {10.1109/MODELS-C.2019.00028},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Preface to MDE Intelligence 2019.pdf:pdf},
isbn = {9781728151250},
keywords = {Artificial Intelligence,MDE,MDE Intelligence},
month = {sep},
pages = {168--169},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Preface to MDE intelligence 2019: 1st workshop on artificial intelligence and model-driven engineering}},
year = {2019}
}
@misc{,
title = {{The MODA framework: Model-Driven Engineering for Data-Centric Systems}},
url = {https://modeling-languages.com/a-hitchhikers-guide-to-model-driven-engineering-for-data-centric-systems/},
urldate = {2020-05-25}
}
@techreport{Amodei,
abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
archivePrefix = {arXiv},
arxivId = {1606.06565v2},
author = {Amodei, Dario and Olah, Chris and Brain, Google and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Dan, Openai and {Google Brain}, Man{\'{e}}},
eprint = {1606.06565v2},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Amodei et al. - Unknown - Concrete Problems in AI Safety.pdf:pdf},
title = {{Concrete Problems in AI Safety}}
}
@article{Berk2015,
author = {Berk, Richard and Hyatt, Jordan},
doi = {10.1525/fsr.2015.27.4.222},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berk, Hyatt - 2015 - Machine Learning Forecasts of Risk to Inform Sentencing Decisions.pdf:pdf},
journal = {Source: Federal Sentencing Reporter},
number = {4},
pages = {222--228},
title = {{Machine Learning Forecasts of Risk to Inform Sentencing Decisions}},
volume = {27},
year = {2015}
}
@techreport{Foster2014,
abstract = {A large number of papers are appearing in the biomedical engineering literature that describe the use of machine learning techniques to develop classifiers for detection or diagnosis of disease. However, the usefulness of this approach in developing clinically validated diagnostic techniques so far has been limited and the methods are prone to overfitting and other problems which may not be immediately apparent to the investigators. This commentary is intended to help sensitize investigators as well as readers and reviewers of papers to some potential pitfalls in the development of classifiers, and suggests steps that researchers can take to help avoid these problems. Building classifiers should be viewed not simply as an add-on statistical analysis, but as part and parcel of the experimental process. Validation of classifiers for diagnostic applications should be considered as part of a much larger process of establishing the clinical validity of the diagnostic technique.},
author = {Foster, Kenneth R and Koprowski, Robert and Skufca, Joseph D},
doi = {10.1186/1475-925X-13-94},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Foster, Koprowski, Skufca - 2014 - Machine learning, medical diagnosis, and biomedical engineering research-commentary.pdf:pdf},
keywords = {Artificial intelligence,Classifiers,Image processing,Machine learning,Support vector machine},
title = {{Machine learning, medical diagnosis, and biomedical engineering research-commentary}},
url = {http://www.biomedical-engineering-online.com/content/13/1/94},
year = {2014}
}
@article{Macrae2019a,
abstract = {Artificial intelligence (AI) has enormous potential to improve the safety of healthcare, from increasing diagnostic accuracy,1 to optimising treatment planning,2 to forecasting outcomes of care.3 However, integrating AI technologies into the delivery of healthcare is likely to introduce a range of new risks and amplify existing ones. For instance, failures in widely used software have the potential to quickly affect large numbers of patients4; hidden assumptions in underlying data and models can lead to AI systems delivering dangerous recommendations that are insensitive to local care processes,5 6 and opaque AI techniques such as deep learning can make explaining and learning from failure extremely difficult.7 8 To maximise the benefits of AI in healthcare and to build trust among patients and practitioners, it will therefore be essential to robustly govern the risks that AI poses to patient safety.

In a recent review in this journal, Challen and colleagues present an important and timely analysis of some of the key technological risks associated with the application of machine learning in clinical settings.9 Machine learning is a subfield of AI that focuses on the development of algorithms that are automatically derived and optimised through exposure to large quantities of exemplar ‘training' data.10 The outputs of machine learning algorithms are essentially classifications of patterns that provide some sort of prediction—for instance, predicting whether an image shows a malignant melanoma or a benign mole.11 Some of the basic techniques of machine learning have existed for half a century or more, but progress in the field has accelerated rapidly due to advances in the development of ‘deep' artificial neural networks12 combined with huge increases in computational power and the availability of enormous quantities of data. These techniques have underpinned recent public demonstrations of AI systems {\ldots}},
author = {Macrae, Carl},
doi = {10.1136/bmjqs-2019-009484},
issn = {20445415},
journal = {BMJ Quality and Safety},
keywords = {governance,information technology,risk management},
month = {jun},
number = {6},
pages = {495--498},
pmid = {30979783},
publisher = {BMJ Publishing Group},
title = {{Governing the safety of artificial intelligence in healthcare}},
url = {https://qualitysafety.bmj.com/content/28/6/495 https://qualitysafety.bmj.com/content/28/6/495.abstract},
volume = {28},
year = {2019}
}
@article{Ashmore2021,
abstract = {<p> Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the <italic>assurance of ML</italic> , i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the <italic>machine learning lifecycle</italic> , i.e., of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research. </p>},
author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
doi = {10.1145/3453444},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashmore, Calinescu, Paterson - 2021 - Assuring the Machine Learning Lifecycle.pdf:pdf},
issn = {0360-0300},
journal = {ACM Computing Surveys},
keywords = {Additional Key Words and Phrases: Machine learning,CCS Concepts: • Computing methodologies → Machine,Model verification and validation,• General and reference → Surveys and overviews},
month = {may},
number = {5},
pages = {1--39},
publisher = {
		ACM
		PUB27
		New York, NY, USA
	},
title = {{Assuring the Machine Learning Lifecycle}},
url = {https://dl.acm.org/doi/10.1145/3453444},
volume = {54},
year = {2021}
}
@techreport{Boehm2000,
author = {Boehm, Barry and Hansen, Wilfred J},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boehm, Hansen - 2000 - Spiral Development Experience, Principles, and Refinements Spiral Development Workshop February 9, 2000.pdf:pdf},
keywords = {anchor point milestones,cyclic phases,invariant,iterative process,project management,risk management,software development,spiral development model,variant},
title = {{Spiral Development: Experience, Principles, and Refinements  Spiral Development Workshop February 9, 2000}},
year = {2000}
}
@techreport{Omg2010,
author = {Omg},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Omg - 2010 - An OMG{\textregistered} Structured Assurance Case Metamodel TM Publication Structured Assurance Case Metamodel (SACM) Version 2.1 OMG Docum.pdf:pdf},
title = {{An OMG{\textregistered} Structured Assurance Case Metamodel TM Publication Structured Assurance Case Metamodel (SACM) Version 2.1 OMG Document Number Release Date}},
url = {https://www.omg.org/spec/SACM/2.1/PDF},
year = {2010}
}
@inproceedings{Bloomfield2010,
abstract = {This paper focuses on the approaches used in safety cases for software based systems. We outline the history of approaches for assuring the safety of software-based systems, the current uptake of safety and assurance cases and the current practice on structured safety cases. Directions for further development are discussed. {\textcopyright} Springer-Verlag London Limited 2010.},
author = {Bloomfield, Robin and Bishop, Peter},
booktitle = {Making Systems Safer - Proceedings of the 18th Safety-Critical Systems Symposium, SSS 2010},
doi = {10.1007/978-1-84996-086-1_4},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bloomfield, Bishop - 2010 - Safety and assurance cases Past, present and possible future - An adelard perspective.pdf:pdf},
isbn = {9781849960854},
pages = {51--67},
publisher = {Springer London},
title = {{Safety and assurance cases: Past, present and possible future - An adelard perspective}},
year = {2010}
}
@article{Amodei2016,
abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
archivePrefix = {arXiv},
arxivId = {1606.06565},
author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'{e}}, Dan},
eprint = {1606.06565},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Amodei et al. - 2016 - Concrete Problems in AI Safety.pdf:pdf},
month = {jun},
title = {{Concrete Problems in AI Safety}},
url = {http://arxiv.org/abs/1606.06565},
year = {2016}
}
@article{Batarseh2021,
abstract = {Artificial Intelligence (AI) algorithms are increasingly providing decision making and operational support across multiple domains. AI includes a wide (and growing) library of algorithms that could be applied for different problems. One important notion for the adoption of AI algorithms into operational decision processes is the concept of assurance. The literature on assurance, unfortunately, conceals its outcomes within a tangled landscape of conflicting approaches, driven by contradicting motivations, assumptions, and intuitions. Accordingly, albeit a rising and novel area, this manuscript provides a systematic review of research works that are relevant to AI assurance, between years 1985 and 2021, and aims to provide a structured alternative to the landscape. A new AI assurance definition is adopted and presented, and assurance methods are contrasted and tabulated. Additionally, a ten-metric scoring system is developed and introduced to evaluate and compare existing methods. Lastly, in this manuscript, we provide foundational insights, discussions, future directions, a roadmap, and applicable recommendations for the development and deployment of AI assurance.},
author = {Batarseh, Feras A. and Freeman, Laura and Huang, Chih Hao},
doi = {10.1186/s40537-021-00445-7},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Batarseh, Freeman, Huang - 2021 - A survey on artificial intelligence assurance.pdf:pdf},
issn = {21961115},
journal = {Journal of Big Data},
keywords = {AI assurance,Data Engineering,Explainable AI (XAI),Validation and verification},
month = {dec},
number = {1},
pages = {1--30},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{A survey on artificial intelligence assurance}},
url = {https://doi.org/10.1186/s40537-021-00445-7},
volume = {8},
year = {2021}
}
@techreport{Abadia,
abstract = {TensorFlow [1] is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition , computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the Ten-sorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
archivePrefix = {arXiv},
arxivId = {1603.04467v2},
author = {Abadi, Mart{\'{i}}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man{\'{e}}, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vi{\'{e}}gas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang and Research, Google},
eprint = {1603.04467v2},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - Unknown - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems.pdf:pdf},
title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
url = {www.tensorflow.org.},
year = {2015}
}
@techreport{koopman2016challenges,
abstract = {Software testing is all too often simply a bug hunt rather than a well-considered exercise in ensuring quality. A more methodical approach than a simple cycle of system-level test-fail-patch-test will be required to deploy safe autonomous vehicles at scale. The ISO 26262 development V process sets up a framework that ties each type of testing to a corresponding design or requirement document, but presents challenges when adapted to deal with the sorts of novel testing problems that face autonomous vehicles. This paper identifies five major challenge areas in testing according to the V model for autonomous vehicles: driver out of the loop, complex requirements, non-deterministic algorithms, inductive learning algorithms, and fail-operational systems. General solution approaches that seem promising across these different challenge areas include: phased deployment using successively relaxed operational scenarios, use of a monitor/actuator pair architecture to separate the most complex autonomy functions from simpler safety functions, and fault injection as a way to perform more efficient edge case testing. While significant challenges remain in safety-certifying the type of algorithms that provide high-level autonomy themselves, it seems within reach to instead architect the system and its accompanying design process to be able to employ existing software safety approaches.},
author = {Koopman, Philip and Wagner, Michael},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Challenges in Autonomous Vehicle testing and validation.pdf:pdf},
pages = {15--24},
title = {{Challenges in Autonomous Vehicle Testing and Validation}},
year = {2016}
}
@techreport{Garcia2015,
abstract = {Safe Reinforcement Learning can be defined as the process of learning policies that maximize the expectation of the return in problems in which it is important to ensure reasonable system performance and/or respect safety constraints during the learning and/or deployment processes. We categorize and analyze two approaches of Safe Reinforcement Learning. The first is based on the modification of the optimality criterion, the classic discounted fi-nite/infinite horizon, with a safety factor. The second is based on the modification of the exploration process through the incorporation of external knowledge or the guidance of a risk metric. We use the proposed classification to survey the existing literature, as well as suggesting future directions for Safe Reinforcement Learning.},
author = {Garc{\'{i}}a, Javier and Fern{\'{a}}ndez, Fernando},
booktitle = {Journal of Machine Learning Research},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{i}}a, Fern{\'{a}}ndez - 2015 - A Comprehensive Survey on Safe Reinforcement Learning.pdf:pdf},
keywords = {reinforcement learning,risk sensitivity,safe exploration,teacher advice},
pages = {1437--1480},
title = {{A Comprehensive Survey on Safe Reinforcement Learning}},
volume = {16},
year = {2015}
}
@article{Birkenbihl2020,
abstract = {Artificial intelligence (AI) approaches pose a great opportunity for individualized, pre-symptomatic disease diagnosis which plays a key role in the context of personalized, predictive, and finally preventive medicine (PPPM). However, to translate PPPM into clinical practice, it is of utmost importance that AI-based models are carefully validated. The validation process comprises several steps, one of which is testing the model on patient-level data from an independent clinical cohort study. However, recruitment criteria can bias statistical analysis of cohort study data and impede model application beyond the training data. To evaluate whether and how data from independent clinical cohort studies differ from each other, this study systematically compares the datasets collected from two major dementia cohorts, namely, the Alzheimer's Disease Neuroimaging Initiative (ADNI) and AddNeuroMed. The presented comparison was conducted on individual feature level and revealed significant differences among both cohorts. Such systematic deviations can potentially hamper the generalizability of results which were based on a single cohort dataset. Despite identified differences, validation of a previously published, ADNI trained model for prediction of personalized dementia risk scores on 244 AddNeuroMed subjects was successful: External validation resulted in a high prediction performance of above 80% area under receiver operator characteristic curve up to 6 years before dementia diagnosis. Propensity score matching identified a subset of patients from AddNeuroMed, which showed significantly smaller demographic differences to ADNI. For these patients, an even higher prediction performance was achieved, which demonstrates the influence systematic differences between cohorts can have on validation results. In conclusion, this study exposes challenges in external validation of AI models on cohort study data and is one of the rare cases in the neurology field in which such external validation was performed. The presented model represents a proof of concept that reliable models for personalized predictive diagnostics are feasible, which, in turn, could lead to adequate disease prevention and hereby enable the PPPM paradigm in the dementia field.},
author = {Birkenbihl, Colin and Emon, Mohammad Asif and Vrooman, Henri and Westwood, Sarah and Lovestone, Simon and Hofmann-Apitius, Martin and Fr{\"{o}}hlich, Holger},
doi = {10.1007/s13167-020-00216-z},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Birkenbihl et al. - 2020 - Differences in cohort study data affect external validation of artificial intelligence models for predictive.pdf:pdf},
issn = {18785085},
journal = {EPMA Journal},
keywords = {Alzheimer's disease,Artificial intelligence,Bioinformatics,Cohort comparison,Cohort data,Data science,Dementia,Digital clinic,Disease modeling,Disease risk prediction,Health data,Individualized patient profiling,Interdisciplinary,Machine learning,Medical data,Model performance,Model validation,Multiprofessional,Neurodegeneration,Precision medicine,Predictive preventive personalized medicine (3 PM/,Propensity score matching,Risk modeling,Sampling bias,Survival analysis,Translational medicine},
month = {sep},
number = {3},
pages = {367--376},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Differences in cohort study data affect external validation of artificial intelligence models for predictive diagnostics of dementia - lessons for translation into clinical practice}},
url = {https://pubmed.ncbi.nlm.nih.gov/32843907/},
volume = {11},
year = {2020}
}
@techreport{Schwalbe2020,
abstract = {Methods for safety assurance suggested by the ISO 26262 automotive functional safety standard are not sufficient for applications based on machine learning (ML). We provide a structured, certification oriented overview on available methods supporting the safety argumen-tation of a ML based system. It is sorted into life-cycle phases, and maturity of the approach as well as applicability to different ML types are collected. From this we deduce current open challenges: powerful solvers, inclusion of expert knowledge, validation of data representativity and model diversity, and model introspection with provable guarantees.},
author = {Schwalbe, Gesina and Schels, Martin},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwalbe, Schels - 2020 - A Survey on Methods for the Safety Assurance of Machine Learning Based Systems A Survey on Methods for the (2).pdf:pdf},
keywords = {ISO 26262,explainable AI,functional safety,life-cycle,machine learning},
title = {{A Survey on Methods for the Safety Assurance of Machine Learning Based Systems A Survey on Methods for the Safety Assurance of Machine Learning Based Systems. 10th European Congress on Embedded Real Time Software and Systems (ERTS A Survey on Methods for }},
url = {https://hal.archives-ouvertes.fr/hal-02442819},
year = {2020}
}
@article{Tao2019,
abstract = {With the fast growth of artificial intelligence and big data computing technologies, more and more software service systems have been developed using diverse machine learning models and technologies to make business and intelligent decisions based on their multimedia input to achieve intelligent features, such as image recognition, recommendation, decision making, prediction, etc. Nevertheless, there are increasing quality problems resulting in erroneous testing costs in enterprises and businesses. Existing work seldom discusses how to perform testing and quality validation for AI software. This paper focuses on quality validation for AI software function features. The paper provides our understanding of AI software testing for new features and requirements. In addition, current AI software testing categories are presented and different testing approaches are discussed. Moreover, test quality assessment and criteria analysis are illustrated. Furthermore, a practical study on quality validation for an image recognition system is performed through a metamorphic testing method. Study results show the feasibility and effectiveness of the approach.},
author = {Tao, Chuanqi and Gao, Jerry and Wang, Tiexin},
doi = {10.1109/ACCESS.2019.2937107},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tao, Gao, Wang - 2019 - Testing and Quality Validation for AI Software-Perspectives, Issues, and Practices.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {AI software quality validation,AI testing,testing AI software},
pages = {120164--120175},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Testing and Quality Validation for AI Software-Perspectives, Issues, and Practices}},
volume = {7},
year = {2019}
}
@techreport{Alves2018,
author = {Alves, Erin and Bhatt, Devesh and Hall, Brendan and Driscoll, Kevin and Murugesan, Anitha and Rushby, John},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alves et al. - 2018 - Considerations in Assuring Safety of Increasingly Autonomous Systems Final Technical Report for NASA Project Assur.pdf:pdf},
title = {{Considerations in Assuring Safety of Increasingly Autonomous Systems Final Technical Report for NASA Project Assurance Reasoning for Increasingly Autonomous Systems (ARIAS)}},
year = {2018}
}
@article{Anderson2020,
abstract = {How should reinforcement learning (RL) agents explain themselves to humans not trained in AI? To gain insights into this question, we conducted a 124-participant, four-treatment experiment to compare participants' mental models of an RL agent in the context of a simple Real-Time Strategy (RTS) game. The four treatments isolated two types of explanations vs. neither vs. both together. The two types of explanations were as follows: (1) saliency maps (an "Input Intelligibility Type"that explains the AI's focus of attention) and (2) reward-decomposition bars (an "Output Intelligibility Type"that explains the AI's predictions of future types of rewards). Our results show that a combined explanation that included saliency and reward bars was needed to achieve a statistically significant difference in participants' mental model scores over the no-explanation treatment. However, this combined explanation was far from a panacea: It exacted disproportionately high cognitive loads from the participants who received the combined explanation. Further, in some situations, participants who saw both explanations predicted the agent's next action worse than all other treatments' participants.},
author = {Anderson, Andrew and Dodge, Jonathan and Sadarangani, Amrita and Juozapaitis, Zoe and Newman, Evan and Irvine, Jed and Chattopadhyay, Souti and Olson, Matthew and Fern, Alan and Burnett, Margaret},
doi = {10.1145/3366485},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson et al. - 2020 - Mental Models of Mere Mortals with Explanations of Reinforcement Learning.pdf:pdf},
issn = {21606463},
journal = {ACM Transactions on Interactive Intelligent Systems},
keywords = {Intelligent user interfaces,human-computer interaction},
month = {jun},
number = {2},
pages = {15},
publisher = {Association for Computing Machinery},
title = {{Mental Models of Mere Mortals with Explanations of Reinforcement Learning}},
url = {https://doi.org/10.1145/3366485},
volume = {10},
year = {2020}
}
@inproceedings{DAlterio2020,
abstract = {In recent year, there has been a growing need for intelligent systems that not only are able to provide reliable classifications but can also produce explanations for the decisions they make. The demand for increased explainability has led to the emergence of explainable artificial intelligence (XAI) as a specific research field. In this context, fuzzy logic systems represent a promising tool thanks to their inherently interpretable structure. The use of a rule-base and linguistic terms, in fact, have allowed researchers to create models that are able to produce explanations in natural language for each of the classifications they make. So far, however, designing systems that make use of interval type-2 (IT2) fuzzy logic and also give explanations for their outputs has been very challenging, partially due to the presence of the type-reduction step. In this paper, it will be shown how constrained interval type-2 (CIT2) fuzzy sets represent a valid alternative to conventional interval type-2 sets in order to address this issue. Through the analysis of two case studies from the medical domain, it is shown how explainable CIT2 classifiers are produced. These systems can explain which rules contributed to the creation of each of the endpoints of the output interval centroid, while showing (in these examples) the same level of accuracy as their IT2 counterpart.},
author = {D'Alterio, Pasquale and Garibaldi, Jonathan M. and John, Robert I.},
booktitle = {IEEE International Conference on Fuzzy Systems},
doi = {10.1109/FUZZ48607.2020.9177671},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Constrained Interval Type-2 Fuzzy classification systems for XAI.pdf:pdf},
isbn = {9781728169323},
issn = {10987584},
keywords = {Constrained interval type-2,Explainable type-2 fuzzy systems,XAI},
month = {jul},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Constrained interval type-2 fuzzy classification systems for explainable AI (XAI)}},
volume = {2020-July},
year = {2020}
}
@techreport{,
abstract = {In this section, we review the basic concepts of functional safety, its lifecycle and the analysis techniques. Definition of Functional Safety ISO 26262: Road Vehicles-Functional Safety is the automotive industry standard, derivative of the more general IEC 61508 functional safety standard (IEC), designed for safety-related systems for series production passenger vehicles with a maximum gross vehicle mass up to 3,500 kg and that are equipped with one or more E/E subsystems (Beckers). According to ISO 26262, functional safety is defined as the "absence of unreasonable risk due to hazards caused by malfunctioning behavior of electrical/electronic systems". This definition can be represented as a chain of implications, as shown in Figure 1. Required Risk Reduction based on acceptable level of risk Risk of harm/damage Hazard or unintended situation Malfunction of E/E component Figure 1: ISO 26262 chain of implications Failure Classification and Hardware Random Failure Metrics Per ISO 26262, malfunction of the electrical/electronic (E/E) component is classified into two types of failures: • Systematic failures: These represent the failures in an item/function that are induced in a deterministic way during development, manufacturing, or maintenance (process issues). These failures-typically due to process causes-can be addressed by a change of the design or of the manufacturing process, operational procedures, documentation, or other relevant factors. Typical requirements are tracking and traceability. All these methods and expectation are captured by the functional safety management activities as reported in ISO 26262-2:2011. • Random failures: Hardware random failures appear during the lifetime of a hardware element and emanate from random defects innate to the process or usage conditions. Hardware random failures can be further classified in permanent faults (e.g., stuck-at faults) and transient faults (e.g., single-event-upsets or soft errors). Handling random failures is addressed during the design and verification of the hardware/software system by introducing safety mechanisms to make the architecture able to detect and correct the malfunctions. From the vocabulary in ISO 26262:1-2011, a safety mechanism is a technical solution implemented by E/E functions or elements, or by other technologies, to detect faults or control failures to achieve or maintain a safe state. Examples of safety mechanisms include:-Error correction code (ECC)-Cyclic redundancy check (CRC)-Hardware redundancy-Built-in-self-test (BIST) The effectiveness of the solution to detect these random failures is measured by three metrics to detect fault and failure in time (FIT), as well as the overall likelihood of risk:-Single-point fault metric (SPFM)-Latent fault metric (LFM)-Probabilistic metrics for hardware failures (PMHF) These three metrics are essentially the measurement of functional safety for hardware components per ISO 26262 and the rest of this paper mainly focuses on how to analyze them and meet their target value.},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Basics of Functional Safety Functional Safety Methodologies for Automotive Applications.pdf:pdf},
isbn = {262622:2011},
keywords = {Automotive,BIST (Built-In-Self-Test),DFA (Dependent Failure Analysis),EDA (Electronic Design Automation),FMEDA (Failure Mode Effects and Diagnostic Analysis),Functional Safety,ISO 26262,Redundancy},
title = {{Basics of Functional Safety Functional Safety Methodologies for Automotive Applications}},
url = {www.cadence.com}
}
@article{Morikawa2020,
abstract = {In recent years, curial incidents and accidents have been reported due to un-intended control caused by misjudgment of statistical machine learning (SML), which include deep learning. The international functional safety standards for Electric/Electronic/Programmable (E/E/P) systems have been widely spread to improve safety. However, most of them do not recom-mended to use SML in safety critical systems so far. In practical the new concepts and methods are urgently required to enable SML to be safely used in safety critical systems. In this paper, we organize five kinds of technical safety concepts (TSCs) for SML components toward accordance with functional safety standards. We discuss not only quantitative evaluation criteria, but also development process based on XAI (eXplainable Artificial Intelligence) and Automotive SPICE to improve explainability and reliability in development phase. Fi-nally, we briefly compare the TSCs in cost and difficulty, and expect to en-courage further discussion in many communities and domain.},
archivePrefix = {arXiv},
arxivId = {2008.01263},
author = {Morikawa, Akihisa and Matsubara, Yutaka},
eprint = {2008.01263},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Morikawa, Matsubara - 2020 - Safety design concepts for statistical machine learning components toward accordance with functional safety.pdf:pdf},
keywords = {Functional safety,Safety design concept,Statistical machine learning},
month = {aug},
title = {{Safety design concepts for statistical machine learning components toward accordance with functional safety standards}},
url = {http://arxiv.org/abs/2008.01263},
year = {2020}
}
@techreport{Chen,
abstract = {As machine learning (ML) has seen increasing adoption in safety-critical domains (e.g., autonomous vehicles), the reliability of ML systems has also grown in importance. While prior studies have proposed techniques to enable efficient error-resilience techniques (e.g., selective instruction duplication), a fundamental requirement for realizing these techniques is a detailed understanding of the application's resilience. In this work, we present TensorFI, a high-level fault injection (FI) framework for TensorFlow-based applications. TensorFI is able to inject both hardware and software faults in general TensorFlow programs. TensorFI is a configurable FI tool that is flexible, easy to use, and portable. It can be integrated into existing TensorFlow programs to assess their resilience for different fault types (e.g., faults in particular operators). We use TensorFI to evaluate the resilience of 12 ML programs, including DNNs used in the autonomous vehicle domain. Our tool is publicly available at https://github.com/DependableSystemsLab/TensorFI .},
archivePrefix = {arXiv},
arxivId = {2004.01743v1},
author = {Chen, Zitao and Narayanan, Niranjhana and Fang, Bo and Li, Guanpeng and Pattabiraman, Karthik and Debardeleben, Nathan},
eprint = {2004.01743v1},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - Unknown - TensorFI A Flexible Fault Injection Framework for TensorFlow Applications.pdf:pdf},
title = {{TensorFI: A Flexible Fault Injection Framework for TensorFlow Applications}},
url = {https://github.com/DependableSystemsLab/TensorFI}
}
@article{Salay2017a,
author = {Salay, Rick and Queiroz, Rodrigo and Czarnecki, Krzysztof},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salay, Queiroz, Czarnecki - 2017 - An Analysis of ISO 26262 Using Machine Learning Safely in Automotive Software.pdf:pdf},
issn = {23318422},
journal = {arXiv},
month = {sep},
publisher = {arXiv},
title = {{An Analysis of ISO 26262: Using Machine Learning Safely in Automotive Software}},
url = {http://arxiv.org/abs/1709.02435},
year = {2017}
}
@inproceedings{Mohseni2020a,
abstract = {Autonomous vehicles rely on machine learning to solve challenging tasks in perception and motion planning. However, automotive software safety standards have not fully evolved to address the challenges of machine learning safety such as interpretability, verification, and performance limitations. In this paper, we review and organize practical machine learn- ing safety techniques that can complement engineering safety for machine learning based software in autonomous vehicles. Our organization maps safety strategies to state-of-theart machine learning techniques in order to enhance dependability and safety of machine learning algorithms. We also discuss security limitations and user experience aspects of machine learning components in autonomous vehicles.},
archivePrefix = {arXiv},
arxivId = {1912.09630},
author = {Mohseni, Sina and Pitale, Mandar and Singh, Vasu and Wang, Zhangyang},
booktitle = {CEUR Workshop Proceedings},
eprint = {1912.09630},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Practical_Solutions_for_Machine_Learning_Safety_in.pdf:pdf},
issn = {16130073},
pages = {162--169},
title = {{Practical solutions for machine learning safety in autonomous vehicles}},
url = {https://www.researchgate.net/publication/338115926_Practical_Solutions_for_Machine_Learning_Safety_in_Autonomous_Vehicles/stats},
volume = {2560},
year = {2020}
}
@article{Amodei2016b,
abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
archivePrefix = {arXiv},
arxivId = {1606.06565},
author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'{e}}, Dan},
eprint = {1606.06565},
file = {:C\:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Amodei et al. - 2016 - Concrete Problems in AI Safety(2).pdf:pdf},
month = {jun},
title = {{Concrete Problems in AI Safety}},
url = {http://arxiv.org/abs/1606.06565},
year = {2016}
}
