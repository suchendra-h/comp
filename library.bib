Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{IanGoodfellow2016,
abstract = {"Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and video games. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors"--Page 4 of cover. Introduction -- Applied math and machine learning basics. Linear algebra -- Probability and information theory -- Numerical computation -- Machine learning basics -- Deep networks: modern practices. Deep feedforward networks -- Regularization for deep learning -- Optimization for training deep models -- Convolutional networks -- Sequence modeling: recurrent and recursive nets -- Practical methodology -- Applications -- Deep learning research. Linear factor models -- Autoencoders -- Representation learning -- Structured probabilistic models for deep learning -- Monte Carlo methods -- Confronting the partition function -- Approximate inference -- Deep generative models.},
author = {Courville, Ian Goodfellow and Yoshua Bengio and Aaron},
booktitle = {Nature},
isbn = {3463353563306},
keywords = {cnn,convolutional neural networks,deep learning,plant disease},
number = {7553},
pages = {1--73},
publisher = {MIT Press},
title = {{Deep learning}},
url = {https://www.deeplearningbook.org/},
volume = {29},
year = {2016}
}
@article{Kristjanpoller2018,
abstract = {Measurement, prediction, and modeling of currency price volatility constitutes an important area of research at both the national and corporate level. Countries attempt to understand currency volatility to set national economic policies and firms to best manage exchange rate risk and leverage assets. A relatively new technological invention that the corporate treasurer has to turn to as part of the overall financial strategy is cryptocurrency. One estimate values the total market capitalization of cryptocurrencies at {\$}557 billion USD at the beginning of 2018. While the overall size of the market for cryptocurrency is significant, our understanding of the behavior of this instrument is only beginning. In this article, we propose a hybrid Artificial Neural Network-Generalized AutoRegressive Conditional Heteroskedasticity (ANN-GARCH) model with preprocessing to forecast the price volatility of bitcoin, the most traded and largest by market capitalization of the cryptocurrencies.},
author = {Kristjanpoller, Werner and Minutolo, Marcel C.},
doi = {10.1016/j.eswa.2018.05.011},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kristjanpoller, Minutolo - 2018 - A hybrid volatility forecasting framework integrating GARCH, artificial neural network, technical anal.pdf:pdf},
issn = {09574174},
journal = {Expert Syst. Appl.},
title = {{A hybrid volatility forecasting framework integrating GARCH, artificial neural network, technical analysis and principal components analysis}},
year = {2018}
}
@article{Russel2015,
abstract = {A rtificial intelligence (AI) research has explored a variety of problems and approaches since its inception, but for the last 20 years or so has been focused on the problems surrounding the construction of intelligent agents-systems that perceive and act in some environment. In this context, the criterion for intelligence is related to statistical and economic notions of rationality-colloquially, the ability to make good decisions, plans, or inferences. The adoption of probabilistic representations and statistical learning methods has led to a large degree of integration and cross-fertilization between AI, machine learning, statistics, control theory, neuroscience, and other fields. The establishment of shared theoretical frameworks, combined with the availability of data and processing power, has yielded remarkable successes in various component tasks such as speech recognition , image classification, autonomous vehicles, machine translation, legged locomotion, and question-answering systems .},
author = {Russell, Stuart and Dewey, Daniel and Tegmark, Max},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Russell, Dewey, Tegmark - 2015 - Research Priorities for Robust and Beneficial Artificial Intelligence(2).pdf:pdf},
issn = {0738-4602},
title = {{Research Priorities for Robust and Beneficial Artificial Intelligence}},
year = {2015}
}
@techreport{Cheriton,
abstract = {The amount of data generated in the modern society is increasing rapidly. New problems and novel approaches of data capture, storage, analysis and visualization are responsible for the emergence of the Big Data research field. Machine Learning algorithms can be used in Big Data to make better and more accurate inferences. However, because of the challenges Big Data imposes, these algorithms need to be adapted and optimized to specific applications. One important decision made by software engineers is the choice of the language that is used in the implementation of these algorithms. Therefore, this literature survey identifies and describes domain-specific languages and frameworks used for Machine Learning in Big Data. By doing this, software engineers can then make more informed choices and beginners have an overview of the main languages used in this domain.},
author = {Cheriton, David R and Alencar, Paulo and Cowan, Donald},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheriton, Alencar, Cowan - Unknown - A Survey on Domain-Specific Languages for Machine Learning in Big Data Ivens Portugal.pdf:pdf},
keywords = {BD,Big Data,DSL,ML,Machine Learning,domain-specific languages,literature survey},
title = {{A Survey on Domain-Specific Languages for Machine Learning in Big Data Ivens Portugal}}
}
@techreport{Chen,
abstract = {As machine learning (ML) has seen increasing adoption in safety-critical domains (e.g., autonomous vehicles), the reliability of ML systems has also grown in importance. While prior studies have proposed techniques to enable efficient error-resilience techniques (e.g., selective instruction duplication), a fundamental requirement for realizing these techniques is a detailed understanding of the application's resilience. In this work, we present TensorFI, a high-level fault injection (FI) framework for TensorFlow-based applications. TensorFI is able to inject both hardware and software faults in general TensorFlow programs. TensorFI is a configurable FI tool that is flexible, easy to use, and portable. It can be integrated into existing TensorFlow programs to assess their resilience for different fault types (e.g., faults in particular operators). We use TensorFI to evaluate the resilience of 12 ML programs, including DNNs used in the autonomous vehicle domain. Our tool is publicly available at https://github.com/DependableSystemsLab/TensorFI .},
archivePrefix = {arXiv},
arxivId = {2004.01743v1},
author = {Chen, Zitao and Narayanan, Niranjhana and Fang, Bo and Li, Guanpeng and Pattabiraman, Karthik and Debardeleben, Nathan},
eprint = {2004.01743v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - Unknown - TensorFI A Flexible Fault Injection Framework for TensorFlow Applications.pdf:pdf},
title = {{TensorFI: A Flexible Fault Injection Framework for TensorFlow Applications}},
url = {https://github.com/DependableSystemsLab/TensorFI}
}
@techreport{Fisac,
abstract = {Safety analysis is a necessary component in the design and deployment of autonomous systems. Techniques from robust optimal control theory, such as Hamilton-Jacobi reachability analysis, allow a rigorous formalization of safety as guaranteed constraint satisfaction. Unfortunately, the computational complexity of these tools for general dynamical systems scales poorly with state dimension, making existing tools impractical beyond small problems. Modern reinforcement learning methods have shown promising ability to find approximate yet proficient solutions to optimal control problems in complex and high-dimensional systems, however their formulation is restricted to problems with an additive payoff (reward) over time, unsuitable for reasoning about safety. In recent work, we proved that the problem of maximizing the minimum payoff over time, central to safety analysis, can be time-discounted to induce a contraction mapping. Here, we introduce a novel, time-discounted Safety Bellman Equation that renders reinforcement learning techniques amenable to quantitative safety analysis, enabling them to approximate the safe set and optimal safety policy. This opens a new avenue of research connecting control-theoretic safety analysis and the reinforcement learning domain. We demonstrate our formulation on a variety of simulated robotics tasks and reinforcement learning schemes, validating our results against analytic and numerical solutions when these can be obtained, and showing scalability to previously intractable problems of up to 18 state dimensions by exploiting state-of-the-art deep reinforcement learning algorithms.},
author = {Fisac, Jaime F and Lugovoy, Neil F and Rubies-Royo, Vicen{\c{c}} and Ghosh, Shromona and Tomlin, Claire J},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisac et al. - Unknown - Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning.pdf:pdf},
title = {{Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning}}
}
@inproceedings{Bloomfield2010,
abstract = {This paper focuses on the approaches used in safety cases for software based systems. We outline the history of approaches for assuring the safety of software-based systems, the current uptake of safety and assurance cases and the current practice on structured safety cases. Directions for further development are discussed. {\textcopyright} Springer-Verlag London Limited 2010.},
author = {Bloomfield, Robin and Bishop, Peter},
booktitle = {Mak. Syst. Safer - Proc. 18th Safety-Critical Syst. Symp. SSS 2010},
doi = {10.1007/978-1-84996-086-1_4},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bloomfield, Bishop - 2010 - Safety and assurance cases Past, present and possible future - An adelard perspective.pdf:pdf},
isbn = {9781849960854},
pages = {51--67},
publisher = {Springer London},
title = {{Safety and assurance cases: Past, present and possible future - An adelard perspective}},
year = {2010}
}
@article{Arlot2010,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplic-ity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
archivePrefix = {arXiv},
arxivId = {0907.4728},
author = {Arlot, Sylvain and Celisse, Alain},
doi = {10.1214/09-SS054},
eprint = {0907.4728},
issn = {19357516},
journal = {Stat. Surv.},
keywords = {Cross-validation,Leave-one-out,Model selection},
pages = {40--79},
title = {{A survey of cross-validation procedures for model selection}},
volume = {4},
year = {2010}
}
@inproceedings{Schwalbe2020,
abstract = {Methods for safety assurance suggested by the ISO 26262 automotive functional safety standard are not sufficient for applications based on machine learning (ML). We provide a structured, certification oriented overview on available methods supporting the safety argumen-tation of a ML based system. It is sorted into life-cycle phases, and maturity of the approach as well as applicability to different ML types are collected. From this we deduce current open challenges: powerful solvers, inclusion of expert knowledge, validation of data representativity and model diversity, and model introspection with provable guarantees.},
author = {Schwalbe, Gesina and Schels, Martin},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwalbe, Schels - 2020 - A Survey on Methods for the Safety Assurance of Machine Learning Based Systems A Survey on Methods for the (2).pdf:pdf},
keywords = {ISO 26262,explainable AI,functional safety,life-cycle,machine learning},
title = {{A Survey on Methods for the Safety Assurance of Machine Learning Based Systems}},
url = {https://hal.archives-ouvertes.fr/hal-02442819},
year = {2020}
}
@article{iso15026-1-2019,
doi = {10.1109/IEEESTD.2019.8657410},
file = {:C$\backslash$:/Users/Suchendra/OneDrive - McMaster University/PhD Thesis/Books/15026-1-2019.pdf:pdf},
journal = {ISO/IEC/IEEE 15026-1:2019(E)},
pages = {1--38},
title = {{15026-1-2019 - ISO/IEC/IEEE International Standard - Systems and software engineering--Systems and software assurance --Part 1:Concepts and vocabulary}},
year = {2019}
}
@techreport{Ries,
author = {Ries, Benoˆıt Benoˆıt and Guelfi, Nicolas and Jahi´c, Benjamin Jahi´c},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ries, Guelfi, Jahi´c - Unknown - An MDE Method for Improving Deep Learning Dataset Requirements Engineering using Alloy and UML.pdf:pdf},
keywords = {Alloy,EMF,Model-Driven Engineering,Requirements Engineering,Sirius,Software Engineering},
title = {{An MDE Method for Improving Deep Learning Dataset Requirements Engineering using Alloy and UML}},
url = {https://orcid.org/0000-0002-8680-2797}
}
@article{Lage2018,
abstract = {We often desire our models to be interpretable as well as accurate. Prior work on optimizing models for interpretability has relied on easy-to-quantify proxies for interpretability, such as sparsity or the number of operations required. In this work, we optimize for interpretability by directly including humans in the optimization loop. We develop an algorithm that minimizes the number of user studies to find models that are both predictive and interpretable and demonstrate our approach on several data sets. Our human subjects results show trends towards different proxy notions of interpretability on different datasets, which suggests that different proxies are preferred on different tasks.},
archivePrefix = {arXiv},
arxivId = {1805.11571},
author = {Lage, Isaac and Ross, Andrew Slavin and Kim, Been and Gershman, Samuel J. and Doshi-Velez, Finale},
eprint = {1805.11571},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lage et al. - 2018 - Human-in-the-Loop Interpretability Prior.pdf:pdf},
journal = {Adv. Neural Inf. Process. Syst.},
month = {may},
pages = {10159--10168},
publisher = {Neural information processing systems foundation},
title = {{Human-in-the-Loop Interpretability Prior}},
url = {http://arxiv.org/abs/1805.11571},
volume = {2018-December},
year = {2018}
}
@inproceedings{DAlterio2020,
abstract = {In recent year, there has been a growing need for intelligent systems that not only are able to provide reliable classifications but can also produce explanations for the decisions they make. The demand for increased explainability has led to the emergence of explainable artificial intelligence (XAI) as a specific research field. In this context, fuzzy logic systems represent a promising tool thanks to their inherently interpretable structure. The use of a rule-base and linguistic terms, in fact, have allowed researchers to create models that are able to produce explanations in natural language for each of the classifications they make. So far, however, designing systems that make use of interval type-2 (IT2) fuzzy logic and also give explanations for their outputs has been very challenging, partially due to the presence of the type-reduction step. In this paper, it will be shown how constrained interval type-2 (CIT2) fuzzy sets represent a valid alternative to conventional interval type-2 sets in order to address this issue. Through the analysis of two case studies from the medical domain, it is shown how explainable CIT2 classifiers are produced. These systems can explain which rules contributed to the creation of each of the endpoints of the output interval centroid, while showing (in these examples) the same level of accuracy as their IT2 counterpart.},
author = {D'Alterio, Pasquale and Garibaldi, Jonathan M. and John, Robert I.},
booktitle = {IEEE Int. Conf. Fuzzy Syst.},
doi = {10.1109/FUZZ48607.2020.9177671},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Constrained Interval Type-2 Fuzzy classification systems for XAI.pdf:pdf},
isbn = {9781728169323},
issn = {10987584},
keywords = {Constrained interval type-2,Explainable type-2 fuzzy systems,XAI},
month = {jul},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Constrained interval type-2 fuzzy classification systems for explainable AI (XAI)}},
volume = {2020-July},
year = {2020}
}
@techreport{Agrawal2019,
abstract = {TensorFlow Eager is a multi-stage, Python-embedded domain-specific language for hardware-accelerated machine learning, suitable for both interactive research and production. TensorFlow, which TensorFlow Eager extends, requires users to represent computations as dataflow graphs; this permits compiler optimizations and simplifies deployment but hinders rapid prototyping and run-time dynamism. TensorFlow Eager eliminates these usability costs without sacrificing the benefits furnished by graphs: It provides an imperative front-end to TensorFlow that executes operations immediately and a JIT tracer that translates Python functions composed of TensorFlow operations into executable dataflow graphs. TensorFlow Eager thus offers a multi-stage programming model that makes it easy to interpolate between imperative and staged execution in a single package.},
archivePrefix = {arXiv},
arxivId = {1903.01855v1},
author = {Agrawal, Akshay and Modi, Akshay Naresh and Passos, Alexandre and Lavoie, Allen and Agarwal, Ashish and Shankar, Asim and Ganichev, Igor and Levenberg, Josh and Hong, Mingsheng and Monga, Rajat and Cai, Shanqing},
eprint = {1903.01855v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Agrawal et al. - 2019 - TENSORFLOW EAGER A MULTI-STAGE, PYTHON-EMBEDDED DSL FOR MACHINE LEARNING.pdf:pdf},
title = {{TENSORFLOW EAGER: A MULTI-STAGE, PYTHON-EMBEDDED DSL FOR MACHINE LEARNING}},
year = {2019}
}
@techreport{Qayyum,
abstract = {Recent years have witnessed widespread adoption of machine learning (ML)/deep learning (DL) techniques due to their superior performance for a variety of healthcare applications ranging from the prediction of cardiac arrest from one-dimensional heart signals to computer-aided diagnosis (CADx) using multi-dimensional medical images. Notwithstanding the impressive performance of ML/DL, there are still lingering doubts regarding the robustness of ML/DL in healthcare settings (which is traditionally considered quite challenging due to the myriad security and privacy issues involved), especially in light of recent results that have shown that ML/DL are vulnerable to adversarial attacks. In this paper, we present an overview of various application areas in healthcare that leverage such techniques from security and privacy point of view and present associated challenges. In addition, we present potential methods to ensure secure and privacy-preserving ML for healthcare applications. Finally, we provide insight into the current research challenges and promising directions for future research.},
archivePrefix = {arXiv},
arxivId = {2001.08103v1},
author = {Qayyum, Adnan and Qadir, Junaid and Bilal, Muhammad and Al-Fuqaha, Ala},
eprint = {2001.08103v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qayyum et al. - Unknown - Secure and Robust Machine Learning for Healthcare A Survey.pdf:pdf},
title = {{Secure and Robust Machine Learning for Healthcare: A Survey}},
url = {https://tinyurl.com/FDA-AI-diabetic-eye}
}
@misc{Salay2017,
abstract = {—Machine learning (ML) plays an ever-increasing role in advanced automotive functionality for driver assistance and autonomous operation; however, its adequacy from the perspective of safety certification remains controversial. In this paper, we analyze the impacts that the use of ML as an implementation approach has on ISO 26262 safety lifecycle and ask what could be done to address them. We then provide a set of recommendations on how to adapt the standard to accommodate ML.},
archivePrefix = {arXiv},
arxivId = {1709.02435},
author = {Salay, Rick and Queiroz, Rodrigo and Czarnecki, Krzysztof},
booktitle = {arXiv},
eprint = {1709.02435},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salay, Queiroz, Czarnecki - 2017 - An Analysis of ISO 26262 Using Machine Learning Safely in Automotive Software.pdf:pdf},
issn = {23318422},
month = {sep},
publisher = {arXiv},
title = {{An Analysis of ISO 26262: Using Machine Learning Safely in Automotive Software}},
year = {2017}
}
@article{Macrae2019a,
abstract = {Artificial intelligence (AI) has enormous potential to improve the safety of healthcare, from increasing diagnostic accuracy,1 to optimising treatment planning,2 to forecasting outcomes of care.3 However, integrating AI technologies into the delivery of healthcare is likely to introduce a range of new risks and amplify existing ones. For instance, failures in widely used software have the potential to quickly affect large numbers of patients4; hidden assumptions in underlying data and models can lead to AI systems delivering dangerous recommendations that are insensitive to local care processes,5 6 and opaque AI techniques such as deep learning can make explaining and learning from failure extremely difficult.7 8 To maximise the benefits of AI in healthcare and to build trust among patients and practitioners, it will therefore be essential to robustly govern the risks that AI poses to patient safety.

In a recent review in this journal, Challen and colleagues present an important and timely analysis of some of the key technological risks associated with the application of machine learning in clinical settings.9 Machine learning is a subfield of AI that focuses on the development of algorithms that are automatically derived and optimised through exposure to large quantities of exemplar ‘training' data.10 The outputs of machine learning algorithms are essentially classifications of patterns that provide some sort of prediction—for instance, predicting whether an image shows a malignant melanoma or a benign mole.11 Some of the basic techniques of machine learning have existed for half a century or more, but progress in the field has accelerated rapidly due to advances in the development of ‘deep' artificial neural networks12 combined with huge increases in computational power and the availability of enormous quantities of data. These techniques have underpinned recent public demonstrations of AI systems {\ldots}},
author = {Macrae, Carl},
doi = {10.1136/bmjqs-2019-009484},
issn = {20445415},
journal = {BMJ Qual. Saf.},
keywords = {governance,information technology,risk management},
month = {jun},
number = {6},
pages = {495--498},
pmid = {30979783},
publisher = {BMJ Publishing Group},
title = {{Governing the safety of artificial intelligence in healthcare}},
url = {https://qualitysafety.bmj.com/content/28/6/495 https://qualitysafety.bmj.com/content/28/6/495.abstract},
volume = {28},
year = {2019}
}
@article{Moin,
abstract = {In this paper, we present the current position of the research project ML-Quadrat, which aims to extend the methodology, modeling language and tool support of ThingML-an open source modeling tool for IoT/CPS-to address Machine Learning needs for the IoT applications. Currently, ThingML offers a modeling language and tool support for modeling the components of the system, their communication interfaces as well as their behaviors. The latter is done through state machines. However, we argue that in many cases IoT/CPS services involve system components and physical processes, whose behaviors are not well understood in order to be modeled using state machines. Hence, quite often a data-driven approach that enables inference based on the observed data, e.g., using Machine Learning is preferred. To this aim, ML-Quadrat integrates the necessary Machine Learning concepts into ThingML both on the modeling level (syntax and semantics of the modeling language) and on the code generators level. We plan to support two target platforms for code generation regarding Stream Processing and Complex Event Processing, namely Apache SAMOA and Apama.},
author = {Moin, Armin and R{\"{o}}ssler, Stephan and G{\"{u}}nnemann, Stephan},
doi = {10.1016/j},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moin, R{\"{o}}ssler, G{\"{u}}nnemann - Unknown - Augmenting Model-Driven Software Engineering for the Internet of Things with Machine Learning.pdf:pdf},
title = {{Augmenting Model-Driven Software Engineering for the Internet of Things with Machine Learning}},
url = {https://doi.org/10.1016/j.}
}
@article{Bishop2013,
abstract = {Several decades of research in the field of machine learning have resulted in a multitude of different algorithms for solving a broad range of problems. To tackle a new application, a researcher typically tries to map their problem onto one of these existing methods, often influenced by their familiarity with specific algorithms and by the availability of corresponding software implementations. In this study, we describe an alternative methodology for applying machine learning, in which a bespoke solution is formulated for each new application. The solution is expressed through a compact modelling language, and the corresponding custom machine learning code is then generated automatically. This model-based approach offers several major advantages, including the opportunity to create highly tailored models for specific scenarios, as well as rapid prototyping and comparison of a range of alternative models. Furthermore, newcomers to the field of machine learning do not have to learn about the huge range of traditional methods, but instead can focus their attention on understanding a single modelling environment. In this study, we show how probabilistic graphical models, coupled with efficient inference algorithms, provide a very flexible foundation formodel-based machine learning, and we outline a large-scale commercial application of this framework involving tens of millions of users. We also describe the concept of probabilistic programming as a powerful software environment for modelbased machine learning, and we discuss a specific probabilistic programming language called Infer.NET, which has been widely used in practical applications. {\textcopyright} 2012 The Author(s) Published by the Royal Society. All rights reserved.},
author = {Bishop, Christopher M.},
doi = {10.1098/rsta.2012.0222},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop - 2013 - Model-based machine learning.pdf:pdf},
issn = {1364503X},
journal = {Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.},
keywords = {Bayesian inference,Graphical probabilistic programming,Infer. NET},
month = {feb},
number = {1984},
publisher = {Royal Society},
title = {{Model-based machine learning}},
url = {/pmc/articles/PMC3538442/ /pmc/articles/PMC3538442/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3538442/},
volume = {371},
year = {2013}
}
@article{Kienzle2019,
abstract = {The growing use of models for separating concerns in complex systems has lead to a proliferation of model composition operators. These composition operators have traditionally been defined from scratch following various approaches differing in formality, level of detail, chosen paradigm, and styles. Due to the lack of proper foundations for defining model composition (concepts, abstractions, or frameworks), it is difficult to compare or reuse composition operators. In this paper, we stipulate the existence of a unifying framework that reduces all structural composition operators to structural merging, and all composition operators acting on discrete behaviors to event scheduling. We provide convincing evidence of this hypothesis by discussing how structural and behavioral homogeneous model composition operators (i.e., weavers) can be mapped onto this framework. Based on this discussion, we propose a conceptual model of the framework and identify a set of research challenges, which, if addressed, lead to the realization of this framework to support rigorous and efficient engineering of model composition operators for homogeneous and eventually heterogeneous modeling languages.},
author = {Kienzle, J{\"{o}}rg and Mussbacher, Gunter and Combemale, Benoit and Deantoni, Julien},
doi = {10.1007/s10270-018-00707-8},
issn = {16191374},
journal = {Softw. Syst. Model.},
keywords = {Event scheduling,Event structures,Model composition,Separation of concerns,Symmetric merge},
month = {oct},
number = {5},
pages = {3005--3023},
publisher = {Springer Verlag},
title = {{A unifying framework for homogeneous model composition}},
volume = {18},
year = {2019}
}
@techreport{Alves2018,
author = {Alves, Erin and Bhatt, Devesh and Hall, Brendan and Driscoll, Kevin and Murugesan, Anitha and Rushby, John},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alves et al. - 2018 - Considerations in Assuring Safety of Increasingly Autonomous Systems Final Technical Report for NASA Project Assur.pdf:pdf},
title = {{Considerations in Assuring Safety of Increasingly Autonomous Systems Final Technical Report for NASA Project Assurance Reasoning for Increasingly Autonomous Systems (ARIAS)}},
year = {2018}
}
@inproceedings{Basciani2016,
abstract = {Over the last years, several model repositories have been proposed in response to the need of the MDE community for advanced systems supporting the reuse of modeling artifacts. Modelers can interact with MDE repositories with different intents ranging from merely repository browsing, to searching specific artifacts satisfying precise requirements. The organization and browsing facilities provided by current repositories is limited since they do not produce structured overviews of the contained artifacts, and the ategorization mechanisms (if any) are based on manual activities. When dealing with large numbers of modeling artifacts, such limitations increase the effort for managing and reusing artifacts stored in model repositories. By focusing on metamodel repositories, in this paper we propose the application of clustering techniques to automatically organize stored metamodels and to provide users with overviews of the application domains covered by the available metamodels. The approach has been implemented in the MDEForge repository.},
author = {Basciani, Francesco and Rocco, Juri Di and Ruscio, Davide Di and Iovino, Ludovico and Pierantonio, Alfonso},
booktitle = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
doi = {10.1007/978-3-319-39696-5_21},
isbn = {9783319396958},
issn = {16113349},
keywords = {MDEForge,Metamodel clustering,Model Driven Engineering,Model repositories},
pages = {342--358},
publisher = {Springer Verlag},
title = {{Automated clustering of metamodel repositories}},
volume = {9694},
year = {2016}
}
@misc{Abadi2016Tensor,
abstract = {TensorFlow [1] is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition , computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the Ten-sorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
archivePrefix = {arXiv},
arxivId = {1603.04467v2},
author = {{Mart{\'{i}}n Abadi et al.}},
eprint = {1603.04467v2},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - Unknown - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems.pdf:pdf},
howpublished = {www.tensorflow.org},
title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
url = {www.tensorflow.org},
urldate = {2021-03-17},
year = {2015}
}
@techreport{Manuel2020,
author = {Manuel, Pedro and Costa, Afonso},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Manuel, Costa - 2020 - FACULDADE DE ENGENHARIA DA UNIVERSIDADE DO PORTO Customized Hardware for Long-Short Term Memory Networks in Embed.pdf:pdf},
title = {{FACULDADE DE ENGENHARIA DA UNIVERSIDADE DO PORTO Customized Hardware for Long-Short Term Memory Networks in Embedded Systems}},
year = {2020}
}
@article{Wang2019,
abstract = {Safety is a central dimension in contemporary debates on human health, loss prevention, environmental protection, sustainability, and cleaner production. In the information age, especially in the era of big data, safety information is an essential strategy for safety, and safety informatics has become a major research interest and a popular issue in the field of safety science. In recent years, safety informaticsda new area of safety sciencedhas received increasing attention, developing greatly with successful research on the subject. The three key purposes of this paper are: (i) to analyze the historical development of safety informatics, (ii) to review the research progress of safety informatics, and (iii) to review limitations and propose future directions in the field of safety informatics. First, the development process of safety informatics is divided into four typical stages: (i) the embryonic stage (1940e1980), (ii) the initial stage (1980e1990), (iii) the formation stage (1990e2010), and (iv) the deepening stage (2010epresent). Then, a review of safety informatics research is provided from seven aspects, including: (i) the discipline construction of safety informatics, (ii) theoretical safety information model, (iii) accident causation model from a safety information perspective, (iv) safety management based on safety information, (v) safety big data, (vi) safety intelligence, and (vii) safety information technology. Finally, limitations and future research directions in the safety informatics area are briefly discussed.},
author = {Wang, Bing and Wu, Chao},
doi = {10.1016/j.jclepro.2019.119852},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Wu - 2019 - Safety informatics as a new, promising and sustainable area of safety science in the information age.pdf:pdf},
keywords = {Information science,Safety 40,Safety informatics,Safety information,Safety science},
title = {{Safety informatics as a new, promising and sustainable area of safety science in the information age}},
url = {https://doi.org/10.1016/j.jclepro.2019.119852},
year = {2019}
}
@techreport{Hernandez-Oralloa,
abstract = {The current analysis in the AI safety literature usually combines a risk or safety issue (e.g., interruptibility) with a particular paradigm for an AI agent (e.g., reinforcement learning). However, there is currently no survey of safety-relevant characteristics of AI systems that may reveal neglected areas of research or suggest to developers what design choices they could make to avoid or minimise certain safety concerns. In this paper, we take a first step towards delivering such a survey , from two angles. The first features AI system characteristics that are already known to be relevant to safety concerns, including internal system characteristics, characteristics relating to the effect of the external environment on the system , and characteristics relating to the effect of the system on the target environment. The second presents a brief survey of a broad range of AI system characteristics that could prove relevant to safety research, including types of interaction, computation, integration, anticipation, supervision, modification , motivation and achievement. This survey enables further work in exploring system characteristics and design choices that affect safety concerns.},
author = {Hern{\'{a}}ndez-Orallo, Jos{\'{e}} and Mart{\'{i}}nez-Plumed, Fernando and Avin, Shahar and Se{\'{a}}n´o, Se{\'{a}}n Se{\'{a}}n´ and Eigeartaigh, ´},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hern{\'{a}}ndez-Orallo et al. - Unknown - Surveying Safety-relevant AI Characteristics.pdf:pdf},
title = {{Surveying Safety-relevant AI Characteristics}}
}
@article{Fischer1936Iris,
abstract = {When two or more populations have been measured in several characters, special interest attaches to certain functions of the measurements by which the populations are discriminated. At the author's suggestion use has already been made of this fact in craniometry (a) by Mr E. S. Martin, who has applied the principle to the sex differences in measurements of the mandible, and (b) by Miss Mildred Barnard, who showed how to obtain from a series of dated series the particular compound of cranial measurements showing most distinctly a progressive or secular trend. In the present paper the application of the same principle will be illustrated on a taxonomic problem; some questions connected with the precision of the processes employed will also be discussed.},
author = {Fisher, R. A.},
doi = {10.1111/j.1469-1809.1936.tb02137.x},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/FISHER - 1936 - THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS.pdf:pdf},
issn = {2050-1439},
journal = {Ann. Eugen.},
month = {sep},
number = {2},
pages = {179--188},
publisher = {Wiley},
title = {{The Use of Multiple Measurments in Taxonomic Problems}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1469-1809.1936.tb02137.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x https://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x},
volume = {7},
year = {1936}
}
@book{taleb2007the,
address = {New York},
author = {Taleb, Nassim},
isbn = {9781400063512},
publisher = {Random House},
title = {{The black swan : the impact of the highly improbable}},
year = {2007}
}
@article{Bencomo2019,
abstract = {More than a decade ago, the research topic models@run.time was coined. Since then, the research area has received increasing attention. Given the prolific results during these years, the current outcomes need to be sorted and classified. Furthermore, many gaps need to be categorized in order to further develop the research topic by experts of the research area but also newcomers. Accordingly, the paper discusses the principles and requirements of models@run.time and the state of the art of the research line. To make the discussion more concrete, a taxonomy is defined and used to compare the main approaches and research outcomes in the area during the last decade and including ancestor research initiatives. We identified and classified 275 papers on models@run.time, which allowed us to identify the underlying research gaps and to elaborate on the corresponding research challenges. Finally, we also facilitate sustainability of the survey over time by offering tool support to add, correct and visualize data.},
author = {Bencomo, Nelly and G{\"{o}}tz, Sebastian and Song, {\textperiodcentered} Hui},
doi = {10.1007/s10270-018-00712-x},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bencomo, G{\"{o}}tz, Song - 2019 - Models@run.time a guided tour of the state of the art and research challenges.pdf:pdf},
journal = {Softw. Syst. Model.},
keywords = {Causal connection,Models@run.time,Self-reflection,Systematic literature review},
pages = {3049--3082},
title = {{Models@run.time: a guided tour of the state of the art and research challenges}},
url = {https://doi.org/10.1007/s10270-018-00712-x},
volume = {18},
year = {2019}
}
@misc{Challen2019,
abstract = {In medicine, artificial intelligence (AI) research is becoming increasingly focused on applying machine learning (ML) techniques to complex problems, and so allowing computers to make predictions from large amounts of patient data, by learning their own associations.1 Estimates of the impact of AI on the wider economy globally vary wildly, with a recent report suggesting a 14{\%} effect on global gross domestic product by 2030, half of which coming from productivity improvements.2 These predictions create political appetite for the rapid development of the AI industry,3 and healthcare is a priority area where this technology has yet to be exploited.2 3 The digital health revolution described by Duggal et al 4 is already in full swing with the potential to ‘disrupt' healthcare. Health AI research has demonstrated some impressive results,5–10 but its clinical value has not yet been realised, hindered partly by a lack of a clear understanding of how to quantify benefit or ensure patient safety, and increasing concerns about the ethical and medico-legal impact.11 

This analysis is written with the dual aim of helping clinical safety professionals to critically appraise current medical AI research from a quality and safety perspective, and supporting research and development in AI by highlighting some of the clinical safety questions that must be considered if medical application of these exciting technologies is to be successful.

Clinical decision support systems (DSS) are in widespread use in medicine and have had most impact providing guidance on the safe prescription of medicines,12 guideline adherence, simple risk screening13 or prognostic scoring.14 These systems use predefined rules, which have predictable behaviour and are usually shown to reduce clinical error,12 although sometimes inadvertently introduce safety issues themselves.15 16 Rules-based systems have also been developed to address diagnostic uncertainty17–19 {\ldots}},
author = {Challen, Robert and Denny, Joshua and Pitt, Martin and Gompels, Luke and Edwards, Tom and Tsaneva-Atanasova, Krasimira},
booktitle = {BMJ Qual. Saf.},
doi = {10.1136/bmjqs-2018-008370},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Challen et al. - 2019 - Artificial intelligence, bias and clinical safety.pdf:pdf;:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Challen et al. - 2019 - Artificial intelligence, bias and clinical safety(2).pdf:pdf},
issn = {20445415},
keywords = {artificial intelligence,clinical decision support systems,clinical safety,machine learning},
month = {mar},
number = {3},
pages = {231--237},
pmid = {30636200},
publisher = {BMJ Publishing Group},
title = {{Artificial intelligence, bias and clinical safety}},
url = {https://qualitysafety.bmj.com/lookup/doi/10.1136/bmjqs-2018-008370 http://qualitysafety.bmj.com/},
volume = {28},
year = {2019}
}
@inproceedings{Burgueno2019,
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations - which we call MDE Intelligence - can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE - for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline. To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
author = {Burgueno, Loli and Burdusel, Alexandru and Gerard, Sebastien and Wimmer, Manuel},
booktitle = {Proc. - 2019 ACM/IEEE 22nd Int. Conf. Model Driven Eng. Lang. Syst. Companion, Model. 2019},
doi = {10.1109/MODELS-C.2019.00028},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Preface to MDE Intelligence 2019.pdf:pdf},
isbn = {9781728151250},
keywords = {Artificial Intelligence,MDE,MDE Intelligence},
month = {sep},
pages = {168--169},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Preface to MDE intelligence 2019: 1st workshop on artificial intelligence and model-driven engineering}},
year = {2019}
}
@inproceedings{Hartmann2017,
abstract = {Machine learning algorithms are designed to resolve unknown behaviours by extracting commonalities over massive datasets. Unfortunately, learning such global behaviours can be inaccurate and slow for systems composed of heterogeneous elements, which behave very differently, for instance as it is the case for cyber-physical systems and Internet of Things applications. Instead, to make smart decisions, such systems have to continuously refine the behaviour on a per-element basis and compose these small learning units together. However, combining and composing learned behaviours from different elements is challenging and requires domain knowledge. Therefore, there is a need to structure and combine the learned behaviours and domain knowledge together in a flexible way. In this paper we propose to weave machine learning into domain modeling. More specifically, we suggest to decompose machine learning into reusable, chainable, and independently computable small learning units, which we refer to as micro learning units. These micro learning units are modeled together with and at the same level as the domain data. We show, based on a smart grid case study, that our approach can be significantly more accurate than learning a global behaviour while the performance is fast enough to be used for live learning.},
author = {Hartmann, Thomas and Moawad, Assaad and Fouquet, Francois and {Le Traon}, Yves},
booktitle = {Proc. - ACM/IEEE 20th Int. Conf. Model Driven Eng. Lang. Syst. Model. 2017},
doi = {10.1109/MODELS.2017.32},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hartmann2019{\_}Article{\_}TheNextEvolutionOfMDEASeamless.pdf:pdf},
isbn = {9781538634929},
keywords = {Cyber-physical systems,Domain modeling,Live learning,Meta modeling,Model-driven engineering,Smart grids},
month = {nov},
pages = {180},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The Next Evolution of MDE: A Seamless Integration of Machine Learning into Domain Modeling}},
year = {2017}
}
@article{Birkenbihl2020,
abstract = {Artificial intelligence (AI) approaches pose a great opportunity for individualized, pre-symptomatic disease diagnosis which plays a key role in the context of personalized, predictive, and finally preventive medicine (PPPM). However, to translate PPPM into clinical practice, it is of utmost importance that AI-based models are carefully validated. The validation process comprises several steps, one of which is testing the model on patient-level data from an independent clinical cohort study. However, recruitment criteria can bias statistical analysis of cohort study data and impede model application beyond the training data. To evaluate whether and how data from independent clinical cohort studies differ from each other, this study systematically compares the datasets collected from two major dementia cohorts, namely, the Alzheimer's Disease Neuroimaging Initiative (ADNI) and AddNeuroMed. The presented comparison was conducted on individual feature level and revealed significant differences among both cohorts. Such systematic deviations can potentially hamper the generalizability of results which were based on a single cohort dataset. Despite identified differences, validation of a previously published, ADNI trained model for prediction of personalized dementia risk scores on 244 AddNeuroMed subjects was successful: External validation resulted in a high prediction performance of above 80{\%} area under receiver operator characteristic curve up to 6 years before dementia diagnosis. Propensity score matching identified a subset of patients from AddNeuroMed, which showed significantly smaller demographic differences to ADNI. For these patients, an even higher prediction performance was achieved, which demonstrates the influence systematic differences between cohorts can have on validation results. In conclusion, this study exposes challenges in external validation of AI models on cohort study data and is one of the rare cases in the neurology field in which such external validation was performed. The presented model represents a proof of concept that reliable models for personalized predictive diagnostics are feasible, which, in turn, could lead to adequate disease prevention and hereby enable the PPPM paradigm in the dementia field.},
author = {Birkenbihl, Colin and Emon, Mohammad Asif and Vrooman, Henri and Westwood, Sarah and Lovestone, Simon and Hofmann-Apitius, Martin and Fr{\"{o}}hlich, Holger},
doi = {10.1007/s13167-020-00216-z},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Birkenbihl et al. - 2020 - Differences in cohort study data affect external validation of artificial intelligence models for predictive.pdf:pdf},
issn = {18785085},
journal = {EPMA J.},
keywords = {Alzheimer's disease,Artificial intelligence,Bioinformatics,Cohort comparison,Cohort data,Data science,Dementia,Digital clinic,Disease modeling,Disease risk prediction,Health data,Individualized patient profiling,Interdisciplinary,Machine learning,Medical data,Model performance,Model validation,Multiprofessional,Neurodegeneration,Precision medicine,Predictive preventive personalized medicine (3 PM/,Propensity score matching,Risk modeling,Sampling bias,Survival analysis,Translational medicine},
month = {sep},
number = {3},
pages = {367--376},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Differences in cohort study data affect external validation of artificial intelligence models for predictive diagnostics of dementia - lessons for translation into clinical practice}},
url = {https://pubmed.ncbi.nlm.nih.gov/32843907/},
volume = {11},
year = {2020}
}
@inproceedings{Hoser2019,
abstract = {The implementation of intelligent agents in industrial applications is often prevented by the high cost of adopting such a system to a particular problem domain. This paper states the thesis that when learning agents are applied to work environments that require domain-specific experience, the agent benefits if it can be further adapted by a supervising domain expert. Closely interacting with the agent, a domain expert should be able to understand its decisions and update the underlying knowledge base as needed. The result would be an agent with individualized knowledge that comes in part from the domain experts. The model of such an adaptive learning agent must take into account the problem domain, the design of the learning agent and the perception of the domain user. Therefore, already in the modeling phase, more attention must be paid to make the learning element of the agent adaptable by an operator. Domain modeling and meta-modeling methods could help to make inner processes of the agent more accessible. In addition, the knowledge gained should be made reusable for future agents in similar environments. To begin with, the existing methods for modeling agent systems and the underlying concepts will be evaluated, based on the requirements for different industrial scenarios. The methods are then compiled into a framework that allows for the description and modeling of such systems in terms of adaptability to a problem domain. Where necessary, new methods or tools will be introduced to close the gap between inconsistent modeling artifacts. The framework shall then be used to build learning agents for real-life scenarios and observe their application in a case study. The results will be used to assess the quality of the adapted knowledge base and compare it to a manual knowledge modeling process.},
author = {Hoser, Moritz},
booktitle = {Proc. - 2019 ACM/IEEE 22nd Int. Conf. Model Driven Eng. Lang. Syst. Companion, Model. 2019},
doi = {10.1109/MODELS-C.2019.00101},
isbn = {9781728151250},
keywords = {Adaptive Learning Agents,Domain modeling,Knowledge Engineering,Multi-modeling},
month = {sep},
pages = {660--665},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Modeling adaptive learning agents for domain knowledge transfer}},
year = {2019}
}
@article{Tao2019,
abstract = {With the fast growth of artificial intelligence and big data computing technologies, more and more software service systems have been developed using diverse machine learning models and technologies to make business and intelligent decisions based on their multimedia input to achieve intelligent features, such as image recognition, recommendation, decision making, prediction, etc. Nevertheless, there are increasing quality problems resulting in erroneous testing costs in enterprises and businesses. Existing work seldom discusses how to perform testing and quality validation for AI software. This paper focuses on quality validation for AI software function features. The paper provides our understanding of AI software testing for new features and requirements. In addition, current AI software testing categories are presented and different testing approaches are discussed. Moreover, test quality assessment and criteria analysis are illustrated. Furthermore, a practical study on quality validation for an image recognition system is performed through a metamorphic testing method. Study results show the feasibility and effectiveness of the approach.},
author = {Tao, Chuanqi and Gao, Jerry and Wang, Tiexin},
doi = {10.1109/ACCESS.2019.2937107},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tao, Gao, Wang - 2019 - Testing and Quality Validation for AI Software-Perspectives, Issues, and Practices.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {AI software quality validation,AI testing,testing AI software},
pages = {120164--120175},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Testing and Quality Validation for AI Software-Perspectives, Issues, and Practices}},
volume = {7},
year = {2019}
}
@book{Piedra2020,
abstract = {Knowledge management plays a crucial role in initiatives that promotes the discovery and sharing of cultural and heritage informational resources from diverse and autonomous organizations and initiatives. Information in this domain is heterogeneous, distributed, multi-lingual, comes in unstructured formats and large quantities, is strongly contextualized by time and place is created collaboratively. These challenges can be undertaken using semantic technologies. Semantic Web approach and Linked Data technologies are a catalyst for cross-domain and cross-organizational semantic data interoperability and data integration. In this regard, this work will look at the interaction between knowledge management and linked open data within the context of cultural and heritage data with a particular focus on the concept of music data. This work will discuss, among other things, how Semantic Knowledge Graphs based on linked data can contribute to enhancing knowledge management and increase productivity, in actions related with cultural data enrichment, data exploration, knowledge discovery, cultural data reuse, and data visualization. By representing information using data models and open semantic standards, data integration and reasoning can be applied to the cultural data in a well-defined way.},
author = {Piedra, Nelson and {Mosquera Ar{\'{e}}valo}, Jean Pa{\'{u}}l},
booktitle = {Adv. Intell. Syst. Comput.},
doi = {10.1007/978-3-030-33547-2_12},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Piedra, Mosquera Ar{\'{e}}valo - 2020 - Linked Data and Musical Information to Improvement the Cultural and Heritage Knowledge Management.pdf:pdf;:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Piedra, Mosquera Ar{\'{e}}valo - 2020 - Linked Data and Musical Information to Improvement the Cultural and Heritage Knowledge Management(2).pdf:pdf},
isbn = {9783030335465},
issn = {21945365},
keywords = {Cultural heritage,Knowledge graphs,Linked open data,Music,Ontologies},
number = {Cimps},
pages = {141--155},
title = {{Linked Data and Musical Information to Improvement the Cultural and Heritage Knowledge Management}},
volume = {1071},
year = {2020}
}
@article{Zhang,
abstract = {Deep learning applications become increasingly popular in important domains such as self-driving systems and facial identity systems. Defective deep learning applications may lead to catastrophic consequences. Although recent research eeorts were made on testing and debugging deep learning applications, the characteristics of deep learning defects have never been studied. To oll this gap, we studied deep learning applications built on top of TensorFlow and collected program bugs related to TensorFlow from StackOver-ow QA pages and Github projects. We extracted information from QA pages, commit messages, pull request messages, and issue discussions to examine the root causes and symptoms of these bugs. We also studied the strategies deployed by TensorFlow users for bug detection and localization. These endings help researchers and TensorFlow users to gain a better understanding of coding defects in TensorFlow programs and point out a new direction for future research. CCS CONCEPTS • Software and its engineering → Software defect analysis; KEYWORDS},
author = {Zhang, Yuhao and Chen, Yifan and Cheung, Shing-Chi and Xiong, Yingfei and Zhang, Lu},
doi = {10.1145/3213846.3213866},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - Unknown - An Empirical Study on TensorFlow Program Bugs.pdf:pdf},
isbn = {9781450356992},
pages = {12},
publisher = {ACM},
title = {{An Empirical Study on TensorFlow Program Bugs}},
url = {https://doi.org/10.1145/3213846.3213866}
}
@inproceedings{Ribeiro2016,
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an in-terpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
address = {New York, NY, USA},
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
booktitle = {Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ribeiro, Singh, Guestrin - Unknown - Why Should I Trust You Explaining the Predictions of Any Classifier.pdf:pdf},
isbn = {9781450342322},
publisher = {ACM},
title = {{"Why Should I Trust You?" Explaining the Predictions of Any Classifier}},
url = {http://dx.doi.org/10.1145/2939672.2939778}
}
@misc{zoo-caffe-21,
howpublished = {http://caffe.berkeleyvision.org/model{\_}zoo.html},
title = {{Caffe | Model Zoo}},
url = {http://caffe.berkeleyvision.org/model{\_}zoo.html},
urldate = {2021-07-19}
}
@article{Adhikari2018,
abstract = {As machine learning models become more accurate, they typically become more
complex and uninterpretable by humans. The black-box character of these models
holds back its acceptance in practice, especially in high-risk domains where
the consequences of failure could be catastrophic such as health-care or
defense. Providing understandable and useful explanations behind ML models or
predictions can increase the trust of the user. Example-based reasoning, which
entails leveraging previous experience with analogous tasks to make a decision,
is a well known strategy for problem solving and justification. This work
presents a new explanation extraction method called LEAFAGE, for a prediction
made by any black-box ML model. The explanation consists of the visualization
of similar examples from the training set and the importance of each feature.
Moreover, these explanations are contrastive which aims to take the
expectations of the user into account. LEAFAGE is evaluated in terms of
fidelity to the underlying black-box model and usefulness to the user. The
results showed that LEAFAGE performs overall better than the current
state-of-the-art method LIME in terms of fidelity, on ML models with non-linear
decision boundary. A user-study was conducted which focused on revealing the
differences between example-based and feature importance-based explanations. It
showed that example-based explanations performed significantly better than
feature importance-based explanation, in terms of perceived transparency,
information sufficiency, competence and confidence. Counter-intuitively, when
the gained knowledge of the participants was tested, it showed that they
learned less about the black-box model after seeing a feature importance-based
explanation than seeing no explanation at all. The participants found feature
importance-based explanation vague and hard to generalize it to other
instances.},
archivePrefix = {arXiv},
arxivId = {1812.09044},
author = {Adhikari, Ajaya and Tax, D. M. J and Satta, Riccardo and Fath, Matthias},
eprint = {1812.09044},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Adhikari et al. - 2018 - LEAFAGE Example-based and Feature importance-based Explanationsfor Black-box ML models.pdf:pdf},
journal = {IEEE Int. Conf. Fuzzy Syst.},
keywords = {eXplainable AI,empirical study,example-based reasoning},
month = {dec},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{LEAFAGE: Example-based and Feature importance-based Explanationsfor Black-box ML models}},
url = {https://arxiv.org/abs/1812.09044v3},
volume = {2019-June},
year = {2018}
}
@techreport{Fulton2018,
abstract = {Formal verification provides a high degree of confidence in safe system operation, but only if reality matches the verified model. Although a good model will be accurate most of the time, even the best models are incomplete. This is especially true in Cyber-Physical Systems because high-fidelity physical models of systems are expensive to develop and often intractable to verify. Conversely, reinforcement learning-based controllers are lauded for their flexibility in unmodeled environments , but do not provide guarantees of safe operation. This paper presents an approach for provably safe learning that provides the best of both worlds: the exploration and optimization capabilities of learning along with the safety guarantees of formal verification. Our main insight is that formal verification combined with verified runtime monitoring can ensure the safety of a learning agent. Verification results are preserved whenever learning agents limit exploration within the confounds of verified control choices as long as observed reality comports with the model used for off-line verification. When a model violation is detected, the agent abandons efficiency and instead attempts to learn a control strategy that guides the agent to a modeled portion of the state space. We prove that our approach toward incorporating knowledge about safe control into learning systems preserves safety guarantees, and demonstrate that we retain the empirical performance benefits provided by reinforcement learning. We also explore various points in the design space for these justified speculative controllers in a simple model of adaptive cruise control model for autonomous cars.},
author = {Fulton, Nathan and Platzer, Andr{\'{e}}},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fulton, Platzer - 2018 - Safe Reinforcement Learning via Formal Methods Toward Safe Control Through Proof and Learning.pdf:pdf},
keywords = {Robotics Track},
title = {{Safe Reinforcement Learning via Formal Methods: Toward Safe Control Through Proof and Learning}},
url = {www.aaai.org},
year = {2018}
}
@incollection{sutton1992introduction,
author = {Sutton, Richard S},
booktitle = {Reinf. Learn.},
pages = {1--3},
publisher = {Springer},
title = {{Introduction: The challenge of reinforcement learning}},
year = {1992}
}
@article{Kuwajima2020,
abstract = {Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that employ machine learning and deep learning models, such as automated driving vehicles. In order to use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system through engineering processes. However, thus far, no such widely accepted engineering concepts or frameworks have been established for these systems. The key to using a machine learning model in a deductively engineered system is decomposing the data-driven training of machine learning models into requirement, design, and verification, particularly for machine learning models used in safety-critical systems. Simultaneously, open problems and relevant technical fields are not organized in a manner that enables researchers to select a theme and work on it. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems—that is, in terms of requirement, design, and verification of machine learning models and systems—as well as discuss related works and research directions, using automated driving vehicles as an example. Our results show that machine learning models are characterized by a lack of requirements specification, lack of design specification, lack of interpretability, and lack of robustness. We also perform a gap analysis on a conventional system quality standard SQuaRE with the characteristics of machine learning models to study quality models for machine learning systems. We find that a lack of requirements specification and lack of robustness have the greatest impact on conventional quality models.},
archivePrefix = {arXiv},
arxivId = {1904.00001},
author = {Kuwajima, Hiroshi and Yasuoka, Hirotoshi and Nakae, Toshihiro},
doi = {10.1007/s10994-020-05872-w},
eprint = {1904.00001},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuwajima, Yasuoka, Nakae - 2020 - Engineering problems in machine learning systems.pdf:pdf},
issn = {15730565},
journal = {Mach. Learn.},
keywords = {Automated driving,Machine learning,Quality models,Safety critical systems,Software engineering,Systems engineering},
month = {may},
number = {5},
pages = {1103--1126},
publisher = {Springer},
title = {{Engineering problems in machine learning systems}},
volume = {109},
year = {2020}
}
@article{Kuwajima2020a,
abstract = {Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that employ machine learning and deep learning models, such as automated driving vehicles. In order to use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system through engineering processes. However, thus far, no such widely accepted engineering concepts or frameworks have been established for these systems. The key to using a machine learning model in a deductively engineered system is decomposing the data-driven training of machine learning models into requirement, design, and verification, particularly for machine learning models used in safety-critical systems. Simultaneously, open problems and relevant technical fields are not organized in a manner that enables researchers to select a theme and work on it. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems—that is, in terms of requirement, design, and verification of machine learning models and systems—as well as discuss related works and research directions, using automated driving vehicles as an example. Our results show that machine learning models are characterized by a lack of requirements specification, lack of design specification, lack of interpretability, and lack of robustness. We also perform a gap analysis on a conventional system quality standard SQuaRE with the characteristics of machine learning models to study quality models for machine learning systems. We find that a lack of requirements specification and lack of robustness have the greatest impact on conventional quality models.},
archivePrefix = {arXiv},
arxivId = {1904.00001},
author = {Kuwajima, Hiroshi and Yasuoka, Hirotoshi and Nakae, Toshihiro},
doi = {10.1007/s10994-020-05872-w},
eprint = {1904.00001},
issn = {15730565},
journal = {Mach. Learn.},
keywords = {Automated driving,Machine learning,Quality models,Safety critical systems,Software engineering,Systems engineering},
month = {may},
number = {5},
pages = {1103--1126},
publisher = {Springer},
title = {{Engineering problems in machine learning systems}},
url = {https://doi.org/10.1007/s10994-020-05872-w},
volume = {109},
year = {2020}
}
@article{Combemale2020,
author = {Combemale, Benoit and Kienzle, J{\"{o}}rg and Mussbacher, Gunter and Ali, Hyacinth and Amyot, Daniel and Bagherzadeh, Mojtaba and Batot, Edouard and Bencomo, Nelly and Benni, Benjamin and Bruel, Jean-Michel and Cabot, Jordi and Cheng, Betty H C and Collet, Philippe and Engels, Gregor and Heinrich, Robert and J{\'{e}}z{\'{e}}quel, Jean-Marc and Koziolek, Anne and Reussner, Ralf and Sahraoui, Houari and Saini, Rijul and Sallou, June and Stinckwich, Serge and Syriani, Eugene and Wimmer, Manuel},
doi = {10.1109/MS.2020.2995125ï},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Combemale et al. - 2020 - A Hitchhiker's Guide to Model-Driven Engineering for Data-Centric Systems.pdf:pdf},
pages = {1--9},
title = {{A Hitchhiker's Guide to Model-Driven Engineering for Data-Centric Systems }},
url = {https://hal.inria.fr/hal-02612087},
year = {2020}
}
@inproceedings{Breuker2014,
abstract = {Graphical models and general purpose inference algorithms are powerful tools for moving from imperative towards declarative specification of machine learning problems. Although graphical models define the principle information necessary to adapt inference algorithms to specific probabilistic models, entirely model-driven development is not yet possible. However, generating executable code from graphical models could have several advantages. It could reduce the skills necessary to implement probabilistic models and may speed up development processes. Both advantages address pressing industry needs. They come along with increased supply of data scientist labor, the demand of which cannot be fulfilled at the moment. To explore the opportunities of model-driven big data analytics, I review the main modeling languages used in machine learning as well as inference algorithms and corresponding software implementations. Gaps hampering direct code generation from graphical models are identified and closed by proposing an initial conceptualization of a domain-specific modeling language. {\textcopyright} 2014 IEEE.},
author = {Breuker, Dominic},
booktitle = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
doi = {10.1109/HICSS.2014.101},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Towards model-driven engineering for big data analytics–an exploratory analysis of domain- specific languages for machine learning.pdf:pdf},
isbn = {9781479925049},
issn = {15301605},
pages = {758--767},
publisher = {IEEE Computer Society},
title = {{Towards model-driven engineering for big data analytics - An exploratory analysis of domain-specific languages for machine learning}},
year = {2014}
}
@techreport{Deepmind,
abstract = {In many real-world reinforcement learning (RL) problems, besides optimizing the main objective function, an agent must concurrently avoid violating a number of constraints. In particular, besides optimizing performance, it is crucial to guarantee the safety of an agent during training as well as deployment (e.g., a robot should avoid taking actions-exploratory or not-which irrevocably harm its hardware). To incorporate safety in RL, we derive algorithms under the framework of constrained Markov decision processes (CMDPs), an extension of the standard Markov decision processes (MDPs) augmented with constraints on expected cumulative costs. Our approach hinges on a novel Lyapunov method. We define and present a method for constructing Lyapunov functions, which provide an effective way to guarantee the global safety of a behavior policy during training via a set of local linear constraints. Leveraging these theoretical underpinnings, we show how to use the Lyapunov approach to systematically transform dynamic programming (DP) and RL algorithms into their safe counterparts. To illustrate their effectiveness, we evaluate these algorithms in several CMDP planning and decision-making tasks on a safety benchmark domain. Our results show that our proposed method significantly outperforms existing baselines in balancing constraint satisfaction and performance.},
author = {Deepmind, Yinlam Chow and Nachum, Ofir and Brain, Google and Ghavamzadeh, Mohammad and Duenez, Edgar and Deepmind, Guzman},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Deepmind et al. - Unknown - A Lyapunov-based Approach to Safe Reinforcement Learning.pdf:pdf},
title = {{A Lyapunov-based Approach to Safe Reinforcement Learning}}
}
@article{Gu2019,
abstract = {Deep learning-based techniques have achieved state-of-the-art performance on
a wide variety of recognition and classification tasks. However, these networks
are typically computationally expensive to train, requiring weeks of
computation on many GPUs; as a result, many users outsource the training
procedure to the cloud or rely on pre-trained models that are then fine-tuned
for a specific task. In this paper we show that outsourced training introduces
new security risks: an adversary can create a maliciously trained network (a
backdoored neural network, or a $\backslash$emph{\{}BadNet{\}}) that has state-of-the-art
performance on the user's training and validation samples, but behaves badly on
specific attacker-chosen inputs. We first explore the properties of BadNets in
a toy example, by creating a backdoored handwritten digit classifier. Next, we
demonstrate backdoors in a more realistic scenario by creating a U.S. street
sign classifier that identifies stop signs as speed limits when a special
sticker is added to the stop sign; we then show in addition that the backdoor
in our US street sign detector can persist even if the network is later
retrained for another task and cause a drop in accuracy of {\{}25{\}}$\backslash${\%} on average
when the backdoor trigger is present. These results demonstrate that backdoors
in neural networks are both powerful and---because the behavior of neural
networks is difficult to explicate---stealthy. This work provides motivation
for further research into techniques for verifying and inspecting neural
networks, just as we have developed tools for verifying and debugging software.},
archivePrefix = {arXiv},
arxivId = {1708.06733},
author = {Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
eprint = {1708.06733},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu, Dolan-Gavitt, Garg - 2017 - BadNets Identifying Vulnerabilities in the Machine Learning Model Supply Chain.pdf:pdf},
month = {aug},
title = {{BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain}},
url = {https://arxiv.org/abs/1708.06733v2},
year = {2017}
}
@inproceedings{Levinson2011,
abstract = {In order to achieve autonomous operation of a vehicle in urban situations with unpredictable traffic, several realtime systems must interoperate, including environment perception, localization, planning, and control. In addition, a robust vehicle platform with appropriate sensors, computational hardware, networking, and software infrastructure is essential. {\textcopyright} 2011 IEEE.},
author = {Levinson, Jesse and Askeland, Jake and Becker, Jan and Dolson, Jennifer and Held, David and Kammel, Soeren and Kolter, J. Zico and Langer, Dirk and Pink, Oliver and Pratt, Vaughan and Sokolsky, Michael and Stanek, Ganymed and Stavens, David and Teichman, Alex and Werling, Moritz and Thrun, Sebastian},
booktitle = {IEEE Intell. Veh. Symp. Proc.},
doi = {10.1109/IVS.2011.5940562},
pages = {163--168},
title = {{Towards fully autonomous driving: Systems and algorithms}},
year = {2011}
}
@inproceedings{Nguyen2019,
abstract = {Manual classification methods of metamodel repositories require highly trained personnel and the results are usually influenced by the subjectivity of human perception. Therefore, automated metamodel classification is very desirable and stringent. In this work, Machine Learning techniques have been employed for metamodel automated classification. In particular, a tool implementing a feed-forward neural network is introduced to classify metamodels. An experimental evaluation over a dataset of 555 metamodels demonstrates that the technique permits to learn from manually classified data and effectively categorize incoming unlabeled data with a considerably high prediction rate: the best performance comprehends 95.40{\%} as success rate, 0.945 as precision, 0.938 as recall, and 0.942 as F1 score.},
author = {Nguyen, Phuong T. and {Di Rocco}, Juri and {Di Ruscio}, Davide and Pierantonio, Alfonso and Iovino, Ludovico},
booktitle = {Proc. - 2019 ACM/IEEE 22nd Int. Conf. Model Driven Eng. Lang. Syst. Model. 2019},
doi = {10.1109/MODELS.2019.00011},
isbn = {9781728125350},
keywords = {Machine learning,metamodel classification,metamodel repositories},
month = {sep},
pages = {272--282},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Automated Classification of Metamodel Repositories: A Machine Learning Approach}},
year = {2019}
}
@article{iso15026,
doi = {10.1109/IEEESTD.2014.6948215},
journal = {IEEE Std 15026-1-2014},
pages = {1--45},
title = {{IEEE Standard Adoption of ISO/IEC 15026-1--Systems and Software Engineering--Systems and Software Assurance--Part 1: Concepts and Vocabulary}},
year = {2014}
}
@article{Egert2020,
abstract = {Artificial intelligence (AI) and machine learning (ML) have the potential to improve multiple facets of medical practice, including diagnosis of disease, surgical training, clinical outcomes, and access to healthcare. There have been various applications of this technology to surgical fields. AI and ML have been used to evaluate a surgeon's technical skill. These technologies can detect instrument motion, recognize patterns in video recordings, and track the physical motion, eye movements, and cognitive function of the surgeon. These modalities also aid in the advancement of robotic surgical training. The da Vinci Standard Surgical System developed a recording and playback system to help trainees receive tactical feedback to acquire more precision when operating. ML has shown promise in recognizing and classifying complex patterns on diagnostic images and within pathologic tissue analysis. This allows for more accurate and efficient diagnosis and treatment. Artificial neural networks are able to analyze sets of symptoms in conjunction with labs, imaging, and exam findings to determine the likelihood of a diagnosis or outcome. Telemedicine is another use of ML and AI that uses technology such as voice recognition to deliver health care remotely. Limitations include the need for large data sets to program computers to create the algorithms. There is also the potential for misclassification of data points that do not follow the typical patterns learned by the machine. As more applications of AI and ML are developed for the surgical field, further studies are needed to determine feasibility, efficacy, and cost.},
author = {Egert, Melissa and Steward, James E. and Sundaram, Chandru P.},
doi = {10.1007/S13193-020-01166-8},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Egert, Steward, Sundaram - 2020 - Machine Learning and Artificial Intelligence in Surgical Fields.pdf:pdf},
issn = {0976-6952},
journal = {Indian J. Surg. Oncol. 2020 114},
keywords = {Oncology,Surgery,Surgical Oncology},
month = {jul},
number = {4},
pages = {573--577},
publisher = {Springer},
title = {{Machine Learning and Artificial Intelligence in Surgical Fields}},
url = {https://link.springer.com/article/10.1007/s13193-020-01166-8},
volume = {11},
year = {2020}
}
@article{Henriksson2018,
abstract = {Machine learning (ML) applications generate a continuous stream of success stories from various domains. ML enables many novel applications, also in safety-critical contexts. However, the functional safety standards such as ISO 26262 did not evolve to cover ML. We conduct an exploratory study on which parts of ISO 26262 represent the most critical gaps between safety engineering and ML development. While this paper only reports the first steps toward a larger research endeavor, we report three adaptations that are critically needed to allow ISO 26262 compliant engineering, and related suggestions on how to evolve the standard. CCS CONCEPTS • Computing methodologies → Machine learning; • Software and its engineering → Software safety; KEYWORDS automotive software, machine learning, safety, interview study ACM Reference Format: Jens Henriksson, Markus Borg, and Cristofer Englund. 2018. Automotive safety and machine learning: Initial results from a study on how to adapt the ISO 26262 safety standard.},
archivePrefix = {arXiv},
arxivId = {1604.07316},
author = {Henriksson, Jens and Borg, Markus and Englund, Cristofer},
doi = {10.1145/3194085.3194090},
eprint = {1604.07316},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Henriksson, Borg, Englund - 2018 - Automotive safety and machine learning Initial results from a study on how to adapt the ISO 26262 saf.pdf:pdf},
isbn = {9781450357395},
publisher = {ACM},
title = {{Automotive safety and machine learning: Initial results from a study on how to adapt the ISO 26262 safety standard}},
url = {https://doi.org/10.1145/3194085.3194090},
year = {2018}
}
@article{Lessmann2015,
author = {Lessmann, Stefan and Baesens, Bart and Seow, Hsin-Vonn and Thomas, Lyn C},
doi = {10.1016/j.ejor.2015.05.030},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lessmann et al. - 2015 - Benchmarking state-of-the-art classification algorithms for credit scoring An update of research.pdf:pdf},
journal = {Eur. J. Oper. Res.},
keywords = {Credit scoring,Data mining,Forecasting benchmark,OR in banking},
pages = {124--136},
title = {{Benchmarking state-of-the-art classification algorithms for credit scoring: An update of research}},
url = {http://dx.doi.org/10.1016/j.ejor.2015.05.030},
volume = {247},
year = {2015}
}
@article{Mahendran2015,
abstract = {Image representations, from SIFT and Bag of Visual Words to Convolutional
Neural Networks (CNNs), are a crucial component of almost any image
understanding system. Nevertheless, our understanding of them remains limited.
In this paper we conduct a direct analysis of the visual information contained
in representations by asking the following question: given an encoding of an
image, to which extent is it possible to reconstruct the image itself? To
answer this question we contribute a general framework to invert
representations. We show that this method can invert representations such as
HOG and SIFT more accurately than recent alternatives while being applicable to
CNNs too. We then use this technique to study the inverse of recent
state-of-the-art CNN image representations for the first time. Among our
findings, we show that several layers in CNNs retain photographically accurate
information about the image, with different degrees of geometric and
photometric invariance.},
archivePrefix = {arXiv},
arxivId = {1412.0035},
author = {Mahendran, Aravindh and Vedaldi, Andrea},
eprint = {1412.0035},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahendran, Vedaldi - 2014 - Understanding Deep Image Representations by Inverting Them.pdf:pdf},
journal = {Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.},
month = {nov},
pages = {5188--5196},
publisher = {IEEE Computer Society},
title = {{Understanding Deep Image Representations by Inverting Them}},
url = {https://arxiv.org/abs/1412.0035v1},
volume = {07-12-June-2015},
year = {2014}
}
@inproceedings{Hartmann2019,
abstract = {Although artificial intelligence and machine learning are currently extremely fashionable, applying machine learning on real-life problems remains very challenging. Data scientists need to evaluate various learning algorithms and tune their numerous parameters, based on their assumptions and experience, against concrete problems and training data sets. This is a long, tedious, and resource expensive task. Meta-learning is a recent technique to overcome, i.e. automate this problem. It aims at using machine learning itself to automatically learn the most appropriate algorithms and parameters for a machine learning problem. As it turns out, there are many parallels between meta-modelling - in the sense of model-driven engineering - and meta-learning. Both rely on abstractions, the meta data, to model a predefined class of problems and to define the variabilities of the models conforming to this definition. Both are used to define the output and input relationships and then fitting the right models to represent that behaviour. In this paper, we envision how a meta-model for meta-learning can look like. We discuss possible variabilities, for what types of learning it could be appropriate for, how concrete learning models can be generated from it, and how models can be finally selected. Last but not least, we discuss a possible integration into existing modelling tools.},
author = {Hartmann, Thomas and Moawad, Assaad and Schockaert, Cedric and Fouquet, Francois and {Le Traon}, Yves},
booktitle = {Proc. - 2019 ACM/IEEE 22nd Int. Conf. Model Driven Eng. Lang. Syst. Model. 2019},
doi = {10.1109/MODELS.2019.00014},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Meta-Modelling Meta-Learning.pdf:pdf},
isbn = {9781728125350},
keywords = {AutoML,meta-learning,meta-modelling,modelling framework},
month = {sep},
pages = {300--305},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Meta-Modelling Meta-Learning}},
year = {2019}
}
@techreport{EllDocu,
abstract = {We present VERIFAI, a software toolkit for the formal design and analysis of systems that include artificial intelligence (AI) and machine learning (ML) components. VERIFAI particularly addresses challenges with applying formal methods to ML components such as perception systems based on deep neural networks, as well as systems containing them, and to model and analyze system behavior in the presence of environment uncertainty. We describe the initial version of VERIFAI, which centers on simulation-based verification and synthesis, guided by formal models and specifications. We give examples of several use cases, including temporal-logic falsification, model-based systematic fuzz testing , parameter synthesis, counterexample analysis, and data set augmentation.},
author = {{Ell Docu}, W and Dreossi, Tommaso and Fremont, Daniel J and Ghosh, Shromona and Kim, Edward and Ravanbakhsh, Hadi and Vazquez-Chanlatte, Marcell and Seshia, Sanjit A},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ell Docu et al. - Unknown - Con sis te n t Comple te VERIFAI A Toolkit for the Formal Design and Analysis of Artificial Intelligence-Ba.pdf:pdf},
keywords = {Artificial,Autonomous,Cyber-,Falsification {\textperiodcentered},Formal,Intelligence {\textperiodcentered},Learning {\textperiodcentered},Machine,Methods {\textperiodcentered},Physical,Simulation {\textperiodcentered},Sys-tems {\textperiodcentered},Vehicles},
title = {{Con sis te n t * Comple te VERIFAI: A Toolkit for the Formal Design and Analysis of Artificial Intelligence-Based Systems}}
}
@article{Ashmore2018,
abstract = {Training data has a significant influence on the behaviour of an artificial intelligence algorithm developed using machine learning techniques. Consequently, any argument that the trained algorithm is, in some way, fit for purpose ought to include consideration of data as an entity in its own right. We describe some simple techniques that can provide domain experts and algorithm developers with insights into training data and which can be implemented without specialist computer hardware. Specifically, we consider sampling density, test case generation and monitoring for distribution shift. The techniques are illustrated using example data sets from the University of California, Irvine, Machine Learning repository.},
author = {Ashmore, Rob and Hill, Matthew},
doi = {10.1007/978-3-319-99229-7_33},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashmore, Hill - 2018 - “Boxing Clever” Practical Techniques for Gaining Insights into Training Data and Monitoring Distribution Shift.pdf:pdf},
journal = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
keywords = {Artificial intelligence,Distribution shift,Machine learning,Test cases,Training data},
month = {sep},
pages = {393--405},
publisher = {Springer, Cham},
title = {{“Boxing Clever”: Practical Techniques for Gaining Insights into Training Data and Monitoring Distribution Shift}},
url = {https://link.springer.com/chapter/10.1007/978-3-319-99229-7{\_}33},
volume = {11094 LNCS},
year = {2018}
}
@article{Waa2018,
abstract = {End-users of machine learning-based systems benefit from measures that quantify the trustworthiness of the underlying models. Measures like accuracy provide for a general sense of model performance, but offer no detailed information on specific model outputs. Probabilistic outputs, on the other hand, express such details, but they are not available for all types of machine learning, and can be heavily influenced by bias and lack of representative training data. Further, they are often difficult to understand for non-experts. This study proposes an intuitive certainty measure (ICM) that produces an accurate estimate of how certain a machine learning model is for a specific output, based on errors it made in the past. It is designed to be easily explainable to non-experts and to act in a predictable, reproducible way. ICM was tested on four synthetic tasks solved by support vector machines, and a real-world task solved by a deep neural network. Our results show that ICM is both more accurate and intuitive than related approaches. Moreover, ICM is neutral with respect to the chosen machine learning model, making it widely applicable.},
author = {{Van Der Waa}, Jasper and {Van Diggelen}, Jurriaan and Neerincx, Mark and Raaijmakers, Stephan},
doi = {10.5220/0006542603140321},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Der Waa et al. - 2018 - ICM An Intuitive Model Independent and Accurate Certainty Measure for Machine Learning(2).pdf:pdf},
isbn = {9789897582752},
keywords = {Certainty,Explainable Artificial Intelligence,Machine learning,Trust,Uncertainty},
title = {{ICM: An Intuitive Model Independent and Accurate Certainty Measure for Machine Learning}},
year = {2018}
}
@article{Morikawa2020,
abstract = {In recent years, curial incidents and accidents have been reported due to un-intended control caused by misjudgment of statistical machine learning (SML), which include deep learning. The international functional safety standards for Electric/Electronic/Programmable (E/E/P) systems have been widely spread to improve safety. However, most of them do not recom-mended to use SML in safety critical systems so far. In practical the new concepts and methods are urgently required to enable SML to be safely used in safety critical systems. In this paper, we organize five kinds of technical safety concepts (TSCs) for SML components toward accordance with functional safety standards. We discuss not only quantitative evaluation criteria, but also development process based on XAI (eXplainable Artificial Intelligence) and Automotive SPICE to improve explainability and reliability in development phase. Fi-nally, we briefly compare the TSCs in cost and difficulty, and expect to en-courage further discussion in many communities and domain.},
archivePrefix = {arXiv},
arxivId = {2008.01263},
author = {Morikawa, Akihisa and Matsubara, Yutaka},
eprint = {2008.01263},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Morikawa, Matsubara - 2020 - Safety design concepts for statistical machine learning components toward accordance with functional safety.pdf:pdf},
keywords = {Functional safety,Safety design concept,Statistical machine learning},
month = {aug},
title = {{Safety design concepts for statistical machine learning components toward accordance with functional safety standards}},
url = {http://arxiv.org/abs/2008.01263},
year = {2020}
}
@techreport{Hernandez-Orallo,
abstract = {AI safety often analyses a risk or safety issue, such as interruptibility, under a particular AI paradigm, such as reinforcement learning. But what is an AI paradigm and how does it affect the understanding and implications of the safety issue? Is AI safety research covering the most representative paradigms and the right combinations of paradigms with safety issues? Will current research directions in AI safety be able to anticipate more capable and powerful systems yet to come? In this paper we analyse these questions, introducing a distinction between two types of paradigms in AI: artefacts and techniques. We then use experimental data of research and media documents from AI Topics, an official publication of the AAAI, to examine how safety research is distributed across artefacts and techniques. We observe that AI safety research is not sufficiently antici-patory, and is heavily weighted towards certain research paradigms. We identify a need for AI safety to be more explicit about the artefacts and techniques for which a particular issue may be applicable, in order to identify gaps and cover a broader range of issues.},
author = {Hern{\'{a}}ndez-Orallo, Jose and Mart{\'{i}}nez-Plumed, Fernando and Avin, Shahar and Whittlestone, Jess and Se{\'{a}}n´o, Se{\'{a}}n Se{\'{a}}n´ and Eigeartaigh, ´},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hern{\'{a}}ndez-Orallo et al. - Unknown - AI Paradigms and AI Safety Mapping Artefacts and Techniques to Safety Issues.pdf:pdf},
title = {{AI Paradigms and AI Safety: Mapping Artefacts and Techniques to Safety Issues}},
url = {https://github.com/nandomp/AIParadigmsSafety.}
}
@article{Zolotas2019,
abstract = {Flexible or bottom-up model-driven engineering (MDE) is an emerging approach to domain and systems modelling. Domain experts, who have detailed domain knowledge, typically lack the technical expertise to transfer this knowledge using traditional MDE tools. Flexible MDE approaches tackle this challenge by promoting the use of simple drawing tools to increase the involvement of domain experts in the language definition process. In such approaches, no metamodel is created upfront, but instead the process starts with the definition of example models that will be used to infer the metamodel. Pre-defined metamodels created by MDE experts may miss important concepts of the domain and thus restrict their expressiveness. However, the lack of a metamodel, that encodes the semantics of conforming models has some drawbacks, among others that of having models with elements that are unintentionally left untyped. In this paper, we propose the use of classification algorithms to help with the inference of such untyped elements. We evaluate the proposed approach in a number of random generated example models from various domains. The correct type prediction varies from 23 to 100{\%} depending on the domain, the proportion of elements that were left untyped and the prediction algorithm used. Keywords Model-driven engineering {\textperiodcentered} Flexible model-driven engineering {\textperiodcentered} Bottom-up metamodelling {\textperiodcentered} Type inference {\textperiodcentered} Classification and regression trees {\textperiodcentered} Random forests},
author = {Zolotas, Athanasios and Matragkas, Nicholas and Devlin, {\textperiodcentered} Sam and Kolovos, Dimitrios S and Richard, {\textperiodcentered} and Paige, F},
doi = {10.1007/s10270-018-0658-5},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zolotas et al. - 2019 - Type inference in flexible model-driven engineering using classification algorithms.pdf:pdf},
journal = {Softw. Syst. Model.},
keywords = {Bottom-up metamodelling,Classification and regression trees,Flexible model-driven engineering,Model-driven engineering,Random forests,Type inference},
pages = {345--366},
title = {{Type inference in flexible model-driven engineering using classification algorithms}},
url = {https://doi.org/10.1007/s10270-018-0658-5},
volume = {18},
year = {2019}
}
@book{mitchell1997machine,
author = {Mitchell, T M},
isbn = {9780070428072},
publisher = {McGraw-Hill Education},
series = {McGraw-Hill international editions - computer science series},
title = {{Machine Learning}},
url = {https://books.google.ca/books?id=xOGAngEACAAJ},
year = {1997}
}
@techreport{koopman2016challenges,
abstract = {Software testing is all too often simply a bug hunt rather than a well-considered exercise in ensuring quality. A more methodical approach than a simple cycle of system-level test-fail-patch-test will be required to deploy safe autonomous vehicles at scale. The ISO 26262 development V process sets up a framework that ties each type of testing to a corresponding design or requirement document, but presents challenges when adapted to deal with the sorts of novel testing problems that face autonomous vehicles. This paper identifies five major challenge areas in testing according to the V model for autonomous vehicles: driver out of the loop, complex requirements, non-deterministic algorithms, inductive learning algorithms, and fail-operational systems. General solution approaches that seem promising across these different challenge areas include: phased deployment using successively relaxed operational scenarios, use of a monitor/actuator pair architecture to separate the most complex autonomy functions from simpler safety functions, and fault injection as a way to perform more efficient edge case testing. While significant challenges remain in safety-certifying the type of algorithms that provide high-level autonomy themselves, it seems within reach to instead architect the system and its accompanying design process to be able to employ existing software safety approaches.},
author = {Koopman, Philip and Wagner, Michael},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Challenges in Autonomous Vehicle testing and validation.pdf:pdf},
pages = {15--24},
title = {{Challenges in Autonomous Vehicle Testing and Validation}},
year = {2016}
}
@techreport{Foster2014,
abstract = {A large number of papers are appearing in the biomedical engineering literature that describe the use of machine learning techniques to develop classifiers for detection or diagnosis of disease. However, the usefulness of this approach in developing clinically validated diagnostic techniques so far has been limited and the methods are prone to overfitting and other problems which may not be immediately apparent to the investigators. This commentary is intended to help sensitize investigators as well as readers and reviewers of papers to some potential pitfalls in the development of classifiers, and suggests steps that researchers can take to help avoid these problems. Building classifiers should be viewed not simply as an add-on statistical analysis, but as part and parcel of the experimental process. Validation of classifiers for diagnostic applications should be considered as part of a much larger process of establishing the clinical validity of the diagnostic technique.},
author = {Foster, Kenneth R and Koprowski, Robert and Skufca, Joseph D},
doi = {10.1186/1475-925X-13-94},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Foster, Koprowski, Skufca - 2014 - Machine learning, medical diagnosis, and biomedical engineering research-commentary.pdf:pdf},
keywords = {Artificial intelligence,Classifiers,Image processing,Machine learning,Support vector machine},
title = {{Machine learning, medical diagnosis, and biomedical engineering research-commentary}},
url = {http://www.biomedical-engineering-online.com/content/13/1/94},
year = {2014}
}
@book{bishop2006pattern,
author = {Bishop, C M},
file = {:C$\backslash$:/Users/Suchendra/OneDrive - McMaster University/PhD Thesis/Books/Bishop - Pattern Recognition And Machine Learning - Springer  2006.pdf:pdf},
isbn = {9780387310732},
publisher = {Springer},
series = {Information Science and Statistics},
title = {{Pattern Recognition and Machine Learning}},
url = {https://books.google.ca/books?id=qWPwnQEACAAJ},
year = {2006}
}
@article{Aydin2019,
abstract = {Drones are currently being used for commercial, public safety, hobby, and scientific research purposes. Short term and long term forecasts show extensive utilization of drones in various sectors. Yet, it is uncertain if general public accepts this highly potential drone congestion. This quantitative survey study explored public acceptance of drones by using the Knowledge, Attitude and Practice (KAP) model and using statistical analysis to decrease the uncertainty. The KAP model was utilized in a recent survey study to understand the public opinion of drones. This survey instrument was thoroughly redesigned to better understand general public's knowledge and attitudes of forty different drone applications, and associated risk perceptions. The practice section was redesigned as well to better understand how public uses drones personally and on company level. The results showed that drones were not well accepted at present except for public safety and scientific research applications. Commercial and hobby uses are not supported. Public sees the drones as a risky technology that directly interferes with their privacy. Moreover, public is not aware of most of the future drone applications, and many current applications. The survey was distributed to both general public and stakeholders to represent both part of the society (153 fully completed surveys). A qualitative risk analysis was conducted in this study as well. By considering the results, this study recommends that public and private institutions should collaborate to develop risk mitigation and response strategies to minimize the risks. Also, public needs to get informed on these strategies through mass media and educational institutions. This might help improving the reputation of drones from killer machines or privacy interrupters towards a technology that helps our society.},
author = {Aydin, Burchan},
doi = {10.1016/J.TECHSOC.2019.101180},
issn = {0160-791X},
journal = {Technol. Soc.},
month = {nov},
pages = {101180},
publisher = {Pergamon},
title = {{Public acceptance of drones: Knowledge, attitudes, and practice}},
volume = {59},
year = {2019}
}
@article{Shlezinger2020,
abstract = {Signal processing, communications, and control have traditionally relied on classical statistical modeling techniques. Such model-based methods utilize mathematical formulations that represent the underlying physics, prior information and additional domain knowledge. Simple classical models are useful but sensitive to inaccuracies and may lead to poor performance when real systems display complex or dynamic behavior. On the other hand, purely data-driven approaches that are model-agnostic are becoming increasingly popular as datasets become abundant and the power of modern deep learning pipelines increases. Deep neural networks (DNNs) use generic architectures which learn to operate from data, and demonstrate excellent performance, especially for supervised problems. However, DNNs typically require massive amounts of data and immense computational resources, limiting their applicability for some signal processing scenarios. We are interested in hybrid techniques that combine principled mathematical models with data-driven systems to benefit from the advantages of both approaches. Such model-based deep learning methods exploit both partial domain knowledge, via mathematical structures designed for specific problems, as well as learning from limited data. In this article we survey the leading approaches for studying and designing model-based deep learning systems. We divide hybrid model-based/data-driven systems into categories based on their inference mechanism. We provide a comprehensive review of the leading approaches for combining model-based algorithms with deep learning in a systematic manner, along with concrete guidelines and detailed signal processing oriented examples from recent literature. Our aim is to facilitate the design and study of future systems on the intersection of signal processing and machine learning that incorporate the advantages of both domains.},
archivePrefix = {arXiv},
arxivId = {2012.08405},
author = {Shlezinger, Nir and Whang, Jay and Eldar, Yonina C. and Dimakis, Alexandros G.},
eprint = {2012.08405},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shlezinger et al. - 2020 - Model-Based Deep Learning.pdf:pdf},
journal = {arXiv},
month = {dec},
publisher = {arXiv},
title = {{Model-Based Deep Learning}},
url = {http://arxiv.org/abs/2012.08405},
year = {2020}
}
@article{iot_apps_conf,
abstract = {With the advent of rapid developments, large number of heterogeneous devices is able to connect with the help of IOT technology. Although IOT possess very complex architecture because of connectivity of variety of devices and services in the system. In this paper, a brief concept of urban IOT system is presented which are designed to support smart city and advanced communication technologies. Hence a comprehensive survey of architecture, technologies, and computational frameworks is provided for a smart IOT. It also discusses the major vulnerabilities and challenges faced by IOT and also present how machine learning is applied to IOT. Hence smart city is considered as the use case and it explains how various techniques are applied to data in order to extract great results with good efficiency.},
author = {Jindal, Mansi and Gupta, Jatin and Bhushan, Bharat},
doi = {10.1109/ICCCIS48478.2019.8974551},
journal = {Proc. - 2019 Int. Conf. Comput. Commun. Intell. Syst. ICCCIS 2019},
keywords = {Internet of Things,Machine Learning,knn (k nearest neighbors),naive bayes,supervised learning,support vector machines},
month = {oct},
pages = {430--434},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Machine learning methods for IoT and their Future Applications}},
volume = {2019-January},
year = {2019}
}
@article{Bishnu2015,
abstract = {Teramoto et al. defined a new measure called the gap ratio that measures the
uniformity of a finite point set sampled from {\$}\backslashcal S{\$}, a bounded subset of
{\$}\backslashmathbb{\{}R{\}}{\^{}}2{\$}. We generalize this definition of measure over all metric spaces
by appealing to covering and packing radius. The definition of gap ratio needs
only a metric unlike discrepancy, a widely used uniformity measure, that
depends on the notion of a range space and its volume. We also show some
interesting connections of gap ratio to Delaunay triangulation and discrepancy
in the Euclidean plane. The major focus of this work is on solving optimization
related questions about selecting uniform point samples from metric spaces; the
uniformity being measured using gap ratio. We consider discrete spaces like
graph and set of points in the Euclidean space and continuous spaces like the
unit square and path connected spaces. We deduce lower bounds, prove hardness
and approximation hardness results. We show that a general approximation
algorithm framework gives different approximation ratios for different metric
spaces based on the lower bound we deduce. Apart from the above, we show
existence of coresets for sampling uniform points from the Euclidean space --
for both the static and the streaming case. This leads to a {\$}\backslashleft( 1+\backslashepsilon
\backslashright){\$}-approximation algorithm for uniform sampling from the Euclidean space.},
archivePrefix = {arXiv},
arxivId = {1411.7819},
author = {Bishnu, Arijit and Desai, Sameer and Ghosh, Arijit and Goswami, Mayank and Paul, Subhabrata},
eprint = {1411.7819},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishnu et al. - 2014 - Uniformity of point samples in metric spaces using gap ratio.pdf:pdf},
journal = {SIAM J. Discret. Math.},
keywords = {Approximation,Gap ratio,Hardness,Lower bounds,Metric space,Uniformity measure},
month = {nov},
number = {3},
pages = {2138--2171},
publisher = {Society for Industrial and Applied Mathematics Publications},
title = {{Uniformity of point samples in metric spaces using gap ratio}},
url = {https://arxiv.org/abs/1411.7819v2},
volume = {31},
year = {2014}
}
@article{Burton,
abstract = {This paper describes the challenges involved in arguing the safety of highly automated driving functions which make use of machine learning techniques. An assurance case structure is used to highlight the systems engineering and validation considerations when applying machine learning methods for highly automated driving. Particular focus is placed on addressing functional insufficiencies in the perception functions based on convolutional neural networks and possible types of evidence that can be used to mitigate against such risks.},
author = {Burton, Simon and Gauerhof, Lydia and Heinzemann, Christian},
doi = {10.1007/978-3-319-66284-8},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Burton, Gauerhof, Heinzemann - Unknown - Making the Case for Safety of Machine Learning in Highly Automated Driving.pdf:pdf},
title = {{Making the Case for Safety of Machine Learning in Highly Automated Driving}},
url = {https://www.youtube.com/watch?v=u6aEYuemt0M}
}
@article{Macrae2019,
author = {Macrae, Carl},
doi = {10.1136/bmjqs-2019-009484},
issn = {20445415},
journal = {BMJ Qual. Saf.},
keywords = {governance,information technology,risk management},
month = {jun},
number = {6},
pages = {495--498},
pmid = {30979783},
publisher = {BMJ Publishing Group},
title = {{Governing the safety of artificial intelligence in healthcare}},
url = {https://qualitysafety.bmj.com/lookup/doi/10.1136/bmjqs-2019-009484},
volume = {28},
year = {2019}
}
@techreport{Boehm2000,
author = {Boehm, Barry and Hansen, Wilfred J},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boehm, Hansen - 2000 - Spiral Development Experience, Principles, and Refinements Spiral Development Workshop February 9, 2000.pdf:pdf},
keywords = {anchor point milestones,cyclic phases,invariant,iterative process,project management,risk management,software development,spiral development model,variant},
title = {{Spiral Development: Experience, Principles, and Refinements  Spiral Development Workshop February 9, 2000}},
year = {2000}
}
@techreport{Pecka,
abstract = {We overview different approaches to safety in (semi)auto-nomous robotics. Particularly, we focus on how to achieve safe behavior of a robot if it is requested to perform exploration of unknown states. Presented methods are studied from the viewpoint of reinforcement learning, a partially-supervised machine learning method. To collect training data for this algorithm, the robot is required to freely explore the state space-which can lead to possibly dangerous situations. The role of safe exploration is to provide a framework allowing exploration while preserving safety. The examined methods range from simple algorithms to sophisticated methods based on previous experience or state prediction. Our overview also addresses the issues of how to define safety in the real-world applications (apparently absolute safety is unachievable in the continuous and random real world). In the conclusion we also suggest several ways that are worth researching more thoroughly.},
author = {Pecka, Martin and Svoboda, Tomas},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pecka, Svoboda - Unknown - LNCS 8906 - Safe Exploration Techniques for Reinforcement Learning – An Overview.pdf:pdf},
keywords = {Safe exploration,policy search,reinforcement learning},
title = {{LNCS 8906 - Safe Exploration Techniques for Reinforcement Learning – An Overview}},
url = {http://cmp.felk.cvut.cz/∼peckama2}
}
@article{Bradley1997,
abstract = {In this paper we investigate the use of the area under the receiver operating characteristic (ROC) curve (AUC) as a performance measure for machine learning algorithms. As a case study we evaluate six machine learning algorithms (C4.5, Multiscale Classifier, Perceptron, Multi-layer Perceptron, k-Nearest Neighbours, and a Quadratic Discriminant Function) on six "real world" medical diagnostics data sets. We compare and discuss the use of AUC to the more conventional overall accuracy and find that AUC exhibits a number of desirable properties when compared to overall accuracy: increased sensitivity in Analysis of Variance (ANOVA) tests; a standard error that decreased as both AUC and the number of test samples increased; decision threshold independent; and it is invafiant to a priori class probabilities. The paper concludes with the recommendation that AUC be used in preference to overall accuracy for "single number" evaluation of machine learning algorithms.},
author = {Bradley, Andrew E},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bradley - 1997 - THE EVALUATION OF MACHINE LEARNING ALGORITHMS.pdf:pdf},
journal = {Pattern Recognit.},
number = {7},
pages = {1145--1159},
title = {{The Use of the Area Under the ROC Curve in the Evaluation of Machine Learning Algorithms}},
volume = {30},
year = {1997}
}
@misc{Kelly2019,
abstract = {Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.},
author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
booktitle = {BMC Med.},
doi = {10.1186/s12916-019-1426-2},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelly et al. - 2019 - Key challenges for delivering clinical impact with artificial intelligence(2).pdf:pdf},
issn = {17417015},
keywords = {Algorithms,Artificial intelligence,Evaluation,Machine learning,Regulation,Translation},
month = {oct},
number = {1},
pages = {195},
pmid = {31665002},
publisher = {BioMed Central Ltd.},
title = {{Key challenges for delivering clinical impact with artificial intelligence}},
url = {https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1426-2},
volume = {17},
year = {2019}
}
@article{Batarseh2021,
abstract = {Artificial Intelligence (AI) algorithms are increasingly providing decision making and operational support across multiple domains. AI includes a wide (and growing) library of algorithms that could be applied for different problems. One important notion for the adoption of AI algorithms into operational decision processes is the concept of assurance. The literature on assurance, unfortunately, conceals its outcomes within a tangled landscape of conflicting approaches, driven by contradicting motivations, assumptions, and intuitions. Accordingly, albeit a rising and novel area, this manuscript provides a systematic review of research works that are relevant to AI assurance, between years 1985 and 2021, and aims to provide a structured alternative to the landscape. A new AI assurance definition is adopted and presented, and assurance methods are contrasted and tabulated. Additionally, a ten-metric scoring system is developed and introduced to evaluate and compare existing methods. Lastly, in this manuscript, we provide foundational insights, discussions, future directions, a roadmap, and applicable recommendations for the development and deployment of AI assurance.},
author = {Batarseh, Feras A. and Freeman, Laura and Huang, Chih Hao},
doi = {10.1186/s40537-021-00445-7},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Batarseh, Freeman, Huang - 2021 - A survey on artificial intelligence assurance.pdf:pdf},
issn = {21961115},
journal = {J. Big Data},
keywords = {AI assurance,Data Engineering,Explainable AI (XAI),Validation and verification},
month = {dec},
number = {1},
pages = {1--30},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{A survey on artificial intelligence assurance}},
url = {https://doi.org/10.1186/s40537-021-00445-7},
volume = {8},
year = {2021}
}
@techreport{Serban2020,
abstract = {Deep reinforcement learning has recently shown many impressive successes. However, one major obstacle towards applying such methods to real-world problems is their lack of data-efficiency. To this end, we propose the Bottleneck Simulator: a model-based reinforcement learning method which combines a learned, factorized transition model of the environment with rollout simulations to learn an effective policy from few examples. The learned transition model employs an abstract, discrete (bottleneck) state, which increases sample efficiency by reducing the number of model parameters and by exploiting structural properties of the environment. We provide a mathematical analysis of the Bottleneck Simulator in terms of fixed points of the learned policy, which reveals how performance is affected by four distinct sources of error: an error related to the abstract space structure, an error related to the transition model estimation variance, an error related to the transition model estimation bias, and an error related to the transition model class bias. Finally, we evaluate the Bottleneck Simulator on two natural language processing tasks: a text adventure game and a real-world, complex dialogue response selection task. On both tasks, the Bottleneck Simulator yields excellent performance beating competing approaches.},
author = {Serban, Iulian Vlad and Sankar, Chinnadhurai and Pieper, Michael and Montreal, Polytechnique Montreal and Pineau, Canada Joelle and Bengio, Yoshua},
booktitle = {J. Artif. Intell. Res.},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Serban et al. - 2020 - The Bottleneck Simulator A Model-Based Deep Reinforcement Learning Approach.pdf:pdf},
pages = {571--612},
title = {{The Bottleneck Simulator: A Model-Based Deep Reinforcement Learning Approach}},
volume = {69},
year = {2020}
}
@article{Berk2015,
author = {Berk, Richard and Hyatt, Jordan},
doi = {10.1525/fsr.2015.27.4.222},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berk, Hyatt - 2015 - Machine Learning Forecasts of Risk to Inform Sentencing Decisions.pdf:pdf},
journal = {Source Fed. Sentencing Report.},
number = {4},
pages = {222--228},
title = {{Machine Learning Forecasts of Risk to Inform Sentencing Decisions}},
volume = {27},
year = {2015}
}
@inproceedings{Mohseni2020a,
abstract = {Autonomous vehicles rely on machine learning to solve challenging tasks in perception and motion planning. However, automotive software safety standards have not fully evolved to address the challenges of machine learning safety such as interpretability, verification, and performance limitations. In this paper, we review and organize practical machine learn- ing safety techniques that can complement engineering safety for machine learning based software in autonomous vehicles. Our organization maps safety strategies to state-of-theart machine learning techniques in order to enhance dependability and safety of machine learning algorithms. We also discuss security limitations and user experience aspects of machine learning components in autonomous vehicles.},
archivePrefix = {arXiv},
arxivId = {1912.09630},
author = {Mohseni, Sina and Pitale, Mandar and Singh, Vasu and Wang, Zhangyang},
booktitle = {CEUR Workshop Proc.},
eprint = {1912.09630},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Practical{\_}Solutions{\_}for{\_}Machine{\_}Learning{\_}Safety{\_}in.pdf:pdf},
issn = {16130073},
pages = {162--169},
title = {{Practical solutions for machine learning safety in autonomous vehicles}},
url = {https://www.researchgate.net/publication/338115926{\_}Practical{\_}Solutions{\_}for{\_}Machine{\_}Learning{\_}Safety{\_}in{\_}Autonomous{\_}Vehicles/stats},
volume = {2560},
year = {2020}
}
@article{bilal2020,
abstract = {The progress in the field of Machine Learning (ML) has enabled the automation of tasks that were considered impossible to program until recently. These advancements today have incited firms to seek intelligent solutions as part of their enterprise software stack. Even governments across the globe are motivating firms through policies to tape into ML arena as it promises opportunities for growth, productivity and efficiency. In reflex, many firms embark on ML without knowing what it entails. The outcomes so far are not as expected because the ML, as hyped by tech firms, is not the silver bullet. However, whatever ML offers, firms urge to capitalise it for their competitive advantage. Applying ML to real-life construction industry problems goes beyond just prototyping predictive models. It entails intensive activities which, in addition to training robust ML models, provides a comprehensive framework for answering questions asked by construction folks when intelligent solutions are getting deployed at their premises to substitute or facilitate their decision-making tasks. Existing ML guidelines used in the IT industry are vastly restricted to training ML models. This paper presents guidelines for Applied Machine Learning (AML) in the construction industry from training to operationalising models, which are drawn from our experience of working with construction folks to deliver Construction Simulation Tool (CST). The unique aspect of these guidelines lies not only in providing a novel framework for training models but also answering critical questions related to model confidence, trust, interpretability, bias, feature importance and model extrapolation capabilities. Generally, ML models are presumed black boxes; hence argued that nobody knows what a model learns and how it generates predictions. Even very few ML folks barely know approaches to answer questions asked by the end users. Without explaining the competence of ML, the broader adoption of intelligent solutions in the construction industry cannot be attained. This paper proposed a detailed process for AML to develop intelligent solutions in the construction industry. Most discussions in the study are elaborated in the context of profit margin estimation for new projects.},
author = {Bilal, Muhammad and Oyedele, Lukumon O.},
doi = {10.1016/J.AEI.2019.101013},
issn = {1474-0346},
journal = {Adv. Eng. Informatics},
keywords = {Applied machine learning,Construction simulation tool,Interpretable machine learning,Predictive modelling,Profit margin forecasting},
month = {jan},
pages = {101013},
publisher = {Elsevier},
title = {{Guidelines for applied machine learning in construction industry—A case of profit margins estimation}},
volume = {43},
year = {2020}
}
@article{Hendrycks2019,
abstract = {In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.},
archivePrefix = {arXiv},
arxivId = {1903.12261},
author = {Hendrycks, Dan and Dietterich, Thomas},
eprint = {1903.12261},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hendrycks, Dietterich - 2019 - Benchmarking Neural Network Robustness to Common Corruptions and Perturbations.pdf:pdf},
journal = {arXiv},
month = {mar},
publisher = {arXiv},
title = {{Benchmarking Neural Network Robustness to Common Corruptions and Perturbations}},
url = {http://arxiv.org/abs/1903.12261},
year = {2019}
}
@techreport{Varshney2017a,
abstract = {Machine learning algorithms increasingly influence our decisions and interact with us in all parts of our daily lives. Therefore, just as we consider the safety of power plants, highways, and a variety of other engineered socio-technical systems, we must also take into account the safety of systems involving machine learning. Heretofore, the definition of safety has not been formalized in a machine learning context. In this paper, we do so by defining machine learning safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. We then use this definition to examine safety in all sorts of applications in cyber-physical systems, decision sciences, and data products. We find that the foundational principle of modern statistical machine learning, empirical risk minimization, is not always a sufficient objective. Finally, we discuss how four different categories of strategies for achieving safety in engineering, including inherently safe design, safety reserves, safe fail, and procedural safeguards can be mapped to a machine learning context. We then discuss example techniques that can be adopted in each category, such as considering interpretability and causality of predictive models, 2 objective functions beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software and open data.},
archivePrefix = {arXiv},
arxivId = {1610.01256v2},
author = {Varshney, Kush R and Alemzadeh, Homa},
eprint = {1610.01256v2},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Varshney, Alemzadeh - 2017 - On the Safety of Machine Learning Cyber-Physical Systems, Decision Sciences, and Data Products.pdf:pdf},
title = {{On the Safety of Machine Learning: Cyber-Physical Systems, Decision Sciences, and Data Products}},
year = {2017}
}
@article{QuantumML2017,
abstract = {Fuelled by increasing computer power and algorithmic advances, machine learning techniques have become powerful tools for finding patterns in data. Quantum systems produce atypical patterns that classical systems are thought not to produce efficiently, so it is reasonable to postulate that quantum computers may outperform classical computers on machine learning tasks. The field of quantum machine learning explores how to devise and implement quantum software that could enable machine learning that is faster than that of classical computers. Recent work has produced quantum algorithms that could act as the building blocks of machine learning programs, but the hardware and software challenges are still considerable.},
author = {Biamonte, Jacob and Wittek, Peter and Pancotti, Nicola and Rebentrost, Patrick and Wiebe, Nathan and Lloyd, Seth},
doi = {10.1038/NATURE23474},
journal = {Nature},
month = {sep},
number = {7671},
pages = {195--202},
publisher = {Nature Publishing Group},
title = {{Quantum machine learning}},
volume = {549},
year = {2017}
}
@inproceedings{Johnson2019,
abstract = {Regulatory bodies, industry and academia present a plethora of approaches for risk analysis and engineering for safety and security. However, few standards and approaches discuss the management of both safety and security risks. Fewer yet provide detail on how the two attributes interact within a given system. In this paper, the Safety-Security Assurance Framework (SSAF) is presented as a candidate solution to many of the extant challenges of attribute co-assurance. It is a holistic approach, based on the concept of independent co-assurance, that considers both the technical risk impact and the socio-technical impact on assurance. The Framework's Technical Risk Model (TRM) is applied and evaluated against a case study of an insulin pump. It is argued that SSAF TRM is not only a plausible and practical approach, but also more effective for co-assurance than many existing approaches alone.},
address = {Cham},
author = {Johnson, Nikita and Kelly, Tim},
booktitle = {Comput. Safety, Reliab. Secur.},
isbn = {978-3-030-26601-1},
pages = {299--314},
publisher = {Springer International Publishing},
title = {{Devil's in the Detail: Through-Life Safety and Security Co-assurance Using SSAF}},
year = {2019}
}
@inproceedings{Ko2015,
abstract = {Data augmentation is a common strategy adopted to increase the quantity of training data, avoid overfitting and improve ro-bustness of the models. In this paper, we investigate audio-level speech augmentation methods which directly process the raw signal. The method we particularly recommend is to change the speed of the audio signal, producing 3 versions of the original signal with speed factors of 0.9, 1.0 and 1.1. The proposed technique has a low implementation cost, making it easy to adopt. We present results on 4 different LVCSR tasks with training data ranging from 100 hours to 1000 hours, to examine the effectiveness of audio augmentation in a variety of data scenarios. An average relative improvement of 4.3{\%} was observed across the 4 tasks.},
author = {Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ko et al. - Unknown - Audio Augmentation for Speech Recognition.pdf:pdf},
keywords = {Index Terms: speech recognition,data augmentation,deep neural network},
title = {{Audio Augmentation for Speech Recognition}},
url = {http://www.isip.piconepress.com/}
}
@article{Ross2016,
author = {Ross, Hans-Leo},
doi = {10.1007/978-3-319-33361-8},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2016 - Functional Safety for Road Vehicles.pdf:pdf},
isbn = {9783319333601},
title = {{Functional Safety for Road Vehicles}},
year = {2016}
}
@article{DelaVega2020,
abstract = {Input data of a data mining algorithm must conform to a very specific tabular format. Data scientists arrange data into that format by creating long and complex scripts, where different low-level operations are performed, and which can be a time-consuming and error-prone process. To alleviate this situation, we present Lavoisier, a declarative language for data selection and formatting in a data mining context. Using Lavoisier, script size for data preparation can be reduced by ∼40{\%} on average, and by up to 80{\%} in some cases. Additionally, accidental complexity present in state-of-the-art technologies is considerably mitigated.},
author = {de la Vega, Alfonso and Garc{\'{i}}a-Saiz, Diego and Zorrilla, Marta and S{\'{a}}nchez, Pablo},
doi = {10.1016/j.cola.2020.100987},
issn = {25901184},
journal = {J. Comput. Lang.},
keywords = {Data formatting,Data mining,Data selection,Domain-specific languages},
month = {oct},
pages = {100987},
publisher = {Elsevier Ltd},
title = {{Lavoisier: A DSL for increasing the level of abstraction of data selection and formatting in data mining}},
volume = {60},
year = {2020}
}
@techreport{BeziersLaFosse2018,
abstract = {Energy consumption is a critical point when developing applications. Either for battery-saving purposes, for lowering the cost of data-centers, or simply for the sake of having an eco-friendly program, reducing the energy needed to run a software becomes mandatory. Model-Driven Engineering has shown great results when it comes to program understanding and refactoring. Modeling the source code along with its energy consumption could be a powerful asset to programmers in order to develop greener code. For that purpose, this paper presents an approach for modeling energy consumption inside a source code model. Energy metrics are gathered at runtime, modeled using the standard Structured Metrics Meta-model, and associated to the source code model, enabling model-driven techniques for energy analysis and optimizations.},
author = {{B{\'{e}}ziers La Fosse}, Thibault and Mottu, Jean-Marie and Tisi, Massimo and Suny{\'{e}}, Gerson and {B{\'{e}}ziers la Fosse}, Thibault and Rocheteau, J{\'{e}}r{\^{o}}me},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/B{\'{e}}ziers La Fosse et al. - 2018 - Characterizing a Source Code Model with Energy Measurements Characterizing a Source Code Model with Ene.pdf:pdf},
title = {{Characterizing a Source Code Model with Energy Measurements Characterizing a Source Code Model with Energy Measurements. Workshop on Measurement and Metrics for Green and Sustainable Software Systems ( Characterizing a Source Code Model with Energy Measur}},
url = {https://asm.ow2.io/},
year = {2018}
}
@article{gsn2004Kelly,
abstract = {In Europe, over recent years, the responsibility for ensuring system safety has shifted onto the developers and operators to construct and present well reasoned arguments that their systems achieve acceptable levels of safety. These arguments (together with supporting evidence) are typically referred to as a "safety case". This paper describes the role and purpose of a safety case. Safety arguments within safety cases are often poorly communicated. This paper presents a technique called GSN (Goal Structuring Notation) that is increasingly being used in safety-critical industries to improve the structure, rigor, and clarity of safety arguments. The paper also describes a number of extensions, based upon GSN, which can be used to assist the maintenance, construction, reuse and assessment of safety cases. The aim of this paper is to describe the current industrial use and research into GSN such that its applicability to other types of Assurance Case, in addition to safety cases, can also be considered.},
author = {Kelly, Tim and Weaver, Rob},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelly, Weaver - Unknown - The Goal Structuring Notation-A Safety Argument Notation.pdf:pdf},
title = {{The Goal Structuring Notation-A Safety Argument Notation}}
}
@article{Bencomo2019a,
abstract = {More than a decade ago, the research topic models@run.time was coined. Since then, the research area has received increasing attention. Given the prolific results during these years, the current outcomes need to be sorted and classified. Furthermore, many gaps need to be categorized in order to further develop the research topic by experts of the research area but also newcomers. Accordingly, the paper discusses the principles and requirements of models@run.time and the state of the art of the research line. To make the discussion more concrete, a taxonomy is defined and used to compare the main approaches and research outcomes in the area during the last decade and including ancestor research initiatives. We identified and classified 275 papers on models@run.time, which allowed us to identify the underlying research gaps and to elaborate on the corresponding research challenges. Finally, we also facilitate sustainability of the survey over time by offering tool support to add, correct and visualize data.},
author = {Bencomo, Nelly and G{\"{o}}tz, Sebastian and Song, Hui},
doi = {10.1007/s10270-018-00712-x},
issn = {16191374},
journal = {Softw. Syst. Model.},
keywords = {Causal connection,Models@run.time,Self-reflection,Systematic literature review},
month = {oct},
number = {5},
pages = {3049--3082},
publisher = {Springer Verlag},
title = {{Models@run.time: a guided tour of the state of the art and research challenges}},
url = {https://link.springer.com/article/10.1007/s10270-018-00712-x},
volume = {18},
year = {2019}
}
@article{FairML2018,
abstract = {The nascent field of fair machine learning aims to ensure that decisions
guided by algorithms are equitable. Over the last several years, three formal
definitions of fairness have gained prominence: (1) anti-classification,
meaning that protected attributes---like race, gender, and their proxies---are
not explicitly used to make decisions; (2) classification parity, meaning that
common measures of predictive performance (e.g., false positive and false
negative rates) are equal across groups defined by the protected attributes;
and (3) calibration, meaning that conditional on risk estimates, outcomes are
independent of protected attributes. Here we show that all three of these
fairness definitions suffer from significant statistical limitations. Requiring
anti-classification or classification parity can, perversely, harm the very
groups they were designed to protect; and calibration, though generally
desirable, provides little guarantee that decisions are equitable. In contrast
to these formal fairness criteria, we argue that it is often preferable to
treat similarly risky people similarly, based on the most statistically
accurate estimates of risk that one can produce. Such a strategy, while not
universally applicable, often aligns well with policy objectives; notably, this
strategy will typically violate both anti-classification and classification
parity. In practice, it requires significant effort to construct suitable risk
estimates. One must carefully define and measure the targets of prediction to
avoid retrenching biases in the data. But, importantly, one cannot generally
address these difficulties by requiring that algorithms satisfy popular
mathematical formalizations of fairness. By highlighting these challenges in
the foundation of fair machine learning, we hope to help researchers and
practitioners productively advance the area.},
archivePrefix = {arXiv},
arxivId = {1808.00023},
author = {Corbett-Davies, Sam and Goel, Sharad},
eprint = {1808.00023},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Corbett-Davies, Goel - 2018 - The Measure and Mismeasure of Fairness A Critical Review of Fair Machine Learning.pdf:pdf},
keywords = {Algorithms,anti-classification,bias,calibration,classification parity,decision analysis,measurement error * We thank},
month = {jul},
title = {{The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning}},
url = {https://arxiv.org/abs/1808.00023v2},
year = {2018}
}
@article{Abadi,
abstract = {TensorFlow is a powerful, programmable system for machine learning. This paper aims to provide the basics of a conceptual framework for understanding the behavior of TensorFlow models during training and inference: it describes an operational semantics, of the kind common in the literature on programming languages. More broadly, the paper suggests that a programming-language perspective is fruitful in designing and in explaining systems such as TensorFlow.},
author = {Abadi, Mart{\'{i}}n and Isard, Michael and {Google Brain}, Derek G Murray},
doi = {10.1145/3088525.3088527},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi, Isard, Google Brain - Unknown - A Computational Model for TensorFlow An Introduction(2).pdf:pdf},
isbn = {9781450350716},
keywords = {CCS Concepts • Theory of computation → Operational,• Computing methodologies → Neural networks,• Software and its engineering → Data flow archite},
title = {{A Computational Model for TensorFlow An Introduction}},
url = {http://dx.doi.org/10.1145/3088525.3088527}
}
@article{Arcos-Garcia2018,
abstract = {This paper presents a Deep Learning approach for traffic sign recognition systems. Several classification experiments are conducted over publicly available traffic sign datasets from Germany and Belgium using a Deep Neural Network which comprises Convolutional layers and Spatial Transformer Networks. Such trials are built to measure the impact of diverse factors with the end goal of designing a Convolutional Neural Network that can improve the state-of-the-art of traffic sign classification task. First, different adaptive and non-adaptive stochastic gradient descent optimisation algorithms such as SGD, SGD-Nesterov, RMSprop and Adam are evaluated. Subsequently, multiple combinations of Spatial Transformer Networks placed at distinct positions within the main neural network are analysed. The recognition rate of the proposed Convolutional Neural Network reports an accuracy of 99.71{\%} in the German Traffic Sign Recognition Benchmark, outperforming previous state-of-the-art methods and also being more efficient in terms of memory requirements.},
author = {Arcos-Garc{\'{i}}a, {\'{A}}lvaro and {\'{A}}lvarez-Garc{\'{i}}a, Juan A. and Soria-Morillo, Luis M.},
doi = {10.1016/j.neunet.2018.01.005},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Arcos-Garc{\'{i}}a, {\'{A}}lvarez-Garc{\'{i}}a, Soria-Morillo - 2018 - Deep neural network for traffic sign recognition systems An analysis of spatial tra.pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Convolutional neural network,Deep learning,Spatial transformer network,Traffic sign},
title = {{Deep neural network for traffic sign recognition systems: An analysis of spatial transformers and stochastic optimisation methods}},
year = {2018}
}
@article{Caffe2014,
abstract = {Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU ({\$}\backslashapprox{\$} 2.5 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.},
archivePrefix = {arXiv},
arxivId = {1408.5093},
author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
eprint = {1408.5093},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2014 - Caffe Convolutional Architecture for Fast Feature Embedding.pdf:pdf},
journal = {MM 2014 - Proc. 2014 ACM Conf. Multimed.},
keywords = {Computer vision,Machine learning,Neural networks,Open source,Parallel computation},
month = {jun},
pages = {675--678},
publisher = {Association for Computing Machinery, Inc},
title = {{Caffe: Convolutional Architecture for Fast Feature Embedding}},
url = {https://arxiv.org/abs/1408.5093v1},
year = {2014}
}
@article{Lemley2017,
abstract = {We present the first algorithm for finding holes in high dimensional data that runs in polynomial time with respect to the number of dimensions. Previous algorithms are exponential. Finding large empty rectangles or boxes in a set of points in 2D and 3D space has been well studied. Efficient algorithms exist to identify the empty regions in these low-dimensional spaces. Unfortunately such efficiency is lacking in higher dimensions where the problem has been shown to be NP-complete when the dimensions are included in the input. Applications for algorithms that find large empty spaces include big data analysis, recommender systems, automated knowledge discovery, and query optimization. Our Monte Carlo-based algorithm discovers interesting maximal empty hyper-rectangles in cases where dimensionality and input size would otherwise make analysis impractical. The run-time is polynomial in the size of the input and the number of dimensions. We apply the algorithm on a 39-dimensional data set for protein structures and discover interesting properties that we think could not be inferred otherwise.},
archivePrefix = {arXiv},
arxivId = {1704.00683v1},
author = {Lemley, Joseph and Jagodzinski, Filip and {Azvan Andonie}, R˘},
eprint = {1704.00683v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lemley, Jagodzinski, Azvan Andonie - Unknown - Big Holes in Big Data A Monte Carlo Algorithm for Detecting Large Hyper-rectangles in Hig.pdf:pdf},
title = {{Big Holes in Big Data: A Monte Carlo Algorithm for Detecting Large Hyper-rectangles in High Dimensional Data}}
}
@misc{Al-Rfou,
archivePrefix = {arXiv},
arxivId = {1605.02688v1},
author = {{The Theano Development Team}},
eprint = {1605.02688v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Rfou et al. - Unknown - Theano A Python framework for fast computation of mathematical expressions (The Theano Development Team).pdf:pdf},
howpublished = {https://github.com/Theano/Theano},
title = {{Theano: A Python framework for fast computation of mathematical expressions}},
url = {https://github.com/Theano/Theano},
year = {2016}
}
@article{KhadjehNassirtoussi2015,
abstract = {In this paper a novel approach is proposed to predict intraday directional-movements of a currency-pair in the foreign exchange market based on the text of breaking financial news-headlines. The motivation behind this work is twofold: First, although market-prediction through text-mining is shown to be a promising area of work in the literature, the text-mining approaches utilized in it at this stage are not much beyond basic ones as it is still an emerging field. This work is an effort to put more emphasis on the text-mining methods and tackle some specific aspects thereof that are weak in previous works, namely: the problem of high dimensionality as well as the problem of ignoring sentiment and semantics in dealing with textual language. This research assumes that addressing these aspects of text-mining have an impact on the quality of the achieved results. The proposed system proves this assumption to be right. The second part of the motivation is to research a specific market, namely, the foreign exchange market, which seems not to have been researched in the previous works based on predictive text-mining. Therefore, results of this work also successfully demonstrate a predictive relationship between this specific market-type and the textual data of news. Besides the above two main components of the motivation, there are other specific aspects that make the setup of the proposed system and the conducted experiment unique, for example, the use of news article-headlines only and not news article-bodies, which enables usage of short pieces of text rather than long ones; or the use of general financial breaking news without any further filtration. In order to accomplish the above, this work produces a multi-layer algorithm that tackles each of the mentioned aspects of the text-mining problem at a designated layer. The first layer is termed the Semantic Abstraction Layer and addresses the problem of co-reference in text mining that is contributing to sparsity. Co-reference occurs when two or more words in a text corpus refer to the same concept. This work produces a custom approach by the name of Heuristic-Hypernyms Feature-Selection which creates a way to recognize words with the same parent-word to be regarded as one entity. As a result, prediction accuracy increases significantly at this layer which is attributed to appropriate noise-reduction from the feature-space. The second layer is termed Sentiment Integration Layer, which integrates sentiment analysis capability into the algorithm by proposing a sentiment weight by the name of SumScore that reflects investors' sentiment. Additionally, this layer reduces the dimensions by eliminating those that are of zero value in terms of sentiment and thereby improves prediction accuracy. The third layer encompasses a dynamic model creation algorithm, termed Synchronous Targeted Feature Reduction (STFR). It is suitable for the challenge at hand whereby the mining of a stream of text is concerned. It updates the models with the most recent information available and, more importantly, it ensures that the dimensions are reduced to the absolute minimum. The algorithm and each of its layers are extensively evaluated using real market data and news content across multiple years and have proven to be solid and superior to any other comparable solution. The proposed techniques implemented in the system, result in significantly high directional-accuracies of up to 83.33{\%}. On top of a well-rounded multifaceted algorithm, this work contributes a much needed research framework for this context with a test-bed of data that must make future research endeavors more convenient. The produced algorithm is scalable and its modular design allows improvement in each of its layers in future research. This paper provides ample details to reproduce the entire system and the conducted experiments. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {{Khadjeh Nassirtoussi}, Arman and Aghabozorgi, Saeed and {Ying Wah}, Teh and Ngo, David Chek Ling},
doi = {10.1016/j.eswa.2014.08.004},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Khadjeh Nassirtoussi et al. - 2015 - Text mining of news-headlines for FOREX market prediction A Multi-layer Dimension Reduction Algorit.pdf:pdf},
issn = {09574174},
journal = {Expert Syst. Appl.},
keywords = {FOREX prediction,Market prediction,Market sentiment analysis,News mining,News semantic analysis},
title = {{Text mining of news-headlines for FOREX market prediction: A Multi-layer Dimension Reduction Algorithm with semantics and sentiment}},
year = {2015}
}
@article{Teramoto,
abstract = {Arranging n points as uniformly as possible is a frequently occurring problem. It is equivalent to packing n equal and non-overlapping circles in a unit square. In this paper we generalize this problem in such a way that points are inserted one by one with uniformity preserved at every instance. Our criterion for uniformity is to minimize the gap ratio (which is the maximum gap over the minimum gap) at every point insertion. We present a linear time algorithm for finding an optimal n-point sequence with the maximum gap ratio bounded by 2 n/2/(n/2+1) in the 1-dimensional case. We describe how hard the same problem is for a point set in the plane and propose a local search heuristics for finding a good solution.},
author = {Teramoto, Sachio and Asano, Tetsuo and Katoh, Naoki and Doerr, Benjamin},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Teramoto et al. - Unknown - Inserting Points Uniformly at Every Instance.pdf:pdf},
keywords = {algorithm,circle packing,computational geometry,discrep-ancy,local search,uniformity},
title = {{Inserting Points Uniformly at Every Instance}}
}
@book{organization2018iso,
author = {for Standardization, International Organization},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/ISO+26262-1-2018.pdf:pdf;:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/ISO+26262-2-2018.pdf:pdf},
publisher = {ISO},
title = {{ISO 26262: Road Vehicles : Functional Safety}},
url = {https://books.google.ca/books?id=3gcAjwEACAAJ},
year = {2018}
}
@article{smartphone2012,
abstract = {Activity-Based Computing [1] aims to capture the state of the user and its environment by exploiting heterogeneous sensors in order to provide adaptation to exogenous computing resources. When these sensors are attached to the subject's body, they permit continuous monitoring of numerous physiological signals. This has appealing use in healthcare applications, e.g. the exploitation of Ambient Intelligence (AmI) in daily activity monitoring for elderly people. In this paper, we present a system for human physical Activity Recognition (AR) using smartphone inertial sensors. As these mobile phones are limited in terms of energy and computing power, we propose a novel hardware-friendly approach for multiclass classification. This method adapts the standard Support Vector Machine (SVM) and exploits fixed-point arithmetic for computational cost reduction. A comparison with the traditional SVM shows a significant improvement in terms of computational costs while maintaining similar accuracy, which can contribute to develop more sustainable systems for AmI. {\textcopyright} 2012 Springer-Verlag.},
author = {Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier and Reyes-Ortiz, Jorge L.},
doi = {10.1007/978-3-642-35395-6_30},
journal = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
keywords = {Activity Recognition,Hardware-Friendly,SVM,Smartphones},
pages = {216--223},
publisher = {Springer, Berlin, Heidelberg},
title = {{Human Activity Recognition on Smartphones Using a Multiclass Hardware-Friendly Support Vector Machine}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-35395-6{\_}30},
volume = {7657 LNCS},
year = {2012}
}
@techreport{pytorch2019,
abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
archivePrefix = {arXiv},
arxivId = {1912.01703v1},
author = {et al. Paszke, Adam},
eprint = {1912.01703v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Deep Learning Library.pdf:pdf},
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
year = {2019}
}
@article{Quantum_sup,
abstract = {The promise of quantum computers is that certain computational tasks might be executed exponentially faster on a quantum processor than on a classical processor1. A fundamental challenge is to build a high-fidelity processor capable of running quantum algorithms in an exponentially large computational space. Here we report the use of a processor with programmable superconducting qubits2–7 to create quantum states on 53 qubits, corresponding to a computational state-space of dimension 253 (about 1016). Measurements from repeated experiments sample the resulting probability distribution, which we verify using classical simulations. Our Sycamore processor takes about 200 seconds to sample one instance of a quantum circuit a million times—our benchmarks currently indicate that the equivalent task for a state-of-the-art classical supercomputer would take approximately 10,000 years. This dramatic increase in speed compared to all known classical algorithms is an experimental realization of quantum supremacy8–14 for this specific computational task, heralding a much-anticipated computing paradigm. Quantum supremacy is demonstrated using a programmable superconducting processor known as Sycamore, taking approximately 200 seconds to sample one instance of a quantum circuit a million times, which would take a state-of-the-art supercomputer around ten thousand years to compute.},
author = {et al. Arute, Frank},
doi = {10.1038/s41586-019-1666-5},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Arute et al. - 2019 - Quantum supremacy using a programmable superconducting processor.pdf:pdf},
issn = {1476-4687},
journal = {Nat. 2019 5747779},
keywords = {Quantum information,Quantum physics},
month = {oct},
number = {7779},
pages = {505--510},
publisher = {Nature Publishing Group},
title = {{Quantum supremacy using a programmable superconducting processor}},
url = {https://www.nature.com/articles/s41586-019-1666-5 https://www.nature.com/articles/s41586 019 1666 5},
volume = {574},
year = {2019}
}
@techreport{Hendrycks,
abstract = {In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.},
archivePrefix = {arXiv},
arxivId = {1903.12261v1},
author = {Hendrycks, Dan and Dietterich, Thomas},
eprint = {1903.12261v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hendrycks, Dietterich - Unknown - BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS.pdf:pdf},
title = {{BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS}},
url = {https://github.com/hendrycks/robustness.}
}
@article{Antonio2018,
abstract = {Effective training of neural networks requires much data. In the low-data
regime, parameters are underdetermined, and learnt networks generalise poorly.
Data Augmentation alleviates this by using existing data more effectively.
However standard data augmentation produces only limited plausible alternative
data. Given there is potential to generate a much broader set of augmentations,
we design and train a generative model to do data augmentation. The model,
based on image conditional Generative Adversarial Networks, takes data from a
source domain and learns to take any data item and generalise it to generate
other within-class data items. As this generative process does not depend on
the classes themselves, it can be applied to novel unseen classes of data. We
show that a Data Augmentation Generative Adversarial Network (DAGAN) augments
standard vanilla classifiers well. We also show a DAGAN can enhance few-shot
learning systems such as Matching Networks. We demonstrate these approaches on
Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. In
our experiments we can see over 13{\%} increase in accuracy in the low-data regime
experiments in Omniglot (from 69{\%} to 82{\%}), EMNIST (73.9{\%} to 76{\%}) and VGG-Face
(4.5{\%} to 12{\%}); in Matching Networks for Omniglot we observe an increase of 0.5{\%}
(from 96.9{\%} to 97.4{\%}) and an increase of 1.8{\%} in EMNIST (from 59.5{\%} to 61.3{\%}).},
archivePrefix = {arXiv},
arxivId = {1711.04340},
author = {Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
eprint = {1711.04340},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Antoniou, Storkey, Edwards - 2017 - Data Augmentation Generative Adversarial Networks.pdf:pdf},
institution = {Penn State University},
month = {nov},
title = {{Data Augmentation Generative Adversarial Networks}},
url = {https://arxiv.org/abs/1711.04340v3},
year = {2017}
}
@article{Wolny2018,
abstract = {Tackling the challenge of managing the full life-cycle of systems requires a well-defined mix of approaches. While in the early phases model-driven approaches are frequently used to design systems, in the later phases data-driven approaches are used to reason on different key performance indicators of systems under operation. This immediately poses the question how operational data can be mapped back to design models to evaluate existing designs and to reason about future redesigns. In this paper, we present a novel approach for harmonizing model-driven and data-driven approaches. In particular, we introduce an architecture for time-series data management to analyse runtime properties of systems which is derived from design models. Having this systematic generation of time-series data management opens the door to analyse data through design models. We show how such data analytics is specified for modelling languages using standard metamodelling techniques and technologies.},
author = {Wolny, Sabine and Mazak, Alexandra and Wimmer, Manuel and Konlechner, Rafael and Kappel, Gerti},
doi = {10.18417/emisa.si.hcm.19},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolny et al. - 2018 - Model-Driven Time-Series Analytics.pdf:pdf},
journal = {Int. J. Concept.},
keywords = {Data Analytics,Language Engineering,Model-Driven Engineering,Time-Series},
month = {feb},
pages = {252--261},
title = {{Model-Driven Time-Series Analytics}},
url = {http://json.org/example.html},
volume = {13},
year = {2018}
}
@article{Russel2018,
abstract = {The popularity, widespread use and increasing dependency on wireless technologies has spawned a telecommunications industrial revolution with increasing public exposure to broader and higher frequencies of the electromagnetic spectrum to transmit data through a variety of devices and infrastructure. On the horizon, a new generation of even shorter high frequency 5G wavelengths is being proposed to power the Internet of Things (IoT). The IoT promises us convenient and easy lifestyles with a massive 5G interconnected telecommunications network, however, the expansion of broadband with shorter wavelength radiofrequency radiation highlights the concern that health and safety issues remain unknown. Controversy continues with regards to harm from current 2G, 3G and 4G wireless technologies. 5G technologies are far less studied for human or environmental effects. It is argued that the addition of this added high frequency 5G radiation to an already complex mix of lower frequencies, will contribute to a negative public health outcome both from both physical and mental health perspectives. Radiofrequency radiation (RF) is increasingly being recognized as a new form of environmental pollution. Like other common toxic exposures, the effects of radiofrequency electromagnetic radiation (RF EMR) will be problematic if not impossible to sort out epidemiologically as there no longer remains an unexposed control group. This is especially important considering these effects are likely magnified by synergistic toxic exposures and other common health risk behaviors. Effects can also be non-linear. Because this is the first generation to have cradle-to-grave lifespan exposure to this level of man-made microwave (RF EMR) radiofrequencies, it will be years or decades before the true health consequences are known. Precaution in the roll out of this new technology is strongly indicated. This article will review relevant electromagnetic frequencies, exposure standards and current scientific literature on the health implications of 2G, 3G, 4G exposure, including some of the available literature on 5G frequencies. The question of what constitutes a public health issue will be raised, as well as the need for a precautionary approach in advancing new wireless technologies.},
author = {Russell, Cindy L.},
doi = {10.1016/J.ENVRES.2018.01.016},
issn = {0013-9351},
journal = {Environ. Res.},
keywords = {Environmental pollution,Public health,Radiofrequency radiation,Wireless technology},
month = {aug},
pages = {484--495},
publisher = {Academic Press},
title = {{5 G wireless telecommunications expansion: Public health and environmental implications}},
volume = {165},
year = {2018}
}
@misc{zoo21,
howpublished = {https://github.com/collections/ai-model-zoos},
title = {{Collection: Model Zoos of machine and deep learning technologies}},
url = {https://github.com/collections/ai-model-zoos},
urldate = {2021-07-19}
}
@inproceedings{Varshney2017,
abstract = {Machine learning algorithms are increasingly influencing our decisions and interacting with us in all parts of our daily lives. Therefore, just like for power plants, highways, and myriad other engineered sociotechnical systems, we must consider the safety of systems involving machine learning. In this paper, we first discuss the definition of safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. Then we examine dimensions, such as the choice of cost function and the appropriateness of minimizing the empirical average training cost, along which certain real-world applications may not be completely amenable to the foundational principle of modern statistical machine learning: empirical risk minimization. In particular, we note an emerging dichotomy of applications: ones in which safety is important and risk minimization is not the complete story (we name these Type A applications), and ones in which safety is not so critical and risk minimization is sufficient (we name these Type B applications). Finally, we discuss how four different strategies for achieving safety in engineering (inherently safe design, safety reserves, safe fail, and procedural safeguards) can be mapped to the machine learning context through inter-pretability and causality of predictive models, objectives beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software.},
archivePrefix = {arXiv},
arxivId = {1601.04126},
author = {Varshney, Kush R.},
booktitle = {2016 Inf. Theory Appl. Work. ITA 2016},
doi = {10.1109/ITA.2016.7888195},
eprint = {1601.04126},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Engineering safety in machine learning.pdf:pdf},
isbn = {9781509025299},
month = {mar},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Engineering safety in machine learning}},
year = {2017}
}
@article{Salay2017a,
author = {Salay, Rick and Queiroz, Rodrigo and Czarnecki, Krzysztof},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salay, Queiroz, Czarnecki - 2017 - An Analysis of ISO 26262 Using Machine Learning Safely in Automotive Software.pdf:pdf},
issn = {23318422},
journal = {arXiv},
month = {sep},
publisher = {arXiv},
title = {{An Analysis of ISO 26262: Using Machine Learning Safely in Automotive Software}},
url = {http://arxiv.org/abs/1709.02435},
year = {2017}
}
@techreport{Varshney2016,
abstract = {Machine learning algorithms are increasingly influencing our decisions and interacting with us in all parts of our daily lives. Therefore, just like for power plants, highways, and myriad other engineered sociotechnical systems, we must consider the safety of systems involving machine learning. In this paper, we first discuss the definition of safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. Then we examine dimensions, such as the choice of cost function and the appropriateness of minimizing the empirical average training cost, along which certain real-world applications may not be completely amenable to the foundational principle of modern statistical machine learning: empirical risk minimization. In particular, we note an emerging dichotomy of applications: ones in which safety is important and risk minimization is not the complete story (we name these Type A applications), and ones in which safety is not so critical and risk minimization is sufficient (we name these Type B applications). Finally, we discuss how four different strategies for achieving safety in engineering (inherently safe design, safety reserves, safe fail, and procedural safeguards) can be mapped to the machine learning context through inter-pretability and causality of predictive models, objectives beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software.},
archivePrefix = {arXiv},
arxivId = {1601.04126v1},
author = {Varshney, Kush R},
eprint = {1601.04126v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Varshney - 2016 - Engineering Safety in Machine Learning.pdf:pdf},
keywords = {()},
title = {{Engineering Safety in Machine Learning}},
year = {2016}
}
@article{Amodei2016,
abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
archivePrefix = {arXiv},
arxivId = {1606.06565},
author = {{Dario Amodei et al.}},
eprint = {1606.06565},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Amodei et al. - 2016 - Concrete Problems in AI Safety.pdf:pdf},
month = {jun},
title = {{Concrete Problems in AI Safety}},
url = {http://arxiv.org/abs/1606.06565},
year = {2016}
}
@article{Federated2019,
abstract = {Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.},
archivePrefix = {arXiv},
arxivId = {1912.04977},
author = {et al. Kairouz, Peter},
eprint = {1912.04977},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kairouz et al. - 2019 - Advances and Open Problems in Federated Learning.pdf:pdf},
journal = {Found. Trends{\textregistered} Mach. Learn.},
month = {dec},
number = {1–2},
pages = {1--210},
publisher = {Now Publishers},
title = {{Advances and Open Problems in Federated Learning}},
url = {https://arxiv.org/abs/1912.04977v3},
volume = {14},
year = {2019}
}
@inproceedings{Abadi,
abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production , we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that Tensor-Flow achieves for several real-world applications.},
author = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang and Brain, Google},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - Unknown - This paper is included in the Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implemen.pdf:pdf},
isbn = {978-1-931971-33-1},
title = {{TensorFlow: A System for Large-Scale Machine Learning TensorFlow: A system for large-scale machine learning}},
url = {https://tensorflow.org.}
}
@article{Sokolva2008,
abstract = {This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier's evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies. Machine Learning (ML) divides classification onto binary, multi-class, multi-labelled, and hierarchical tasks. In this work we present a systematic analysis of twenty four performance measures used in these classification subfields. We focus on how well classes are identified without reference to computation cost or time. We consider a set of changes in a confusion matrix that correspond to specific characteristics of data. We then analyze the type of changes that do not change a measure's value and therefore preserve a classifier's evaluation. This is what we call measure invariance. As a result, we build the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. We supplement the formal analysis by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers; examples are taken from text classification. Note, that we focus on recent ML developments; more details on ML measures can be found, for example, in Sokolova, Japkowicz, and Szpakowicz (2006) which looks into relations between the measures and assessment of medical trials. To the best of our knowledge, our current study is the first reviews of ML measures which comprehensively evaluates the invariant properties of measures. Preliminary results on binary classification appear in (Sokolova {\&} Lapalme, 2007). This study expands the results twofold , with discussion of new invariant properties, in some cases, adding monotonicity properties, and consideration of multi-class, multi-labelled, and hierarchical measures. Empirical evaluation remains the most used approach for the algorithm assessment, although ML algorithms can be evaluated through empirical assessment or theory or both, e.g., derived generalized bounds and empirical results (Marchand {\&} Shawe-Taylor, 2002). Evaluation techniques based on multiple experiments are considered in Dietterich (1998), one of the most cited work on empirical evaluation of ML algorithms. An extensive critique of ML evaluation practice can be found in Salzberg (1999). The author analyzes the currently used methods and their statistical validity. The paper distinguishes two goals of evaluation: a comparison of algorithms, and the feasibility of algorithms on a specific domain. Demsar (2006) surveys how classifiers are compared over multiple data sets. Empirical comparison is most often done by applying algorithms on various data sets and then evaluating the performance of the classifiers that the algorithms have produced; accuracy 0306-4573/{\$}-see front matter {\'{O}}},
author = {Sokolova, Marina and Lapalme, Guy},
doi = {10.1016/j.ipm.2009.03.002},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sokolova, Lapalme - 2009 - A systematic analysis of performance measures for classification tasks.pdf:pdf},
journal = {Inf. Process. Manag.},
keywords = {Machine Learning,Performance evaluation,Text classification},
pages = {427--437},
title = {{A systematic analysis of performance measures for classification tasks}},
url = {http://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html.},
volume = {45},
year = {2009}
}
@article{Xu,
archivePrefix = {arXiv},
arxivId = {1609.08144},
author = {Xu, Zongben and Sun, Jian},
doi = {10.1093/nsr/nwx099},
eprint = {1609.08144},
title = {{Special Topic: Machine Learning Model-driven deep-learning}},
url = {https://academic.oup.com/nsr/article-abstract/5/1/22/4093908}
}
@article{Sheng2019,
abstract = {With crowdsourcing systems, labels can be obtained with low cost, which facilitates the creation of training sets for prediction model learning. However, the labels obtained from crowdsourcing are often imperfect, which brings great challenges in model learning. Since 2008, the machine learning community has noticed the great opportunities brought by crowdsourcing and has developed a large number of techniques to deal with inaccuracy, randomness, and uncertainty issues when learning with crowdsourcing. This paper summarizes the technical progress in this field during past eleven years. We focus on two fundamental issues: the data (label) quality and the prediction model quality. For data quality, we summarize ground truth inference methods and some machine learning based methods to further improve data quality. For the prediction model quality, we summarize several learning paradigms developed under the crowdsourcing scenario. Finally, we further discuss several promising future research directions to attract researchers to make contributions in crowdsourcing.},
author = {Sheng, Victor S. and Zhang, Jing},
doi = {10.1609/AAAI.V33I01.33019837},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sheng, Zhang - 2019 - Machine Learning with Crowdsourcing A Brief Summary of the Past Research and Future Directions.pdf:pdf},
issn = {2374-3468},
journal = {Proc. AAAI Conf. Artif. Intell.},
keywords = {Anomaly Detection,Novelty Detection,Open Set Recognition,Open World Recognition,Rejection},
month = {jul},
number = {01},
pages = {9837--9843},
publisher = {Association for the Advancement of Artificial Intelligence (AAAI)},
title = {{Machine Learning with Crowdsourcing: A Brief Summary of the Past Research and Future Directions}},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/5059},
volume = {33},
year = {2019}
}
@inproceedings{Braiek2019,
abstract = {The increasing inclusion of Machine Learning (ML) models in safety-critical systems like autonomous cars have led to the development of multiple model-based ML testing techniques. One common denominator of these testing techniques is their assumption that training programs are adequate and bug-free. These techniques only focus on assessing the performance of the constructed model using manually labeled data or automatically generated data. However, their assumptions about the training program are not always true as training programs can contain inconsistencies and bugs. In this paper, we examine training issues in ML programs and propose a catalog of verification routines that can be used to detect the identified issues, automatically. We implemented the routines in a Tensorflow-based library named TFCheck. Using TFCheck, practitioners can detect the aforementioned issues automatically. To assess the effectiveness of TFCheck, we conducted a case study with real-world, mutants, and synthetic training programs. Results show that TFCheck can successfully detect training issues in ML code implementations.},
archivePrefix = {arXiv},
arxivId = {1909.02562},
author = {Braiek, Houssem Ben and Khomh, Foutse},
booktitle = {Proc. - 19th IEEE Int. Conf. Softw. Qual. Reliab. Secur. QRS 2019},
doi = {10.1109/QRS.2019.00059},
eprint = {1909.02562},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/A TensorFlow Library for Detecting Training Issues in.pdf:pdf},
isbn = {9781728139272},
keywords = {Deep Learning,TensorFlow program,Testing,Training issues},
month = {jul},
pages = {426--433},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{TFCheck : A TensorFlow Library for Detecting Training Issues in Neural Network Programs}},
year = {2019}
}
@techreport{Annable2020,
abstract = {Thesis},
author = {Annable, Nicholas and Mechatronics, B Eng},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Annable, Mechatronics - 2020 - A Model-Based Approach to Formal Assurance Cases.pdf:pdf},
keywords = {Safety Assurance,Software Engineering,Thesis},
title = {{A Model-Based Approach to Formal Assurance Cases}},
url = {https://macsphere.mcmaster.ca/handle/11375/25343},
year = {2020}
}
@techreport{Chen2017,
abstract = {Deep learning models have achieved high performance on many tasks, and thus have been applied to many security-critical scenarios. For example, deep learning-based face recognition systems have been used to authenticate users to access many security-sensitive applications like payment apps. Such usages of deep learning systems provide the adversaries with sufficient incentives to perform attacks against these systems for their adversarial purposes. In this work, we consider a new type of attacks, called backdoor attacks, where the attacker's goal is to create a backdoor into a learning-based authentication system, so that he can easily circumvent the system by leveraging the backdoor. Specifically, the adversary aims at creating backdoor instances, so that the victim learning system will be misled to classify the backdoor instances as a target label specified by the adversary. In particular, we study backdoor poisoning attacks, which achieve backdoor attacks using poisoning strategies. That is, the attacker injects poisoning samples into the training set to achieve his adversarial goal. Different from all existing work, our studied poisoning strategies can apply under a very weak threat model: (1) the adversary has no knowledge of the model and the training set used by the victim system; (2) the attacker is allowed to inject only a small amount of poisoning samples; (3) the backdoor key is hard to notice even by human beings to achieve stealthiness. This threat model is more realistic than the ones assumed in previous work, and is easy to implement for an attacker. Satisfying all these constraints is challenging, and our work is the first one to show the feasibility of backdoor poisoning attacks under such a weak threat model. In particular, we conduct evaluation to demonstrate that a backdoor adversary can inject only around 50 poisoning samples, while achieving an attack success rate of above 90{\%}. We are also the first work to show that a data poisoning attack can create physically implementable backdoors without touching the training process. Our work demonstrates that backdoor poisoning attacks pose real threats to a learning system, and thus highlights the importance of further investigation and proposing defense strategies against them.},
archivePrefix = {arXiv},
arxivId = {1712.05526v1},
author = {Chen, Xinyun and Liu, Chang and Li, Bo and Lu, Kimberly and Song, Dawn},
eprint = {1712.05526v1},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - Unknown - Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning.pdf:pdf},
title = {{Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning}}
}
@article{Flach2019,
abstract = {This paper gives an overview of some ways in which our understanding of performance evaluation measures for machine-learned classifiers has improved over the last twenty years. I also highlight a range of areas where this understanding is still lacking, leading to ill-advised practices in classifier evaluation. This suggests that in order to make further progress we need to develop a proper measurement theory of machine learning. I then demonstrate by example what such a measurement theory might look like and what kinds of new results it would entail. Finally, I argue that key properties such as classification ability and data set difficulty are unlikely to be directly observable, suggesting the need for latent-variable models and causal inference.},
author = {Flach, Peter},
doi = {10.1609/AAAI.V33I01.33019808},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Flach - 2019 - Performance Evaluation in Machine Learning The Good, the Bad, the Ugly, and the Way Forward.pdf:pdf},
issn = {2374-3468},
journal = {Proc. AAAI Conf. Artif. Intell.},
keywords = {Anomaly Detection,Novelty Detection,Open Set Recognition,Open World Recognition,Rejection},
month = {jul},
number = {01},
pages = {9808--9814},
publisher = {Association for the Advancement of Artificial Intelligence (AAAI)},
title = {{Performance Evaluation in Machine Learning: The Good, the Bad, the Ugly, and the Way Forward}},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/5055},
volume = {33},
year = {2019}
}
@article{Vogel2014,
abstract = {The development of self-adaptive software requires the engineering of an adaptation engine that controls the underlying adaptable software by feedback loops. The engine often describes the adaptation by runtime models representing the adaptable software and by activities such as analysis and planning that use these models. To systematically address the interplay between runtime models and adaptation activities, runtime megamodels have been proposed. A runtime megamodel is a specific model capturing runtime models and adaptation activities. In this article, we go one step further and present an executable modeling language for ExecUtable RuntimE MegAmodels (EUREMA) that eases the development of adaptation engines by following a model-driven engineering approach. We provide a domain-specific modeling language and a runtime interpreter for adaptation engines, in particular feedback loops. Megamodels are kept alive at runtime and by interpreting them, they are directly executed to run feedback loops. Additionally, they can be dynamically adjusted to adapt feedback loops. Thus, EUREMA supports development by making feedback loops explicit at a higher level of abstraction and it enables solutions where multiple feedback loops interact or operate on top of each other and self-adaptation co-exists with offline adaptation for evolution.},
author = {Vogel, Thomas and Giese, Holger},
doi = {10.1145/2555612},
journal = {ACM Trans. Auton. Adapt. Syst. 8, 4, Artic.},
keywords = {D210 [Software Engineering]: Design General Terms:,D22 [Software Engineering]: Design Tools and Techn,D29 [Software Engineering]: Management},
title = {{8 Model-Driven Engineering of Self-Adaptive Software with EUREMA}},
url = {http://dx.doi.org/10.1145/2555612},
volume = {18},
year = {2014}
}
@article{Anderson2020,
abstract = {How should reinforcement learning (RL) agents explain themselves to humans not trained in AI? To gain insights into this question, we conducted a 124-participant, four-treatment experiment to compare participants' mental models of an RL agent in the context of a simple Real-Time Strategy (RTS) game. The four treatments isolated two types of explanations vs. neither vs. both together. The two types of explanations were as follows: (1) saliency maps (an "Input Intelligibility Type"that explains the AI's focus of attention) and (2) reward-decomposition bars (an "Output Intelligibility Type"that explains the AI's predictions of future types of rewards). Our results show that a combined explanation that included saliency and reward bars was needed to achieve a statistically significant difference in participants' mental model scores over the no-explanation treatment. However, this combined explanation was far from a panacea: It exacted disproportionately high cognitive loads from the participants who received the combined explanation. Further, in some situations, participants who saw both explanations predicted the agent's next action worse than all other treatments' participants.},
author = {Anderson, Andrew and Dodge, Jonathan and Sadarangani, Amrita and Juozapaitis, Zoe and Newman, Evan and Irvine, Jed and Chattopadhyay, Souti and Olson, Matthew and Fern, Alan and Burnett, Margaret},
doi = {10.1145/3366485},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson et al. - 2020 - Mental Models of Mere Mortals with Explanations of Reinforcement Learning.pdf:pdf},
issn = {21606463},
journal = {ACM Trans. Interact. Intell. Syst.},
keywords = {Intelligent user interfaces,human-computer interaction},
month = {jun},
number = {2},
pages = {15},
publisher = {Association for Computing Machinery},
title = {{Mental Models of Mere Mortals with Explanations of Reinforcement Learning}},
url = {https://doi.org/10.1145/3366485},
volume = {10},
year = {2020}
}
@article{Ashmore2021,
abstract = {{\textless}p{\textgreater} Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the {\textless}italic{\textgreater}assurance of ML{\textless}/italic{\textgreater} , i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the {\textless}italic{\textgreater}machine learning lifecycle{\textless}/italic{\textgreater} , i.e., of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research. {\textless}/p{\textgreater}},
author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
doi = {10.1145/3453444},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashmore, Calinescu, Paterson - 2021 - Assuring the Machine Learning Lifecycle.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
keywords = {Additional Key Words and Phrases: Machine learning,CCS Concepts: • Computing methodologies → Machine,Model verification and validation,• General and reference → Surveys and overviews},
month = {may},
number = {5},
pages = {1--39},
publisher = {
		ACM
		PUB27
		New York, NY, USA
	},
title = {{Assuring the Machine Learning Lifecycle}},
url = {https://dl.acm.org/doi/10.1145/3453444},
volume = {54},
year = {2021}
}
@article{Koseler,
abstract = {Accompanying the Big Data (BD) paradigm is a resurgence in machine learning (ML). Using ML techniques to work with BD is a complex task, requiring specialized knowledge of the problem space, domain specific concepts, and appropriate ML approaches. However, specialists who possess that knowledge and programming ability are difficult to find and expensive to train. Model-Driven Engineering (MDE) allows developers to implement quality software through modeling using high-level domain specific concepts. In this research, we attempt to fill the gap between MDE and the industrial need for development of ML software by demonstrating the plausibility of applying MDE to BD. Specifically, we apply MDE to the setting of the thriving industry of professional baseball analytics. Our case study involves developing an MDE solution for the binary classification problem of predicting if a baseball pitch will be a fastball. We employ and refine an existing, but untested, ML Domain-Specific Modeling Language (DSML); devise model instances representing prediction features; create a code generation scheme; and evaluate our solution. We show our MDE solution is comparable to the one developed through traditional programming, distribute all our artifacts for public use and extension, and discuss the impact of our work and lessons we learned.},
author = {Koseler, Kaan and Mcgraw, Kelsea and Stephan, Matthew},
doi = {10.5220/0007245800130024},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Koseler, Mcgraw, Stephan - Unknown - Realization of a Machine Learning Domain Specific Modeling Language A Baseball Analytics Case Study.pdf:pdf},
isbn = {9789897583582},
keywords = {Baseball Analytics,Binary Classification,Domain Specific Modeling Language,Machine Learning,Model Driven Engineering,Supervised Learning},
title = {{Realization of a Machine Learning Domain Specific Modeling Language: A Baseball Analytics Case Study}},
url = {https://sc.lib.miamioh.edu/handle/2374.MIA/6234}
}
@inproceedings{Perez-Soler2020,
abstract = {Conversational interfaces (also called chatbots) are being increasingly adopted in various domains such as e-commerce or customer service, as a direct communication channel between companies and end-users. Their advantage is that they can be embedded within social networks, and provide a natural language (NL) interface that enables their use by non-technical users. While there are many emerging platforms for building chatbots, their construction remains a highly technical, challenging task. In this paper, we propose the use of chatbots to facilitate querying domain-specific models. This way, instead of relying on technical query languages (e.g., OCL), models are queried using NL as this can be more suitable for non-technical users. To avoid manual programming, our solution is based on the automatic synthesis of the model query chatbots from a domain meta-model. These chatbots communicate with an EMF-based modelling backend using the Xatkit framework.},
author = {P{\'{e}}rez-Soler, Sara and Daniel, Gwendal and Cabot, Jordi and Guerra, Esther and de Lara, Juan},
booktitle = {Lect. Notes Bus. Inf. Process.},
doi = {10.1007/978-3-030-49418-6_17},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/P{\'{e}}rez-Soler et al. - 2020 - Towards automating the synthesis of chatbots for conversational model query.pdf:pdf},
isbn = {9783030494179},
issn = {18651356},
keywords = {Automatic chatbot synthesis,Model query,Model-driven engineering},
month = {jun},
pages = {257--265},
publisher = {Springer},
title = {{Towards automating the synthesis of chatbots for conversational model query}},
url = {https://doi.org/10.1007/978-3-030-49418-6{\_}17},
volume = {387 LNBIP},
year = {2020}
}
@misc{Omg2010,
author = {{Object Management Group}},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Omg - 2010 - An OMG{\textregistered} Structured Assurance Case Metamodel TM Publication Structured Assurance Case Metamodel (SACM) Version 2.1 OMG Docum.pdf:pdf},
howpublished = {https://www.omg.org/spec/SACM/2.1/PDF},
title = {{Structured Assurance Case Metamodel (SACM)}},
url = {https://www.omg.org/spec/SACM/2.1/PDF},
urldate = {2021-06-15},
year = {2010}
}
@article{Mohseni2020,
abstract = {Autonomous vehicles rely on machine learning to solve challenging tasks in perception and motion planning. However, automotive software safety standards have not fully evolved to address the challenges of machine learning safety such as interpretability, verification, and performance limitations. In this paper, we review and organize practical machine learning safety techniques that can complement engineering safety for machine learning based software in autonomous vehicles. Our organization maps safety strategies to state-of-the-art machine learning techniques in order to enhance dependability and safety of machine learning algorithms. We also discuss security limitations and user experience aspects of machine learning components in autonomous vehicles.},
author = {Mohseni, Sina and Pitale, Mandar and Singh, Vasu and Wang, Zhangyang},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohseni et al. - 2020 - Practical Solutions for Machine Learning Safety in Autonomous Vehicles.pdf:pdf},
keywords = {Autonomous,Machine Learning,Safety},
mendeley-tags = {Autonomous,Machine Learning,Safety},
title = {{Practical Solutions for Machine Learning Safety in Autonomous Vehicles}},
year = {2020}
}
@techreport{Garcia2015,
abstract = {Safe Reinforcement Learning can be defined as the process of learning policies that maximize the expectation of the return in problems in which it is important to ensure reasonable system performance and/or respect safety constraints during the learning and/or deployment processes. We categorize and analyze two approaches of Safe Reinforcement Learning. The first is based on the modification of the optimality criterion, the classic discounted fi-nite/infinite horizon, with a safety factor. The second is based on the modification of the exploration process through the incorporation of external knowledge or the guidance of a risk metric. We use the proposed classification to survey the existing literature, as well as suggesting future directions for Safe Reinforcement Learning.},
author = {Garc{\'{i}}a, Javier and Fern{\'{a}}ndez, Fernando},
booktitle = {J. Mach. Learn. Res.},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{i}}a, Fern{\'{a}}ndez - 2015 - A Comprehensive Survey on Safe Reinforcement Learning.pdf:pdf},
keywords = {reinforcement learning,risk sensitivity,safe exploration,teacher advice},
pages = {1437--1480},
title = {{A Comprehensive Survey on Safe Reinforcement Learning}},
volume = {16},
year = {2015}
}
@article{Laciok2021,
abstract = {Citation: Laciok, V.; Sikorova, K.; Fabiano, B.; Bernatik, A. Trends and Opportunities of Tertiary Education in Safety Engineering Moving towards Safety 4.0. Sustainability 2021, 13, 524. https://doi. Publisher's Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations. Abstract: Industry and related work and workplaces are constantly changing as a result of the implementation of new technologies, substances and work processes, changes in the composition of the workforce and the labor market, and new forms of employment and work organization. The implementation of new technologies represents certain ambivalence. Next to the positive impact on workers' health, new risks and challenges can arise in the area of process and occupational safety and health of people at work. On these bases, it follows the need for predicting and handling the new risks, in order to ensure safe and healthy workplaces in the future. The aim of most forecasting studies is not only to identify new emerging risks, but also to foresee changes that could affect occupational safety and health. However, a number of questions still require proper investigation, i.e., "What impact do new emerging risks have on tertiary education in the area of Safety engineering? Has tertiary education already reacted to progress in science and research and does it have these innovations in its syllabus? How are tertiary graduates prepared for the real world of new technologies?" This paper represents a first attempt in the literature to provide answers to the raised questions, by a survey approach involving academics, Health Safety and Environment (HSE) industrial experts and university students in the Czech Republic. Even if statistical evaluation is limited to a single Country and to a small sample size, the obtained results allow suggesting practical recommendations that can contribute to ensuring new challenges in the area of education by addressing relevant culture issues needed to support new workplace realities according to the newly defined Safety 4.0.},
author = {Laciok, Vendula and Sikorova, Katerina and Fabiano, Bruno and Bernatik, Ales},
doi = {10.3390/su13020524},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Laciok et al. - 2021 - Trends and Opportunities of Tertiary Education in Safety Engineering Moving towards Safety 4.0.pdf:pdf},
keywords = {Safety 40,digital technologies and risk,occupational safety and health,process safety engineering,sustainable education},
title = {{Trends and Opportunities of Tertiary Education in Safety Engineering Moving towards Safety 4.0}},
url = {https://doi.org/10.3390/su13020524},
year = {2021}
}
@article{ Krenin2016,
abstract = {In order for robots to learn from people with no machine learning expertise, robots should learn from natural human instruction. Most machine learning techniques that incorporate explanations require people to use a limited vocabulary and provide state information, even if it is not intuitive. This paper discusses a software agent that learned to play the Mario Bros. game using explanations. Our goals to improve learning from explanations were twofold: to filter explanations into advice and warnings, and to learn policies from sentences without state information. We used sentiment analysis to filter explanations into advice of what to do and warnings of what to avoid. We developed Object-focused advice to represent what actions the agent should take when dealing with objects. An RL agent used Object-focused advice to learn policies that maximized its reward. After mitigating false negatives, using sentiment as a filter was approximately 85{\%} accurate. Object-focused advice performed better than when no advice was given, the agent learned where to apply the advice, and the agent could recover from adversarial advice. We also found the method of interaction should be designed to ease the cognitive load of the human teacher or the advice may be of poor quality.},
author = {Krening, Samantha and Harrison, Brent and Feigh, Karen M and Isbell, Charles and Riedl, Mark and Thomaz, Andrea},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krening et al. - Unknown - Learning from Explanations using Sentiment and Advice in RL.pdf:pdf},
keywords = {Advice,Index Terms-Sentiment,Reinforcement Learning},
title = {{Learning from Explanations using Sentiment and Advice in RL}}
}
@article{Hartmann2019a,
abstract = {Machine learning algorithms are designed to resolve unknown behaviors by extracting commonalities over massive datasets. Unfortunately, learning such global behaviors can be inaccurate and slow for systems composed of heterogeneous elements, which behave very differently, for instance as it is the case for cyber-physical systems and Internet of Things applications. Instead, to make smart decisions, such systems have to continuously refine the behavior on a per-element basis and compose these small learning units together. However, combining and composing learned behaviors from different elements is challenging and requires domain knowledge. Therefore, there is a need to structure and combine the learned behaviors and domain knowledge together in a flexible way. In this paper we propose to weave machine learning into domain modeling. More specifically, we suggest to decompose machine learning into reusable, chainable, and independently computable small learning units, which we refer to as microlearning units. These microlearning units are modeled together with and at the same level as the domain data. We show, based on a smart grid case study, that our approach can be significantly more accurate than learning a global behavior, while the performance is fast enough to be used for live learning.},
author = {Hartmann, Thomas and Moawad, Assaad and Fouquet, Francois and {Le Traon}, Yves},
doi = {10.1007/s10270-017-0600-2},
issn = {1619-1366},
journal = {Softw. Syst. Model.},
keywords = {Cyber-physical systems,Domain modeling,Live learning,Metamodeling,Model-driven engineering,Smart grids},
month = {apr},
number = {2},
pages = {1285--1304},
publisher = {Springer Verlag},
title = {{The next evolution of MDE: a seamless integration of machine learning into domain modeling}},
url = {http://link.springer.com/10.1007/s10270-017-0600-2},
volume = {18},
year = {2019}
}
@article{Ganin2015,
abstract = {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of "deep" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard back-propagation. Overall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.},
archivePrefix = {arXiv},
arxivId = {1409.7495},
author = {Ganin, Yaroslav and Lempitsky, Victor},
eprint = {1409.7495},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ganin, Lempitsky - 2015 - Unsupervised domain adaptation by backpropagation.pdf:pdf},
isbn = {9781510810587},
journal = {32nd Int. Conf. Mach. Learn. ICML 2015},
month = {sep},
pages = {1180--1189},
publisher = {International Machine Learning Society (IMLS)},
title = {{Unsupervised domain adaptation by backpropagation}},
url = {https://arxiv.org/abs/1409.7495v2},
volume = {2},
year = {2015}
}
@article{Humbatova,
abstract = {The growing application of deep neural networks in safety-critical domains makes the analysis of faults that occur in such systems of enormous importance. In this paper we introduce a large taxonomy of faults in deep learning (DL) systems. We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts. Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our tax-onomy with a variety of additional faults that did not emerge from the other two sources. Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50{\%} of the survey participants. CCS CONCEPTS • Software and its engineering → Software verification and validation.},
author = {Humbatova, Nargiz and Jahangirova, Gunel and Bavota, Gabriele and Riccio, Vincenzo and Stocco, Andrea and Tonella, Paolo},
doi = {10.1145/3377811.3380395},
file = {:C$\backslash$:/Users/Suchendra/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Humbatova et al. - Unknown - Taxonomy of Real Faults in Deep Learning Systems.pdf:pdf},
isbn = {9781450371216},
keywords = {deep learning,real faults,software testing,taxonomy},
pages = {12},
publisher = {ACM},
title = {{Taxonomy of Real Faults in Deep Learning Systems}},
url = {https://doi.org/10.1145/3377811.3380395}
}
